[
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "anndata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "anndata",
        "description": "anndata",
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "AnnData",
        "importPath": "anndata",
        "description": "anndata",
        "isExtraImport": true,
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "scanpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scanpy",
        "description": "scanpy",
        "detail": "scanpy",
        "documentation": {}
    },
    {
        "label": "scanpy.external",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scanpy.external",
        "description": "scanpy.external",
        "detail": "scanpy.external",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "mst",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mst",
        "description": "mst",
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "unionfind",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unionfind",
        "description": "unionfind",
        "detail": "unionfind",
        "documentation": {}
    },
    {
        "label": "unionfind",
        "importPath": "unionfind",
        "description": "unionfind",
        "isExtraImport": true,
        "detail": "unionfind",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "plotly.graph_objs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "plotly.graph_objs",
        "description": "plotly.graph_objs",
        "detail": "plotly.graph_objs",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "read_data",
        "description": "read_data",
        "isExtraImport": true,
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "calendar",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "calendar",
        "description": "calendar",
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "optim",
        "description": "optim",
        "detail": "optim",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "importPath": "datasets.hc_dataset",
        "description": "datasets.hc_dataset",
        "isExtraImport": true,
        "detail": "datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "isExtraImport": true,
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "importPath": "model.hyphc",
        "description": "model.hyphc",
        "isExtraImport": true,
        "detail": "model.hyphc",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "add_flags_from_config",
        "importPath": "utils.training",
        "description": "utils.training",
        "isExtraImport": true,
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "get_savedir",
        "importPath": "utils.training",
        "description": "utils.training",
        "isExtraImport": true,
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_geodesic",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "core",
        "description": "core",
        "isExtraImport": true,
        "detail": "core",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "kind": 6,
        "importPath": "datasets.hc_dataset",
        "description": "datasets.hc_dataset",
        "peekOfCode": "class HCDataset(data.Dataset):\n    \"\"\"Hierarchical clustering dataset.\"\"\"\n    def __init__(self, features, labels, similarities, num_samples):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.features = features",
        "detail": "datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "IMDataset",
        "kind": 6,
        "importPath": "datasets.improve_dataset",
        "description": "datasets.improve_dataset",
        "peekOfCode": "class IMDataset(data.Dataset):\n    def __init__(self,similarities, num_samples,leaves_embeddings,datas):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.similarities = similarities\n        self.leaves_embeddings = leaves_embeddings",
        "detail": "datasets.improve_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "peekOfCode": "def load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.\n    @param dataset: dataset name\n    @type dataset: str\n    @param normalize: whether to normalize features or not\n    @type normalize: boolean\n    @return: feature vectors, labels, and pairwise similarities computed with cosine similarity\n    @rtype: Tuple[np.array, np.array, np.array]\n    \"\"\"\n    # if dataset in UCI_DATASETS:",
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_uci_data",
        "kind": 2,
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "peekOfCode": "def load_uci_data(dataset,start_idx,end_idx,label_idx):\n    \"\"\"Loads data from UCI repository.\n    @param dataset: UCI dataset name\n    @return: feature vectors, labels\n    @rtype: Tuple[np.array, np.array]\n    \"\"\"\n    x = []\n    y = []\n    # data_path = os.path.join(os.environ[\"DATAPATH\"], dataset, \"{}.data\".format(dataset))\n    data_path = dataset",
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "UCI_DATASETS",
        "kind": 5,
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "peekOfCode": "UCI_DATASETS = [\n    \"glass\",\n    \"zoo\",\n    \"iris\",\n    \"sc\",\n    \"4_7\",\n    \"4_8\",\n]\ndef load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.",
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "Preprocessing",
        "kind": 6,
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "peekOfCode": "class Preprocessing:\n    def __init__(self):\n        pass\n    def preprocessing_rawdata(\n        self,\n        adata,\n        Min_Genes=200,\n        Min_Cells=3,\n        Min_Mean=0.0125,\n        Max_Mean=3,",
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 2,
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "peekOfCode": "def preprocessing(\n    adata: AnnData,\n    Min_Genes: int = 200,\n    Min_Cells: int = 3,\n    Min_Mean: float = 0.0125,\n    Max_Mean: float = 3,\n    Min_Disp: float = 0.5,\n    N_pcs: int = 50,\n    n_Top_genes: int = 2000,\n    K: int = 10,",
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing_cluster",
        "kind": 2,
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "peekOfCode": "def preprocessing_cluster(adata,\n                        N_pcs=50,\n                        K=10,\n                        copy=False,\n                        resolution=0.5,\n                    ):\n        adata.raw = adata\n        # adata._inplace_subset_var(adata.var['highly_variable'])\n        sc.tl.pca(\n            adata,",
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid_for_genes",
        "kind": 2,
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid_for_genes(\n        adata,\n        gene_list,\n        save_path=\"./\",\n        groupby ='leiden',\n    ):\n    filtered_data = adata.raw.to_adata()[:, gene_list]\n    # filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    # adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))",
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "sort_data",
        "kind": 2,
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "peekOfCode": "def sort_data(\n    adata1,\n    adata2,\n    N_1=2000,\n    N_2=2000\n):\n    if N_1 is not None:\n        adata1 = adata1.raw.to_adata()\n        sc.pp.highly_variable_genes(adata1, n_top_genes=N_1,flavor='seurat_v3')\n        adata1 = adata1[:, adata1.var['highly_variable']]",
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "kind": 2,
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "peekOfCode": "def samples_triples(n_nodes, num_samples):\n    num_samples = int(num_samples)\n    all_nodes = np.arange(n_nodes)\n    mesh = np.array(np.meshgrid(all_nodes, all_nodes))\n    pairs = mesh.T.reshape(-1, 2)\n    pairs = pairs[pairs[:, 0] < pairs[:, 1]]\n    n_pairs = pairs.shape[0]\n    if num_samples < n_pairs:\n        print(\"Generating all pairs subset\")\n        subset = np.random.choice(np.arange(n_pairs), num_samples, replace=False)",
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "kind": 2,
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "peekOfCode": "def generate_all_triples(n_nodes):\n    triples = []\n    for n1 in tqdm(np.arange(n_nodes)):\n        for n2 in np.arange(n1 + 1, n_nodes):\n            for n3 in np.arange(n2 + 1, n_nodes):\n                triples += [(n1, n2, n3)]\n    return np.array(triples)",
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "kind": 6,
        "importPath": "model.hyphc",
        "description": "model.hyphc",
        "peekOfCode": "class HypHC(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(HypHC, self).__init__()\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)",
        "detail": "model.hyphc",
        "documentation": {}
    },
    {
        "label": "improvehc",
        "kind": 6,
        "importPath": "model.improvehc",
        "description": "model.improvehc",
        "peekOfCode": "class improvehc(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self,leaves_embeddings,dumpy_node, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(improvehc, self).__init__()\n        self.leaves_embeddings = leaves_embeddings\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature",
        "detail": "model.improvehc",
        "documentation": {}
    },
    {
        "label": "RAdam",
        "kind": 6,
        "importPath": "optim.radam",
        "description": "optim.radam",
        "peekOfCode": "class RAdam(torch.optim.Adam):\n    \"\"\"Riemannian Adam with the same API as :class:`torch.optim.Adam`\n    Parameters\n    ----------\n    params : iterable\n        iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr : float (optional)\n        learning rate (default: 1e-3)\n    betas : Tuple[float, float] (optional)",
        "detail": "optim.radam",
        "documentation": {}
    },
    {
        "label": "copy_or_set_",
        "kind": 2,
        "importPath": "optim.radam",
        "description": "optim.radam",
        "peekOfCode": "def copy_or_set_(dest, source):\n    \"\"\"\n    A workaround to respect strides of :code:`dest` when copying :code:`source`\n    (https://github.com/geoopt/geoopt/issues/70)\n    Parameters\n    ----------\n    dest : torch.Tensor\n        Destination tensor where to store new data\n    source : torch.Tensor\n        Source data to put in the new tensor",
        "detail": "optim.radam",
        "documentation": {}
    },
    {
        "label": "isometric_transform",
        "kind": 2,
        "importPath": "utils.lca",
        "description": "utils.lca",
        "peekOfCode": "def isometric_transform(a, x):\n    \"\"\"Reflection (circle inversion of x through orthogonal circle centered at a).\"\"\"\n    r2 = torch.sum(a ** 2, dim=-1, keepdim=True) - 1.\n    u = x - a\n    return r2 / torch.sum(u ** 2, dim=-1, keepdim=True) * u + a\ndef reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"",
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "reflection_center",
        "kind": 2,
        "importPath": "utils.lca",
        "description": "utils.lca",
        "peekOfCode": "def reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)",
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "euc_reflection",
        "kind": 2,
        "importPath": "utils.lca",
        "description": "utils.lca",
        "peekOfCode": "def euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)\n    norm_a_sq = torch.sum(a ** 2, dim=-1, keepdim=True).clamp_min(MIN_NORM)\n    proj = xTa * a / norm_a_sq\n    return 2 * proj - x",
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "kind": 2,
        "importPath": "utils.lca",
        "description": "utils.lca",
        "peekOfCode": "def hyp_lca(a, b, return_coord=True):\n    \"\"\"\n    Computes projection of the origin on the geodesic between a and b, at scale c\n    More optimized than hyp_lca1\n    \"\"\"\n    r = reflection_center(a)\n    b_inv = isometric_transform(r, b)\n    o_inv = a\n    o_inv_ref = euc_reflection(o_inv, b_inv)\n    o_ref = isometric_transform(r, o_inv_ref)",
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "sl_np_mst",
        "kind": 2,
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "peekOfCode": "def sl_np_mst(similarities):\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst.mst(similarities, n)\n    uf = unionfind.UnionFind(n)\n    uf.merge(ij)\n    return uf.tree\ndef sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]",
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "kind": 2,
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "peekOfCode": "def sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    return sl_np_mst(sim_mat.numpy())\n### Single linkage using naive union find\n# @profile\ndef nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1",
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "kind": 2,
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "peekOfCode": "def nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1\n    similarities will be partitioned into buckets of geometrically increasing size\n    \"\"\"\n    n = xs.shape[0]\n    # Construct distance matrix (negative similarity; since numpy only has increasing sorting)\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    dist_mat = -S(xs0, xs1)  # (n, n)",
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "Artanh",
        "kind": 6,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "class Artanh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(-1 + 1e-5, 1 - 1e-5)\n        ctx.save_for_backward(x)\n        dtype = x.dtype\n        x = x.double()\n        return (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5).to(dtype)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "Arcosh",
        "kind": 6,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "class Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "Arsinh",
        "kind": 6,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "class Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors\n        return grad_output / (1 + input ** 2) ** 0.5",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "kind": 2,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "def arctanh(x):\n    return Artanh.apply(x)\ndef tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "kind": 2,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "def tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "kind": 2,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "def arcosh(x):\n    return Arcosh.apply(x)\ndef cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "cosh",
        "kind": 2,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "def cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arsinh",
        "kind": 2,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "def arsinh(x):\n    return Arsinh.apply(x)\ndef sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "sinh",
        "kind": 2,
        "importPath": "utils.math",
        "description": "utils.math",
        "peekOfCode": "def sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost_iterative",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def dasgupta_cost_iterative(tree, similarities):\n    \"\"\" Non-recursive version of DC. Also works on non-binary trees \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    cost = [0] * n\n    desc = [None] * n  # intermediate computation: children of node\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def dasgupta_cost(tree, similarities):\n    \"\"\" Non-recursive version of DC for binary trees.\n    Optimized for speed by reordering similarity matrix for locality\n    \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    n_leaves = len(similarities)\n    leaves = descendants_traversal(tree)\n    n_desc, left_desc = descendants_count(tree)\n    cost = [0] * n  # local cost for every node",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "lambda_",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)\ndef gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "gyration",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)\n    uv = (u * v).sum(dim=-1, keepdim=True)\n    uw = (u * w).sum(dim=-1, keepdim=True)\n    vw = (v * w).sum(dim=-1, keepdim=True)\n    a = - uw * v2 + vw + 2 * uv * vw\n    b = - vw * u2 - uw\n    d = 1 + 2 * uv + u2 * v2",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def ptransp(x, y, u):\n    \"\"\"Parallel transport.\"\"\"\n    lx = lambda_(x)\n    ly = lambda_(y)\n    return gyration(y, -x, u) * lx / ly\ndef expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1\ndef project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)\n    cond = norm > maxnorm\n    projected = x / norm * maxnorm\n    return torch.where(cond, projected, x)\ndef mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"\n    x2 = torch.sum(x * x, dim=-1, keepdim=True)\n    y2 = torch.sum(y * y, dim=-1, keepdim=True)\n    xy = torch.sum(x * y, dim=-1, keepdim=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    denom = 1 + 2 * xy + x2 * y2\n    return num / denom.clamp_min(MIN_NORM)\ndef mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"\n    normx = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    return tanh(t * arctanh(normx)) * x / normx\ndef get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "get_midpoint_o",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)\n    return 2 * arctanh(x_norm)\ndef hyp_dist(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "kind": 2,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "def hyp_dist(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "kind": 5,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "MIN_NORM = 1e-15\nBALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "BALL_EPS",
        "kind": 5,
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "peekOfCode": "BALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)",
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "str2bool",
        "kind": 2,
        "importPath": "utils.training",
        "description": "utils.training",
        "peekOfCode": "def str2bool(v):\n    \"\"\"Converts string to boolean.\"\"\"\n    if isinstance(v, bool):\n        return v\n    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError('Boolean value expected.')",
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "add_flags_from_config",
        "kind": 2,
        "importPath": "utils.training",
        "description": "utils.training",
        "peekOfCode": "def add_flags_from_config(parser, config_dict):\n    \"\"\"Adds a flag (and default value) to an ArgumentParser for each parameter in a config.\"\"\"\n    def OrNone(default):\n        def func(x):\n            # Convert \"none\" to proper None object\n            if x.lower() == \"none\":\n                return None\n            # If default is None (and x is not None), return x without conversion as str\n            elif default is None:\n                return str(x)",
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "hash_dict",
        "kind": 2,
        "importPath": "utils.training",
        "description": "utils.training",
        "peekOfCode": "def hash_dict(values):\n    \"\"\"Hash of dict key, value pairs.\"\"\"\n    m = hashlib.sha256()\n    keys = sorted(list(values.keys()))\n    for k in keys:\n        if k != \"seed\":\n            m.update(str(values[k]).encode('utf-8'))\n    return m.hexdigest()\ndef get_savedir(args):\n    \"\"\"Hash of args used for training.\"\"\"",
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "get_savedir",
        "kind": 2,
        "importPath": "utils.training",
        "description": "utils.training",
        "peekOfCode": "def get_savedir(args):\n    \"\"\"Hash of args used for training.\"\"\"\n    dir_hash = hash_dict(args.__dict__)\n    save_dir = os.path.join(os.environ[\"SAVEPATH\"], args.dataset, dir_hash)\n    return save_dir",
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "kind": 2,
        "importPath": "utils.tree",
        "description": "utils.tree",
        "peekOfCode": "def descendants_traversal(tree):\n    \"\"\"Get all descendants non-recursively, in traversal order.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    traversal = []\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    is_leaf = [len(children[node]) == 0 for node in range(n)]\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "kind": 2,
        "importPath": "utils.tree",
        "description": "utils.tree",
        "peekOfCode": "def descendants_count(tree):\n    \"\"\"For every node, count its number of descendant leaves, and the number of leaves before it.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    left = [0] * n\n    desc = [0] * n\n    leaf_idx = 0\n    children = [list(tree.neighbors(node))[::-1] for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:",
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition in numpy.\"\"\"\n    xy = np.sum(x * y, 1, keepdims=True)\n    x2 = np.sum(x * x, 1, keepdims=True)\n    y2 = np.sum(y * y, 1, keepdims=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    den = 1 + 2 * xy + x2 * y2\n    return num / den\ndef mobius_mul(x, t):\n    \"\"\"Mobius multiplication in numpy.\"\"\"",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius multiplication in numpy.\"\"\"\n    normx = np.sqrt(np.sum(x * x, 1, keepdims=True)) \n    return np.tanh(t * np.arctanh(normx)) * x / normx \ndef geodesic_fn(x, y, nb_points=100):\n    \"\"\"Get coordinates of points on the geodesic between x and y.\"\"\"\n    t = np.linspace(0, 1, nb_points)\n    x_rep = np.repeat(x.reshape((1, -1)), len(t), 0)\n    y_rep = np.repeat(y.reshape((1, -1)), len(t), 0)\n    t1 = mobius_add(-x_rep, y_rep)",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "geodesic_fn",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def geodesic_fn(x, y, nb_points=100):\n    \"\"\"Get coordinates of points on the geodesic between x and y.\"\"\"\n    t = np.linspace(0, 1, nb_points)\n    x_rep = np.repeat(x.reshape((1, -1)), len(t), 0)\n    y_rep = np.repeat(y.reshape((1, -1)), len(t), 0)\n    t1 = mobius_add(-x_rep, y_rep)\n    t2 = mobius_mul(t1, t.reshape((-1, 1)))\n    return mobius_add(x_rep, t2)\ndef plot_geodesic(x, y, ax):\n    \"\"\"Plots geodesic between x and y.\"\"\"",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_geodesic",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def plot_geodesic(x, y, ax):\n    \"\"\"Plots geodesic between x and y.\"\"\"\n    points = geodesic_fn(x, y)\n    ax.plot(points[:, 0]*20, points[:, 1]*20, color='black', linewidth=1.5, alpha=1)\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)\n            if left_leaf and right_leaf:\n                pass",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"Computes the hyperbolic LCA in numpy.\"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"random color assignment for label classes.\"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()\n        colors[k] = (r, g, b)\n    return [colors[k] for k in y]",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves_djj_1",
        "kind": 2,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "def plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "alignment",
        "description": "alignment",
        "peekOfCode": "class node:\n    def __init__(self,value=None,son=[],name=''):\n        self.value = value;\n        self.son = son;\n        self.name =name;\n        self.f = None;\n        self.depth=0;\n        self.subson= [];\n    def __repr__(self):\n        return self.name",
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "tree_alignment",
        "kind": 6,
        "importPath": "alignment",
        "description": "alignment",
        "peekOfCode": "class tree_alignment:\n    def __init__(self,root1,root2,cost1):\n        self.cost1 = cost1;\n        self.dp = dict();\n        self.forestdp = dict();\n        self.anslist = [];\n        self.ansnodes = [];\n        self.root1 = root1;\n        self.root2 = root2;\n        self.minn = math.inf;",
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "show_graph",
        "kind": 6,
        "importPath": "alignment",
        "description": "alignment",
        "peekOfCode": "class show_graph:\n    def __init__(self,ans,root1,root2):\n        self.ans = ans;\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];",
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "show_tree",
        "kind": 6,
        "importPath": "alignment",
        "description": "alignment",
        "peekOfCode": "class show_tree:\n    def __init__(self,root1):\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];\n        self.cnt = 0;",
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment",
        "kind": 2,
        "importPath": "alignment",
        "description": "alignment",
        "peekOfCode": "def run_alignment(folder_path1,folder_path2):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    pos_2 = pd.read_csv(folder_path2+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    edge_2 = np.load(folder_path2+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    mer2 = np.load(folder_path2+\"datamerge.npy\");\n    n1 = len(pos_1)\n    n2 = len(pos_2)\n    root1 = -1;",
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "show_the_tree",
        "kind": 2,
        "importPath": "alignment",
        "description": "alignment",
        "peekOfCode": "def show_the_tree(folder_path1):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    n1 = len(pos_1)\n    root1 = -1;\n    for i,j in edge_1:\n        root1 = max(root1,i);\n    length1 = root1 + 1;    \n    nodes1 = [node(name=str(i),son=[]) for i in range(length1)]",
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "alignment_process",
        "kind": 2,
        "importPath": "core",
        "description": "core",
        "peekOfCode": "def alignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin=True,resolution=0.5,method='average'):\n    current_GMT = time.gmtime()\n    ts = calendar.timegm(current_GMT)\n    print(\"Current timestamp:\", ts)\n    log1 = open(folder_path1+\"log_{}.txt\".format(ts), \"a\")   \n    log2 = open(folder_path2+\"log_{}.txt\".format(ts), \"a\")\n    log1.write(\"args for data1: -cp1 {} -f1 {},-r1 {},-c1 {},-e {}\\n\".format(cell_path1,folder_path1,radius1,c1,epoches1))\n    log1.write(\"args for data2: -cp1 {} -f1 {},-r1 {},-c1 {},-e {}\\n\".format(cell_path2,folder_path2,radius2,c2,epoches2))\n    log2.write(\"args for data1: -cp1 {} -f1 {},-r1 {},-c1 {},-e {}\\n\".format(cell_path1,folder_path1,radius1,c1,epoches1))\n    log2.write(\"args for data2: -cp1 {} -f1 {},-r1 {},-c1 {},-e {}\\n\".format(cell_path2,folder_path2,radius2,c2,epoches2))",
        "detail": "core",
        "documentation": {}
    },
    {
        "label": {
            "name": "",
            "kind": 6,
            "peekOfCode": "class  UnionFind:\n    def __init__(self, n , pos):\n        self.n = n\n        self.pos = pos\n        # self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self.vis = [0 for i in range(2*n-1)]\n        self.vis2 = [0 for i in range(2*n-1)]\n        self.mer = [-1 for i in range(2*n-1)]"
        },
        "kind": 6,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "class  UnionFind:\n    def __init__(self, n , pos):\n        self.n = n\n        self.pos = pos\n        # self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self.vis = [0 for i in range(2*n-1)]\n        self.vis2 = [0 for i in range(2*n-1)]\n        self.mer = [-1 for i in range(2*n-1)]",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"Computes the hyperbolic LCA in numpy.\"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)\n            if left_leaf and right_leaf:\n                pass",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def train(model,dataloader,optimizer,similarities,epoches):\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n        total_loss = 0.0\n        # with tqdm(total=len(dataloader), unit='ex') as bar:\n        #     for step, (triple_ids, triple_similarities) in enumerate(dataloader):\n        #         # triple_ids = triple_ids.cuda()",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "dist",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def dist(x,y):\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));\ndef plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves_djj_1",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "sl_np_mst_ij",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def sl_np_mst_ij(xs, S):\n    xs = project(xs).detach().cpu()\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    similarities = sim_mat.numpy()\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst.mst(similarities, n)\n    return ij",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"random color assignment for label classes.\"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()\n        colors[k] = (r, g, b)\n    return [colors[k] for k in y]",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "search_merge_tree",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def search_merge_tree(now,ids,save_path,values,fathers):\n    fathers.append(ids);\n    values.append(now.name);\n    now_id = len(values)-1;\n    for son in now.son:\n        search_merge_tree(son,now_id,save_path,values,fathers)\ndef get_Hyper_tree(data_path,start,end,lable,epoches,model_path=None,save_path='./',c=-1):\n    np.random.seed(1234)\n    torch.manual_seed(1234)\n    # x, y_true, similarities = load_data('../../../cityu/HypHC/data/4_8/4_8.data',start,end,lable)",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "get_Hyper_tree",
        "kind": 2,
        "importPath": "hyper",
        "description": "hyper",
        "peekOfCode": "def get_Hyper_tree(data_path,start,end,lable,epoches,model_path=None,save_path='./',c=-1):\n    np.random.seed(1234)\n    torch.manual_seed(1234)\n    # x, y_true, similarities = load_data('../../../cityu/HypHC/data/4_8/4_8.data',start,end,lable)\n    x, y_true, similarities = load_data(data_path,start,end,lable)\n    print(\"{} length:{}\".format(data_path,len(y_true)));\n    dataset = HCDataset(x, y_true, similarities, num_samples=50000)\n    dataloader = data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n    model = HypHC(dataset.n_nodes, 2, 5e-2, 5e-2 ,0.999)\n    if(model_path==None or os.path.exists(model_path)==False):",
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "read_data",
        "description": "read_data",
        "peekOfCode": "def read_file(file_path, file_label):\n    '''\n    Read data with given path.\n    args:\n        file_path: file path.\n        file_label: the file label to raise exception.\n    return:\n        the read file.\n    '''\n    try:",
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "read_training_data",
        "kind": 2,
        "importPath": "read_data",
        "description": "read_data",
        "peekOfCode": "def read_training_data(sc_path,meta_path,marker,sc_nor,out_dir):\n    \"\"\"read sc data and meta information to train model.\n    args:\n        sc_path:    sc-rna data path.\n        meta_path:  meta data with cell type information path.\n        marker:     the marker gene list if provided or none.\n        sc_nor:     Boolean, true for using preprocessing on sc data.\n        out_path:   the dir to store the result files.\n    \"\"\"\n    warnings.filterwarnings(action='ignore', category=FutureWarning) ",
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "merge_by_radius",
        "kind": 2,
        "importPath": "read_data",
        "description": "read_data",
        "peekOfCode": "def merge_by_radius(cell_path,folder_path,radius,method='average'):\n    np.random.seed(1234)\n    datas = sc.read_h5ad(cell_path)\n    celltype = datas.obs['celltype']\n    datas = datas.to_df()\n    adata = datas.copy()\n    adata['Celltype']= list(celltype)\n    # adata.loc[list(celltype['Cell']), 'Celltype'] = list(celltype[celltype_column])\n    ans_value = []\n    ans_label = []",
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "build_hyper_tree",
        "kind": 2,
        "importPath": "read_data",
        "description": "read_data",
        "peekOfCode": "def build_hyper_tree(folder_path):\n    pos_1 = pd.read_csv(folder_path + 'datas.csv')\n    pos = pos_1.set_index(pos_1.columns[0]).values\n    edge = np.load(folder_path + \"datalink.npy\");\n    father_name = np.load(folder_path + \"dataxy.npy\")\n    father_name = father_name.astype(np.int)\n    n = len(edge)\n    n_points = len(pos);\n    nodes = [node(name=str(i),son=[]) for i in range(n)];\n    for i in range(n):",
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "search_tree",
        "kind": 2,
        "importPath": "read_data",
        "description": "read_data",
        "peekOfCode": "def search_tree(now,c,merge_list):\n    if(len(now.son) != 2):\n        return now;\n    lson = search_tree(now.son[0],c,merge_list);\n    now.son[0] = lson;\n    rson = search_tree(now.son[1],c,merge_list);\n    now.son[1] = rson\n    if(np.linalg.norm(lson.value-rson.value)<=c):\n        if(len(lson.son)>1 and len(rson.son)>1):\n            pass",
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('--cell_path1','-cp1', type=str)\nparser.add_argument('--folder_path1','-f1', type=str)\nparser.add_argument('--radius1','-r1', type=float,default=15)\nparser.add_argument('--capacity1','-c1', type=float,default=0.1)\nparser.add_argument('--epoches1','-e1', type=int,default=10)\nparser.add_argument('--cell_path2','-cp2', type=str)\nparser.add_argument('--folder_path2','-f2', type=str)\nparser.add_argument('--radius2','-r2', type=float,default=15)\nparser.add_argument('--capacity2','-c2', type=float,default=0.1)",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "args = parser.parse_args()\nif(args.cell_path1 ==None):\n    print(\"Please input the h5 file path for data 1\")\n    exit()\nif(args.cell_path2 ==None):\n    print(\"Please input the h5 file paht for data 2\")\n    exit()\nif(os.path.exists(args.cell_path1)==False):\n    print(\"Input correct path for data 1\")\nif(os.path.exists(args.cell_path2)==False):",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "cell_path1",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "cell_path1 = args.cell_path1\ncell_path2= args.cell_path2\nfolder_path1 = args.folder_path1\nfolder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "folder_path1",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "folder_path1 = args.folder_path1\nfolder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "folder_path2",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "folder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "radius1",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "radius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "radius2",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "radius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "c1",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "c1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "c2",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "c2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "epoches1",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "epoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "epoches2",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "epoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "contin",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "contin = args.contin\nmethod = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    },
    {
        "label": "method",
        "kind": 5,
        "importPath": "run_sc",
        "description": "run_sc",
        "peekOfCode": "method = args.method\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,contin,resolution=1,method)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "run_sc",
        "documentation": {}
    }
]