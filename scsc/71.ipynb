{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import *\n",
    "from hyper import *\n",
    "from alignment import *\n",
    "from datasets.preprecossing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"./datas/data1/data_cell.csv\").set_index(\"Unnamed: 0\")\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype  = cell_type1 = pd.read_csv(\"../../../capital/docs/tutorials/BRCA_EMTAB8107_CellMetainfo_table.tsv\",sep=\"\\t\")\n",
    "celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1 = datas.copy()\n",
    "adata1.loc[list(celltype['Cell']), 'Celltype'] = list(celltype['Celltype (minor-lineage)'])\n",
    "adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "ans_value = []\n",
    "ans_label = []\n",
    "true_label = [];\n",
    "now_labels = adata1['Celltype'].tolist();\n",
    "c= -71\n",
    "r= 10\n",
    "now_label = 0;\n",
    "now =  datas.values;\n",
    "while len(now) != 0:\n",
    "    rnd = np.random.randint(now.shape[0], size=1);\n",
    "    rand_choice = now[rnd, :].reshape(-1)\n",
    "    tree = KDTree(now);\n",
    "    indices = tree.query_ball_point(rand_choice,r)\n",
    "    points_within_k = now[indices]\n",
    "    now = now.tolist();\n",
    "    if(len(points_within_k)-1 < c):\n",
    "        for i in points_within_k:\n",
    "            ans_value.append(i.tolist())\n",
    "            ans_label.append(now_label);\n",
    "            now_label +=1\n",
    "            now.remove(i.tolist());\n",
    "            true_label.append(now_labels[int(rnd)])\n",
    "    else:\n",
    "        for i in points_within_k:\n",
    "            ans_value.append(i.tolist())\n",
    "            ans_label.append(now_label);\n",
    "            now.remove(i.tolist());            \n",
    "            true_label.append(now_labels[int(rnd)])\n",
    "        now_label+=1;\n",
    "    now = np.array(now);\n",
    "    print(\"remain length: {}\".format(len(now)))\n",
    "    # for i in points_within_k:\n",
    "    #     if(i == rand_choice).all():\n",
    "    #         continue;\n",
    "        \n",
    "    # now.remove(rand_choice)\n",
    "    # now.tolist().remove(rand_choice.tolist())\n",
    "    # now = np.array(now)\n",
    "    # break\n",
    "# rand_choice == now\n",
    "np.save('./datas/try/c_{}_r_{}_label.npy'.format(c,r),np.array(ans_label))\n",
    "np.save('./datas/try/c_{}_r_{}_value.npy'.format(c,r),np.array(ans_value))\n",
    "np.save('./datas/try/c_{}_r_{}_true.npy'.format(c,r),np.array(true_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.DataFrame(ans_value)\n",
    "v['label'] = ans_label\n",
    "ann1  = v.groupby(\"label\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.DataFrame(true_label)\n",
    "v1['label'] = ans_label\n",
    "meta1 = v1.groupby(\"label\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(v1['label'])\n",
    "correct = 0;\n",
    "for i in range(len(v1['label'])):\n",
    "    # print(v1['label'][i]);\n",
    "    # print(v1[0][i])\n",
    "    if(v1[0][i] == meta1[0][v1['label'][i]]):\n",
    "        correct+=1;\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann2 = ann1.copy()\n",
    "ann2.index = meta1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1.to_csv('./datas/72/datas.data',header=None)\n",
    "ann1.to_csv('./datas/72/datas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_true, similarities = load_data('./datas/72/datas.data',1,514,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_true, similarities = load_data('./datas/72/datas.data',1,514,0)\n",
    "data_path = './datas/72/datas.data'\n",
    "start = 1\n",
    "end =514\n",
    "lable = 0\n",
    "model_path = None;\n",
    "save_path = './datas/72/'\n",
    "epoches=10\n",
    "c=-1\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "# x, y_true, similarities = load_data('../../../cityu/HypHC/data/4_8/4_8.data',start,end,lable)\n",
    "# x, y_true, similarities = load_data(data_path,start,end,lable)\n",
    "print(\"{} length:{}\".format(data_path,len(y_true)));\n",
    "dataset = HCDataset(x, y_true, similarities, num_samples=50000)\n",
    "dataloader = data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "if(model_path ==None):\n",
    "    model = HypHC(dataset.n_nodes, 2, 5e-2, 5e-2 ,0.999)\n",
    "    model.to(\"cpu\")\n",
    "    Optimizer = getattr(optim, 'RAdam')\n",
    "    optimizer = Optimizer(model.parameters(),0.0005)\n",
    "    train(model,dataloader,optimizer,similarities,epoches);\n",
    "    torch.save(model,save_path+'model.pth');\n",
    "else:\n",
    "    params = torch.load((model_path), map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(params, strict=False)\n",
    "model.eval()\n",
    "sim_fn = lambda x, y: torch.sum(x * y, dim=-1)\n",
    "n=len(x);\n",
    "d = model.normalize_embeddings(model.embeddings.weight.data)\n",
    "d = project(d).detach().cpu()\n",
    "ijs = sl_np_mst_ij(d,sim_fn)\n",
    "uf = UnionFind(n,d,c)\n",
    "uf.merge(ijs)\n",
    "count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = nx.DiGraph()\n",
    "for i, j in enumerate(uf.tree()[:-1]):\n",
    "    if(j!=-1):\n",
    "        tree.add_edge(j, i)\n",
    "        \n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_subplot(111)\n",
    "circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n",
    "ax.add_artist(circle)\n",
    "\n",
    "n = len(d)\n",
    "embeddings = np.array(uf.pos)\n",
    "# for i in range(len(embeddings)):\n",
    "#     if(np.isnan(embeddings[i][0]) or embeddings[i][0] + embeddings[i][1] == 0):\n",
    "#         embeddings[i] = embeddings[i-1];\n",
    "#     pass;\n",
    "# print(embeddings)\n",
    "where_are_NaNs = np.isnan(embeddings)\n",
    "embeddings[where_are_NaNs] = 0\n",
    "vis = uf.vis\n",
    "# xlist=[]\n",
    "# ylist=[]\n",
    "# labels=[]\n",
    "\n",
    "# for i in range(n):\n",
    "#     if(uf.vis[i]!=1):\n",
    "#         xlist.append(embeddings[i,0]*20);\n",
    "#         ylist.append(embeddings[i,1]*20);\n",
    "#         labels.append(y_true[i]);\n",
    "# # colors = get_colors(labels, 1234)\n",
    "colors = get_colors(y_true, 1234)\n",
    "\n",
    "# ax.scatter(xlist, ylist, c=colors, s=50, alpha=0.6)\n",
    "\n",
    "ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if(i<n):\n",
    "        continue;\n",
    "    if(uf.mer[i]!=-1):\n",
    "        # print(i,'pass')\n",
    "        pass;\n",
    "    else:\n",
    "        ax.scatter(embeddings[i][0]*20,embeddings[i][1]*20,color='black',s=20,alpha=0.7)\n",
    "\n",
    "    \n",
    "\n",
    "for n1, n2 in tree.edges():\n",
    "#     if(uf.vis[n1]== 1 or uf.vis[n2]== 1 ):\n",
    "# #         print(\"1\")\n",
    "#         pass\n",
    "#     else:\n",
    "#         x1 = embeddings[n1]\n",
    "#         x2 = embeddings[n2]\n",
    "# #         if(n1>=n):\n",
    "# #             if(uf.mer[n1]!=-1):\n",
    "# #                 pass;\n",
    "# #             else:\n",
    "# #                 count+=1;\n",
    "# #         if(n2>n):\n",
    "# #             if(uf.mer[n1]!=-1):\n",
    "# # # \n",
    "# #                 pass;\n",
    "# #             else:\n",
    "# # #                 ax.scatter(x2[0]*20,x2[1]*20,color='black',s=20,alpha=0.7)\n",
    "# #                 count+=1\n",
    "    \n",
    "    \n",
    "#         plot_geodesic(x1, x2, ax)\n",
    "# #         print(x1,x2,n1,n2)\n",
    "# #         break\n",
    "#         pass\n",
    "\n",
    "#     ax.axis(\"off\")\n",
    "    x1 = embeddings[n1];\n",
    "    x2 = embeddings[n2];\n",
    "    plot_geodesic(x1,x2,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alignment import node\n",
    "from alignment import show_tree\n",
    "embeddings = np.array(uf.pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes1 = [node(name=str(i),son=[]) for i in range(len(uf.tree()))]\n",
    "for i,j in enumerate(uf.tree()):\n",
    "    if(j!=-1):\n",
    "        nodes1[j].son.append(nodes1[i])\n",
    "    nodes1[i].value=embeddings[i];\n",
    "    nodes1[i].subson=0\n",
    "    # if(i==49):\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree(now,c):\n",
    "    \n",
    "    if(len(now.son) != 2):\n",
    "        return now;\n",
    "    lson = search_tree(now.son[0],c);\n",
    "    now.son[0] = lson;\n",
    "    rson = search_tree(now.son[1],c);\n",
    "    now.son[1] = rson\n",
    "    # lson = now.son[0]\n",
    "    # rson = now.son[1]\n",
    "    if(np.linalg.norm(lson.value-rson.value)<=c):\n",
    "        if(len(lson.son)>1 and len(rson.son)>1):\n",
    "            pass\n",
    "        elif(len(lson.son)>1):\n",
    "            print(rson.name,lson.name)\n",
    "            now = rson;\n",
    "            now.son.append(lson);\n",
    "        else:\n",
    "            print(rson.name,lson.name)\n",
    "            now = lson;\n",
    "            now.son.append(rson)\n",
    "    # exit(0)\n",
    "    return now;\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes1 = [node(name=str(i),son=[]) for i in range(len(uf.tree()))]\n",
    "for i,j in enumerate(uf.tree()):\n",
    "    if(j!=-1):\n",
    "        nodes1[j].son.append(nodes1[i])\n",
    "    nodes1[i].value=embeddings[i];\n",
    "    nodes1[i].subson=0\n",
    "    # if(i==49):\n",
    "    #     break\n",
    "# show_tree(nodes1[-1]).show_fig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes1 = [node(name=str(i),son=[]) for i in range(len(uf.tree()))]\n",
    "for i,j in enumerate(uf.tree()):\n",
    "    if(j!=-1):\n",
    "        nodes1[j].son.append(nodes1[i])\n",
    "    nodes1[i].value=embeddings[i];\n",
    "    nodes1[i].subson=0\n",
    "    # if(i==49):\n",
    "    #     break\n",
    "# show_tree(nodes1[-1]).show_fig()\n",
    "\n",
    "root  = search_tree(nodes1[-1],0.001)\n",
    "# show_tree(root).show_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [];\n",
    "fathers = [];\n",
    "save_path = \"./datas/72/\"\n",
    "def search_merge_tree(now,ids,save_path,values,fathers):\n",
    "    fathers.append(ids);\n",
    "    values.append(now.name);\n",
    "    now_id = len(values)-1;\n",
    "    for son in now.son:\n",
    "        search_merge_tree(son,now_id,save_path,values,fathers)\n",
    "search_merge_tree(root,-1,0,values,fathers)\n",
    "np.save(save_path+\"dataxy.npy\",values)\n",
    "np.save(save_path+\"datalink.npy\",fathers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"./datas/data2/data_cell.csv\").set_index(\"Unnamed: 0\")\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype  = cell_type1 = pd.read_csv(\"../../../capital/docs/tutorials/BRCA_GSE114727_inDrop_CellMetainfo_table.tsv\",sep=\"\\t\")\n",
    "celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1 = datas.copy()\n",
    "adata1.loc[list(celltype['Cell']), 'Celltype'] = list(celltype['Celltype (minor-lineage)'])\n",
    "adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2]\n",
    "a.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "ans_value = []\n",
    "ans_label = []\n",
    "true_label = [];\n",
    "now_labels = adata1['Celltype'].tolist();\n",
    "c= -73\n",
    "r= 8\n",
    "now_label = 0;\n",
    "now =  datas.values;\n",
    "while len(now) != 0:\n",
    "    rnd = np.random.randint(now.shape[0], size=1);\n",
    "    rand_choice = now[rnd, :].reshape(-1)\n",
    "    tree = KDTree(now);\n",
    "    indices = tree.query_ball_point(rand_choice,r)\n",
    "    points_within_k = now[indices]\n",
    "    now = now.tolist();\n",
    "    if(len(points_within_k)-1 < c):\n",
    "        for i in points_within_k:\n",
    "            ans_value.append(i.tolist())\n",
    "            ans_label.append(now_label);\n",
    "            now_label +=1\n",
    "            now.remove(i.tolist());\n",
    "            true_label.append(now_labels[i])\n",
    "    else:\n",
    "        for i in points_within_k:\n",
    "            ans_value.append(i.tolist())\n",
    "            ans_label.append(now_label);\n",
    "            index = now.index(i.tolist());\n",
    "            true_label.append(now_labels[index]);\n",
    "            now.remove(now[index]);            \n",
    "            now_labels.remove(now_labels[index])\n",
    "        now_label+=1;\n",
    "    # for i in range(len(points_within_k)):\n",
    "        \n",
    "    now = np.array(now);\n",
    "    print(\"remain length: {}\".format(len(now)))\n",
    "    # for i in points_within_k:\n",
    "    #     if(i == rand_choice).all():\n",
    "    #         continue;\n",
    "        \n",
    "    # now.remove(rand_choice)\n",
    "    # now.tolist().remove(rand_choice.tolist())\n",
    "    # now = np.array(now)\n",
    "    # break\n",
    "# rand_choice == now\n",
    "np.save('./datas/try/c_{}_r_{}_label.npy'.format(c,r),np.array(ans_label))\n",
    "np.save('./datas/try/c_{}_r_{}_value.npy'.format(c,r),np.array(ans_value))\n",
    "np.save('./datas/try/c_{}_r_{}_true.npy'.format(c,r),np.array(true_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.DataFrame(ans_value)\n",
    "v['label'] = ans_label\n",
    "ann1  = v.groupby(\"label\").mean()\n",
    "ann1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.DataFrame(true_label)\n",
    "v1['label'] = ans_label\n",
    "meta1 = v1.groupby(\"label\").max()\n",
    "meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v1.groupby(\"label\").describe()[0]['count'] - v1.groupby(\"label\").describe()[0]['freq']).sum() / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1.to_csv('./datas/73/datas.data',header=None)\n",
    "ann1.to_csv('./datas/73/datas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_true, similarities = load_data('./datas/73/datas.data',1,514,0)\n",
    "data_path = './datas/73/datas.data'\n",
    "start = 1\n",
    "end =514\n",
    "lable = 0\n",
    "model_path = None;\n",
    "save_path = './datas/73/'\n",
    "epoches=10\n",
    "c=-1\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "# x, y_true, similarities = load_data('../../../cityu/HypHC/data/4_8/4_8.data',start,end,lable)\n",
    "# x, y_true, similarities = load_data(data_path,start,end,lable)\n",
    "print(\"{} length:{}\".format(data_path,len(y_true)));\n",
    "dataset = HCDataset(x, y_true, similarities, num_samples=50000)\n",
    "dataloader = data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "if(model_path ==None):\n",
    "    model = HypHC(dataset.n_nodes, 2, 5e-2, 5e-2 ,0.999)\n",
    "    model.to(\"cpu\")\n",
    "    Optimizer = getattr(optim, 'RAdam')\n",
    "    optimizer = Optimizer(model.parameters(),0.0005)\n",
    "    train(model,dataloader,optimizer,similarities,epoches);\n",
    "    torch.save(model,save_path+'model.pth');\n",
    "else:\n",
    "    params = torch.load((model_path), map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(params, strict=False)\n",
    "model.eval()\n",
    "sim_fn = lambda x, y: torch.sum(x * y, dim=-1)\n",
    "n=len(x);\n",
    "d = model.normalize_embeddings(model.embeddings.weight.data)\n",
    "d = project(d).detach().cpu()\n",
    "ijs = sl_np_mst_ij(d,sim_fn)\n",
    "uf = UnionFind(n,d,c)\n",
    "uf.merge(ijs)\n",
    "count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = nx.DiGraph()\n",
    "for i, j in enumerate(uf.tree()[:-1]):\n",
    "    if(j!=-1):\n",
    "        tree.add_edge(j, i)\n",
    "        \n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_subplot(111)\n",
    "circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n",
    "ax.add_artist(circle)\n",
    "\n",
    "n = len(d)\n",
    "embeddings = np.array(uf.pos)\n",
    "# for i in range(len(embeddings)):\n",
    "#     if(np.isnan(embeddings[i][0]) or embeddings[i][0] + embeddings[i][1] == 0):\n",
    "#         embeddings[i] = embeddings[i-1];\n",
    "#     pass;\n",
    "# print(embeddings)\n",
    "where_are_NaNs = np.isnan(embeddings)\n",
    "embeddings[where_are_NaNs] = 0\n",
    "vis = uf.vis\n",
    "# xlist=[]\n",
    "# ylist=[]\n",
    "# labels=[]\n",
    "\n",
    "# for i in range(n):\n",
    "#     if(uf.vis[i]!=1):\n",
    "#         xlist.append(embeddings[i,0]*20);\n",
    "#         ylist.append(embeddings[i,1]*20);\n",
    "#         labels.append(y_true[i]);\n",
    "# # colors = get_colors(labels, 1234)\n",
    "colors = get_colors(y_true, 1234)\n",
    "\n",
    "# ax.scatter(xlist, ylist, c=colors, s=50, alpha=0.6)\n",
    "\n",
    "ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if(i<n):\n",
    "        continue;\n",
    "    if(uf.mer[i]!=-1):\n",
    "        # print(i,'pass')\n",
    "        pass;\n",
    "    else:\n",
    "        ax.scatter(embeddings[i][0]*20,embeddings[i][1]*20,color='black',s=20,alpha=0.7)\n",
    "\n",
    "    \n",
    "\n",
    "for n1, n2 in tree.edges():\n",
    "#     if(uf.vis[n1]== 1 or uf.vis[n2]== 1 ):\n",
    "# #         print(\"1\")\n",
    "#         pass\n",
    "#     else:\n",
    "#         x1 = embeddings[n1]\n",
    "#         x2 = embeddings[n2]\n",
    "# #         if(n1>=n):\n",
    "# #             if(uf.mer[n1]!=-1):\n",
    "# #                 pass;\n",
    "# #             else:\n",
    "# #                 count+=1;\n",
    "# #         if(n2>n):\n",
    "# #             if(uf.mer[n1]!=-1):\n",
    "# # # \n",
    "# #                 pass;\n",
    "# #             else:\n",
    "# # #                 ax.scatter(x2[0]*20,x2[1]*20,color='black',s=20,alpha=0.7)\n",
    "# #                 count+=1\n",
    "    \n",
    "    \n",
    "#         plot_geodesic(x1, x2, ax)\n",
    "# #         print(x1,x2,n1,n2)\n",
    "# #         break\n",
    "#         pass\n",
    "\n",
    "#     ax.axis(\"off\")\n",
    "    x1 = embeddings[n1];\n",
    "    x2 = embeddings[n2];\n",
    "    plot_geodesic(x1,x2,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alignment import node\n",
    "from alignment import show_tree\n",
    "embeddings = np.array(uf.pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree(now,c,merge_list):\n",
    "    \n",
    "    if(len(now.son) != 2):\n",
    "        return now;\n",
    "    lson = search_tree(now.son[0],c,merge_list);\n",
    "    now.son[0] = lson;\n",
    "    rson = search_tree(now.son[1],c,merge_list);\n",
    "    now.son[1] = rson\n",
    "    # lson = now.son[0]\n",
    "    # rson = now.son[1]\n",
    "    if(np.linalg.norm(lson.value-rson.value)<=c):\n",
    "        if(len(lson.son)>1 and len(rson.son)>1):\n",
    "            pass\n",
    "        elif(len(lson.son)>1):\n",
    "            merge_list.append((rson.name,lson.name))\n",
    "            print(rson.name,lson.name)\n",
    "            now = rson;\n",
    "            now.son.append(lson);\n",
    "        else:\n",
    "            merge_list.append((rson.name,lson.name))\n",
    "            print(rson.name,lson.name)\n",
    "            now = lson;\n",
    "            now.son.append(rson)\n",
    "    # exit(0)\n",
    "    return now;\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes1 = [node(name=str(i),son=[]) for i in range(len(uf.tree()))]\n",
    "for i,j in enumerate(uf.tree()):\n",
    "    if(j!=-1):\n",
    "        nodes1[j].son.append(nodes1[i])\n",
    "    nodes1[i].value=embeddings[i];\n",
    "    nodes1[i].subson=0\n",
    "    # if(i==49):\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes1 = [node(name=str(i),son=[]) for i in range(len(uf.tree()))]\n",
    "for i,j in enumerate(uf.tree()):\n",
    "    if(j!=-1):\n",
    "        nodes1[j].son.append(nodes1[i])\n",
    "    nodes1[i].value=embeddings[i];\n",
    "    nodes1[i].subson=0\n",
    "    # if(i==49):\n",
    "    #     break\n",
    "# show_tree(nodes1[-1]).show_fig()\n",
    "ans_list = []\n",
    "root  = search_tree(nodes1[-1],0.001,ans_list)\n",
    "# show_tree(root).show_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union =0\n",
    "inter=0\n",
    "for j in range(len(ans_list)):\n",
    "    \n",
    "    l = ans_list[j][0]\n",
    "    l = list(adata1.obs[adata1.obs['leiden']==l]['celltype'])\n",
    "    r = ans_list[j][1]\n",
    "    r = list(adata1.obs[adata1.obs['leiden']==r]['celltype'])\n",
    "    inter += len(l)+len(r);\n",
    "    for i in l:\n",
    "        if(r.__contains__(i)):\n",
    "            union +=1;\n",
    "            r.remove(i)\n",
    "\n",
    "2*union / inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [];\n",
    "fathers = [];\n",
    "save_path = \"./datas/73/\"\n",
    "def search_merge_tree(now,ids,save_path,values,fathers):\n",
    "    fathers.append(ids);\n",
    "    values.append(now.name);\n",
    "    now_id = len(values)-1;\n",
    "    for son in now.son:\n",
    "        search_merge_tree(son,now_id,save_path,values,fathers)\n",
    "search_merge_tree(root,-1,0,values,fathers)\n",
    "np.save(save_path+\"dataxy.npy\",values)\n",
    "np.save(save_path+\"datalink.npy\",fathers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Mar  1 2023, 21:19:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6f9107c7570fe5c9625bfb2661451db78c34fa5b495f83483e2a28949c1d386"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
