[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "anndata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "anndata",
        "description": "anndata",
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "AnnData",
        "importPath": "anndata",
        "description": "anndata",
        "isExtraImport": true,
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "AnnData",
        "importPath": "anndata",
        "description": "anndata",
        "isExtraImport": true,
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "AnnData",
        "importPath": "anndata",
        "description": "anndata",
        "isExtraImport": true,
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "AnnData",
        "importPath": "anndata",
        "description": "anndata",
        "isExtraImport": true,
        "detail": "anndata",
        "documentation": {}
    },
    {
        "label": "scanpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scanpy",
        "description": "scanpy",
        "detail": "scanpy",
        "documentation": {}
    },
    {
        "label": "scipy.sparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csr_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "issparse",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csr_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "issparse",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csr_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csc_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "isspmatrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "issparse",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csr_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csc_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csr_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csr_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "cell2location",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cell2location",
        "description": "cell2location",
        "detail": "cell2location",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "filter_genes",
        "importPath": "cell2location.utils.filtering",
        "description": "cell2location.utils.filtering",
        "isExtraImport": true,
        "detail": "cell2location.utils.filtering",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "choice",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "choice",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "choice",
        "importPath": "numpy.random",
        "description": "numpy.random",
        "isExtraImport": true,
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "LinearSegmentedColormap",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "to_hex",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "to_rgb",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "to_rgba",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "LinearSegmentedColormap",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "to_hex",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "to_rgb",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "to_rgba",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "matplotlib.patches",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "rpy2.robjects",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rpy2.robjects",
        "description": "rpy2.robjects",
        "detail": "rpy2.robjects",
        "documentation": {}
    },
    {
        "label": "pandas2ri",
        "importPath": "rpy2.robjects",
        "description": "rpy2.robjects",
        "isExtraImport": true,
        "detail": "rpy2.robjects",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "cpu_count",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "pearsonr",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "pearsonr",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "inplace_column_scale",
        "importPath": "sklearn.utils.sparsefuncs",
        "description": "sklearn.utils.sparsefuncs",
        "isExtraImport": true,
        "detail": "sklearn.utils.sparsefuncs",
        "documentation": {}
    },
    {
        "label": "inplace_row_scale",
        "importPath": "sklearn.utils.sparsefuncs",
        "description": "sklearn.utils.sparsefuncs",
        "isExtraImport": true,
        "detail": "sklearn.utils.sparsefuncs",
        "documentation": {}
    },
    {
        "label": "inplace_column_scale",
        "importPath": "sklearn.utils.sparsefuncs",
        "description": "sklearn.utils.sparsefuncs",
        "isExtraImport": true,
        "detail": "sklearn.utils.sparsefuncs",
        "documentation": {}
    },
    {
        "label": "inplace_row_scale",
        "importPath": "sklearn.utils.sparsefuncs",
        "description": "sklearn.utils.sparsefuncs",
        "isExtraImport": true,
        "detail": "sklearn.utils.sparsefuncs",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "numba",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numba",
        "description": "numba",
        "detail": "numba",
        "documentation": {}
    },
    {
        "label": "njit",
        "importPath": "numba",
        "description": "numba",
        "isExtraImport": true,
        "detail": "numba",
        "documentation": {}
    },
    {
        "label": "prange",
        "importPath": "numba",
        "description": "numba",
        "isExtraImport": true,
        "detail": "numba",
        "documentation": {}
    },
    {
        "label": "njit",
        "importPath": "numba",
        "description": "numba",
        "isExtraImport": true,
        "detail": "numba",
        "documentation": {}
    },
    {
        "label": "prange",
        "importPath": "numba",
        "description": "numba",
        "isExtraImport": true,
        "detail": "numba",
        "documentation": {}
    },
    {
        "label": "anndata._core.views",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "anndata._core.views",
        "description": "anndata._core.views",
        "detail": "anndata._core.views",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "scipy.spatial",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "tarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tarfile",
        "description": "tarfile",
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "nnls",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "cytobulk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cytobulk",
        "description": "cytobulk",
        "detail": "cytobulk",
        "documentation": {}
    },
    {
        "label": "ascii_uppercase",
        "importPath": "string",
        "description": "string",
        "isExtraImport": true,
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "ascii_uppercase",
        "importPath": "string",
        "description": "string",
        "isExtraImport": true,
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "ascii_uppercase",
        "importPath": "string",
        "description": "string",
        "isExtraImport": true,
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "importPath": "datasets.triples",
        "description": "datasets.triples",
        "isExtraImport": true,
        "detail": "datasets.triples",
        "documentation": {}
    },
    {
        "label": "scanpy.external",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scanpy.external",
        "description": "scanpy.external",
        "detail": "scanpy.external",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "alignment",
        "description": "alignment",
        "isExtraImport": true,
        "detail": "alignment",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_djj",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_djj",
        "importPath": "utils.poincare",
        "description": "utils.poincare",
        "isExtraImport": true,
        "detail": "utils.poincare",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "importPath": "utils.lca",
        "description": "utils.lca",
        "isExtraImport": true,
        "detail": "utils.lca",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "importPath": "utils.linkage",
        "description": "utils.linkage",
        "isExtraImport": true,
        "detail": "utils.linkage",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "utils.unionfind",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "utils.unionfind",
        "description": "utils.unionfind",
        "detail": "utils.unionfind",
        "documentation": {}
    },
    {
        "label": "UnionFind",
        "importPath": "utils.unionfind",
        "description": "utils.unionfind",
        "isExtraImport": true,
        "detail": "utils.unionfind",
        "documentation": {}
    },
    {
        "label": "UnionFind",
        "importPath": "utils.unionfind",
        "description": "utils.unionfind",
        "isExtraImport": true,
        "detail": "utils.unionfind",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "utils.mst",
        "description": "utils.mst",
        "isExtraImport": true,
        "detail": "utils.mst",
        "documentation": {}
    },
    {
        "label": "reorder",
        "importPath": "utils.mst",
        "description": "utils.mst",
        "isExtraImport": true,
        "detail": "utils.mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "utils.mst",
        "description": "utils.mst",
        "isExtraImport": true,
        "detail": "utils.mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "utils.mst",
        "description": "utils.mst",
        "isExtraImport": true,
        "detail": "utils.mst",
        "documentation": {}
    },
    {
        "label": "reorder",
        "importPath": "utils.mst",
        "description": "utils.mst",
        "isExtraImport": true,
        "detail": "utils.mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "utils.mst",
        "description": "utils.mst",
        "isExtraImport": true,
        "detail": "utils.mst",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "importPath": "utils.tree",
        "description": "utils.tree",
        "isExtraImport": true,
        "detail": "utils.tree",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "importPath": "utils.math",
        "description": "utils.math",
        "isExtraImport": true,
        "detail": "utils.math",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "plotly.graph_objs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "plotly.graph_objs",
        "description": "plotly.graph_objs",
        "detail": "plotly.graph_objs",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "pulp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pulp",
        "description": "pulp",
        "detail": "pulp",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "hyper",
        "description": "hyper",
        "isExtraImport": true,
        "detail": "hyper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "datasets.preprecossing",
        "description": "datasets.preprecossing",
        "isExtraImport": true,
        "detail": "datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "calendar",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "calendar",
        "description": "calendar",
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "optim",
        "description": "optim",
        "detail": "optim",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "importPath": "datasets.hc_dataset",
        "description": "datasets.hc_dataset",
        "isExtraImport": true,
        "detail": "datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "importPath": "datasets.hc_dataset",
        "description": "datasets.hc_dataset",
        "isExtraImport": true,
        "detail": "datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "importPath": "datasets.hc_dataset",
        "description": "datasets.hc_dataset",
        "isExtraImport": true,
        "detail": "datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "importPath": "datasets.hc_dataset",
        "description": "datasets.hc_dataset",
        "isExtraImport": true,
        "detail": "datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "balance_dataset",
        "importPath": "datasets.balance_dataset",
        "description": "datasets.balance_dataset",
        "isExtraImport": true,
        "detail": "datasets.balance_dataset",
        "documentation": {}
    },
    {
        "label": "balance_dataset",
        "importPath": "datasets.balance_dataset",
        "description": "datasets.balance_dataset",
        "isExtraImport": true,
        "detail": "datasets.balance_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "isExtraImport": true,
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "isExtraImport": true,
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "isExtraImport": true,
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "datasets.loading",
        "description": "datasets.loading",
        "isExtraImport": true,
        "detail": "datasets.loading",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "importPath": "model.hyphc",
        "description": "model.hyphc",
        "isExtraImport": true,
        "detail": "model.hyphc",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "importPath": "model.hyphc",
        "description": "model.hyphc",
        "isExtraImport": true,
        "detail": "model.hyphc",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "importPath": "model.hyphc",
        "description": "model.hyphc",
        "isExtraImport": true,
        "detail": "model.hyphc",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "importPath": "model.hyphc",
        "description": "model.hyphc",
        "isExtraImport": true,
        "detail": "model.hyphc",
        "documentation": {}
    },
    {
        "label": "balancehc",
        "importPath": "model.balancehc",
        "description": "model.balancehc",
        "isExtraImport": true,
        "detail": "model.balancehc",
        "documentation": {}
    },
    {
        "label": "balancehc",
        "importPath": "model.balancehc",
        "description": "model.balancehc",
        "isExtraImport": true,
        "detail": "model.balancehc",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "core",
        "description": "core",
        "isExtraImport": true,
        "detail": "core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "core",
        "description": "core",
        "isExtraImport": true,
        "detail": "core",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "mst",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mst",
        "description": "mst",
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "mst",
        "importPath": "mst",
        "description": "mst",
        "isExtraImport": true,
        "detail": "mst",
        "documentation": {}
    },
    {
        "label": "unionfind",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unionfind",
        "description": "unionfind",
        "detail": "unionfind",
        "documentation": {}
    },
    {
        "label": "unionfind",
        "importPath": "unionfind",
        "description": "unionfind",
        "isExtraImport": true,
        "detail": "unionfind",
        "documentation": {}
    },
    {
        "label": "unionfind",
        "importPath": "unionfind",
        "description": "unionfind",
        "isExtraImport": true,
        "detail": "unionfind",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "read_data",
        "description": "read_data",
        "isExtraImport": true,
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "read_data",
        "description": "read_data",
        "isExtraImport": true,
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "read_data",
        "description": "read_data",
        "isExtraImport": true,
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "read_data",
        "description": "read_data",
        "isExtraImport": true,
        "detail": "read_data",
        "documentation": {}
    },
    {
        "label": "add_flags_from_config",
        "importPath": "utils.training",
        "description": "utils.training",
        "isExtraImport": true,
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "get_savedir",
        "importPath": "utils.training",
        "description": "utils.training",
        "isExtraImport": true,
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "add_flags_from_config",
        "importPath": "utils.training",
        "description": "utils.training",
        "isExtraImport": true,
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "get_savedir",
        "importPath": "utils.training",
        "description": "utils.training",
        "isExtraImport": true,
        "detail": "utils.training",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_geodesic",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_geodesic",
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "isExtraImport": true,
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "run_cell2location",
        "kind": 2,
        "importPath": "CytoBulk.analysis.st_deconv.stcell2",
        "description": "CytoBulk.analysis.st_deconv.stcell2",
        "peekOfCode": "def run_cell2location(sc_adata,st_adata,project,ref_run_name,run_name):\n    print(\"data\")\n    selected = filter_genes(sc_adata, cell_count_cutoff=5, cell_percentage_cutoff2=0.03, nonz_mean_cutoff=1.12)\n    sc_adata = sc_adata[:, selected].copy()\n    cell2location.models.RegressionModel.setup_anndata(adata=sc_adata,\n                        # cell type, covariate used for constructing signatures\n                        labels_key='Celltype_minor'\n                       )\n    mod = cell2location.models.RegressionModel(sc_adata)\n    mod.view_anndata_setup()",
        "detail": "CytoBulk.analysis.st_deconv.stcell2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "CytoBulk.analysis.st_deconv.stcell2",
        "description": "CytoBulk.analysis.st_deconv.stcell2",
        "peekOfCode": "def main():\n    project_list = [\"NSCLC_GSE179373\",\"KIRC_GSE121636\",\"HNSC_GSE139324\"]\n    for i in project_list:\n      st_data = f\"/data1/wangxueying/cytobulk/eval_data/{i}/{i}_expression_test.csv\"\n      st_meta = f\"/data1/wangxueying/cytobulk/eval_data/{i}/meta_test.csv\"\n      sc_adata = f\"/data1/wangxueying/cytobulk/eval_data/{i}/{i}_sc_data_cell2.txt\"\n      sc_meta = f\"/data1/wangxueying/cytobulk/eval_data/{i}/{i}_sc_meta.txt\"\n      project = i\n      results_folder = f\"/data1/wangxueying/cytobulk/out/{i}/cell2\"\n      #st_adata = sc.read_visium(st_adata,library_id=\"st\")",
        "detail": "CytoBulk.analysis.st_deconv.stcell2",
        "documentation": {}
    },
    {
        "label": "get_count_data",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.get._counts",
        "description": "CytoBulk.cytobulk.get._counts",
        "peekOfCode": "def get_count_data(adata,counts_location=None):\n    data = adata.layers[counts_location].copy() if counts_location else adata.X.copy()\n    if not isinstance(data, np.ndarray):\n        data= data.toarray()\n    data_df = pd.DataFrame(data,index=adata.obs_names,columns=adata.var_names).transpose()\n    return data_df\ndef get_count_data_t(adata,counts_location=None):\n    data = adata.layers[counts_location].copy() if counts_location else adata.X.copy()\n    if not isinstance(data, np.ndarray):\n        data= data.toarray()",
        "detail": "CytoBulk.cytobulk.get._counts",
        "documentation": {}
    },
    {
        "label": "get_count_data_t",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.get._counts",
        "description": "CytoBulk.cytobulk.get._counts",
        "peekOfCode": "def get_count_data_t(adata,counts_location=None):\n    data = adata.layers[counts_location].copy() if counts_location else adata.X.copy()\n    if not isinstance(data, np.ndarray):\n        data= data.toarray()\n    return pd.DataFrame(data,index=adata.obs_names,columns=adata.var_names)",
        "detail": "CytoBulk.cytobulk.get._counts",
        "documentation": {}
    },
    {
        "label": "get_meta",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.get._meta",
        "description": "CytoBulk.cytobulk.get._meta",
        "peekOfCode": "def get_meta(\n    adata,\n    position_key=\"obs\",\n    columns=None\n):\n    \"\"\"\n    Get an :class:`~pandas.DataFrame` with the positions of the observations.\n    Parameters\n    ----------\n    adata",
        "detail": "CytoBulk.cytobulk.get._meta",
        "documentation": {}
    },
    {
        "label": "get_coords",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.get._meta",
        "description": "CytoBulk.cytobulk.get._meta",
        "peekOfCode": "def get_coords(visium_adata):\n    df_coords = visium_adata.obs[['array_row', 'array_col']]\n    df_coords.columns = ['row','col']\n    df_coords.index.name = 'SpotID'\n    return df_coords",
        "detail": "CytoBulk.cytobulk.get._meta",
        "documentation": {}
    },
    {
        "label": "Const",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.plots._eval_plot",
        "description": "CytoBulk.cytobulk.plots._eval_plot",
        "peekOfCode": "class Const:\n    \"\"\"\n    Some COLOR SET used in the class.\n    \"\"\"\n    COLOR_BLUE = ['#191970','#ADD8E6','#22AAA1']\n    DIFF_COLOR_GRAY = ['#474350','#FAFAC6']\n    FIG_FORMAT = 'svg'\ndef plot_mse_box(ground_truth,df_list,name_list,title,num_column=6,skipping_mse_calculation=False,\n                color_set=Const.COLOR_BLUE,fig_format=None,out_dir='/out',filter_list=None,save=True):\n    sns.set(font_scale=0.8,style=\"white\")",
        "detail": "CytoBulk.cytobulk.plots._eval_plot",
        "documentation": {}
    },
    {
        "label": "plot_mse_box",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.plots._eval_plot",
        "description": "CytoBulk.cytobulk.plots._eval_plot",
        "peekOfCode": "def plot_mse_box(ground_truth,df_list,name_list,title,num_column=6,skipping_mse_calculation=False,\n                color_set=Const.COLOR_BLUE,fig_format=None,out_dir='/out',filter_list=None,save=True):\n    sns.set(font_scale=0.8,style=\"white\")\n    if skipping_mse_calculation:\n        mse_result_list= df_list\n    else:\n        mse_result_list=[]\n        for method_index in range(len(name_list)):\n            df = df_list[method_index]\n            mse_result = utils.eval_each_sample_mse(ground_truth,df,name_list[method_index])",
        "detail": "CytoBulk.cytobulk.plots._eval_plot",
        "documentation": {}
    },
    {
        "label": "Const",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.plots._plot",
        "description": "CytoBulk.cytobulk.plots._plot",
        "peekOfCode": "class Const:\n    \"\"\"\n    Some COLOR SET used in the class.\n    \"\"\"\n    DIFF_COLOR_2 = ['#011F5B','#F19CBB']\n    #DIFF_COLOR_N = ['#005f73','#94d2bd','#e9d8a6','#fac748','#e76f51','#9b2226']\n    DIFF_COLOR_N = ['#191970','#ADD8E6']\n    FIG_FORMAT = 'svg'\ndef _plot_scatter_2label(x1,x2,X1_label,X2_label,title,color_set=None,fig_format=None,out_dir='/out'):\n    columns=x1.columns",
        "detail": "CytoBulk.cytobulk.plots._plot",
        "documentation": {}
    },
    {
        "label": "plot_batch_effect",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.plots._plot",
        "description": "CytoBulk.cytobulk.plots._plot",
        "peekOfCode": "def plot_batch_effect(bulk_adata,pseudo_bulk,out_dir,title=''):\n    def _get_paired_data(adata,status=None):\n        data = get.count_data(adata,counts_location=status)\n        return(utils.pca(data))\n    def _plot_paired_data(bulk_adata,pseudo_bulk,title,out_dir,status=None):\n        X1 = _get_paired_data(bulk_adata,status)\n        X2 = _get_paired_data(pseudo_bulk,status)\n        _plot_scatter_2label(X1,X2,X1_label=\"input_data\",X2_label=\"simulated data\",title=title,out_dir=out_dir)\n    _plot_paired_data(bulk_adata,pseudo_bulk,title+\"(original)\",out_dir=out_dir)\n    _plot_paired_data(bulk_adata,pseudo_bulk,title+\"(batch effected)\",out_dir=out_dir,status=\"batch_effected\")",
        "detail": "CytoBulk.cytobulk.plots._plot",
        "documentation": {}
    },
    {
        "label": "qc_bulk_sc",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._filtering",
        "description": "CytoBulk.cytobulk.preprocessing._filtering",
        "peekOfCode": "def qc_bulk_sc(bulk_data,\n            sc_adata,\n            min_counts_per_sample=100,\n            min_genes_per_sample=100,\n            out_dir='.',\n            dataset_name='',\n            **kwargs):\n    \"\"\"\n    Quality control in bulk dataframe and sc adata.\n    Parameters",
        "detail": "CytoBulk.cytobulk.preprocessing._filtering",
        "documentation": {}
    },
    {
        "label": "high_variable_gene",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._filtering",
        "description": "CytoBulk.cytobulk.preprocessing._filtering",
        "peekOfCode": "def high_variable_gene(adata,flavor):\n    sc.pp.highly_variable_genes(adata, min_mean=0, max_mean=np.inf, min_disp=0.25,flavor=flavor)\n    return adata[:, adata.var.highly_variable]\ndef qc_st_sc(st_adata,\n            sc_adata,\n            min_counts_per_sample=1,\n            min_genes_per_sample=5,\n            dataset_name='',\n            out_dir='.',\n            **kwargs):",
        "detail": "CytoBulk.cytobulk.preprocessing._filtering",
        "documentation": {}
    },
    {
        "label": "qc_st_sc",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._filtering",
        "description": "CytoBulk.cytobulk.preprocessing._filtering",
        "peekOfCode": "def qc_st_sc(st_adata,\n            sc_adata,\n            min_counts_per_sample=1,\n            min_genes_per_sample=5,\n            dataset_name='',\n            out_dir='.',\n            **kwargs):\n    \"\"\"\n    Quality control in bulk dataframe and sc adata.\n    Parameters",
        "detail": "CytoBulk.cytobulk.preprocessing._filtering",
        "documentation": {}
    },
    {
        "label": "qc_sc",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._filtering",
        "description": "CytoBulk.cytobulk.preprocessing._filtering",
        "peekOfCode": "def qc_sc(sc_adata,**kwargs):\n    \"\"\"\n    Quality control in sc adata.\n    Parameters\n    ----------\n    sc_adata: anndata.AnnData\n        An :class:`~anndata.AnnData` containing the expression to filter.\n    **kwargs:\n        Additional keyword arguments forwarded to\n        :func:`~cytobulk.preprocessing._filter_adata`.",
        "detail": "CytoBulk.cytobulk.preprocessing._filtering",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._preprocessing",
        "description": "CytoBulk.cytobulk.preprocessing._preprocessing",
        "peekOfCode": "def preprocessing(bulk_data,\n                sc_adata,\n                annotation_key,\n                is_st:False,\n                marker_data=None,\n                rename=None,\n                dataset_name=\"\",\n                out_dir='.',\n                different_source=True,\n                cell_list=None,",
        "detail": "CytoBulk.cytobulk.preprocessing._preprocessing",
        "documentation": {}
    },
    {
        "label": "find_marker_giotto",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._rpackage",
        "description": "CytoBulk.cytobulk.preprocessing._rpackage",
        "peekOfCode": "def find_marker_giotto(sc_adata,anno_key,out_dir='./',project=''):\n    \"\"\"\n    find marker gene for each cell type using Giotto package.\n    Parameters\n    ----------\n    raw_sc_adata : anndata.AnnData\n        An :class:`~anndata.AnnData` containing the raw expression.\n    annotation_key : string, optional\n        The `.obs` key where the single cell annotation is stored.: anndata.AnnData.\n    out_dir : string, optional",
        "detail": "CytoBulk.cytobulk.preprocessing._rpackage",
        "documentation": {}
    },
    {
        "label": "remove_batch_effect",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.preprocessing._rpackage",
        "description": "CytoBulk.cytobulk.preprocessing._rpackage",
        "peekOfCode": "def remove_batch_effect(pseudo_bulk, bulk_adata, out_dir, project='',batch_effect=True):\n    \"\"\"\n    Remove batch effect between pseudo_bulk and input bulk data.\n    Parameters\n    ----------\n    pseudo_bulk : anndata.AnnData\n        An :class:`~anndata.AnnData` containing the pseudo expression.\n    bulk_adata : anndata.AnnData\n        An :class:`~anndata.AnnData` containing the input expression.\n    out_dir : string, optional",
        "detail": "CytoBulk.cytobulk.preprocessing._rpackage",
        "documentation": {}
    },
    {
        "label": "os.environ[\"R_HOME\"]",
        "kind": 5,
        "importPath": "CytoBulk.cytobulk.preprocessing._rpackage",
        "description": "CytoBulk.cytobulk.preprocessing._rpackage",
        "peekOfCode": "os.environ[\"R_HOME\"] = \"D:/R/R-4.3.1\" \nos.environ[\"PATH\"] = \"D:/R/R-4.3.1/bin/x64\" + \";\" + os.environ[\"R_HOME\"] \nimport rpy2.robjects as robjects\nfrom rpy2.robjects import pandas2ri\nfrom .. import utils\nfrom .. import get\nfrom os.path import exists\ndef find_marker_giotto(sc_adata,anno_key,out_dir='./',project=''):\n    \"\"\"\n    find marker gene for each cell type using Giotto package.",
        "detail": "CytoBulk.cytobulk.preprocessing._rpackage",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": "CytoBulk.cytobulk.preprocessing._rpackage",
        "description": "CytoBulk.cytobulk.preprocessing._rpackage",
        "peekOfCode": "os.environ[\"PATH\"] = \"D:/R/R-4.3.1/bin/x64\" + \";\" + os.environ[\"R_HOME\"] \nimport rpy2.robjects as robjects\nfrom rpy2.robjects import pandas2ri\nfrom .. import utils\nfrom .. import get\nfrom os.path import exists\ndef find_marker_giotto(sc_adata,anno_key,out_dir='./',project=''):\n    \"\"\"\n    find marker gene for each cell type using Giotto package.\n    Parameters",
        "detail": "CytoBulk.cytobulk.preprocessing._rpackage",
        "documentation": {}
    },
    {
        "label": "Const",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class Const:\n    \"\"\"\n    Some constants used in the class.\n    \"\"\"\n    MODE_TRAINING = \"training\"\n    MODE_PREDICTION = \"prediction\"\n    SAMPLE_COL = \"sample_name\"\n    GENE_SYMBOL_COL = \"GeneSymbol\"\n    BATCH_SIZE = 64\n    LEARNING_RATE = 0.005",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "LinearModel",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class LinearModel(torch.nn.Module):\n    def __init__(self, t):\n        super(LinearModel, self).__init__()\n        self.encoder = torch.nn.Sequential(\n            torch.nn.Linear(t,64),\n            nn.BatchNorm1d(64),\n            torch.nn.Linear(64,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self, t):",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "GraphConv",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class GraphConv(nn.Module):\n    def __init__(self, in_c, out_c, K, device, bias=True, normalize=True):\n        super(GraphConv, self).__init__()\n        self.device = device\n        self.normalize = normalize\n        self.weight = nn.Parameter(torch.Tensor(K + 1, 1, in_c, out_c))\n        nn.init.orthogonal_(self.weight, gain=nn.init.calculate_gain('leaky_relu', 0.4))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(1, 1, out_c))\n            # nn.init.zeros_(self.bias)",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "GraphNet_bulk",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class GraphNet_bulk(nn.Module):\n    def __init__(self, in_c, hid_c, out_c, K, device):\n        super(GraphNet_bulk, self).__init__()\n        self.conv1 = GraphConv(in_c=in_c, out_c=hid_c, K=K, device=device)\n        self.conv2 = GraphConv(in_c=hid_c, out_c=out_c, K=K, device=device)\n        self.act = nn.ELU()\n    def forward(self, graph, data):\n        graph_data = graph\n        flow_x = data\n        B, N = flow_x.size(0), flow_x.size(1)",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "GraphNet_st",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class GraphNet_st(nn.Module):\n    def __init__(self, in_c, hid_c, out_c, K, device):\n        super(GraphNet_st, self).__init__()\n        self.conv1 = GraphConv(in_c=in_c, out_c=out_c, K=K, device=device)\n        self.act = nn.ELU()\n    def forward(self, graph, data):\n        graph_data = graph\n        flow_x = data\n        B, N = flow_x.size(0), flow_x.size(1)\n        flow_x = flow_x.view(B, 1, N)",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "InferDataset",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class InferDataset(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __getitem__(self, index):\n        x = self.data[index]\n        return x\n    def __len__(self):\n        return len(self.data)\ndef get_G(cell_name, sel_gene, sc_adata,annotation_key):\n        def _get_mat_YW(sc_df):",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "GraphDeconv",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "class GraphDeconv:\n    def __init__(\n            self,\n            cell_num=200,\n            mode=Const.MODE_PREDICTION,\n            use_gpu=True\n    ):\n        \"\"\"\n            cell_num: int, the number of cell for each bulk sample.\n            mode: string, prediction or training.",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "configure_device",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "def configure_device(use_gpu):\n    if use_gpu:\n        if torch.cuda.is_available(): return \"cuda\"\n        if torch.backends.mps.is_available(): return \"mps\"\n    return \"cpu\"\ndef naive_parallel(\n        func: Callable, \n        args: Generator, \n        cpu_limit = mp.cpu_count()\n):",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "naive_parallel",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "def naive_parallel(\n        func: Callable, \n        args: Generator, \n        cpu_limit = mp.cpu_count()\n):\n    print(f\"Try to allocate {cpu_limit}, \", end='')\n    cpu_limit = min(cpu_limit, mp.cpu_count())\n    print(f\"{cpu_limit} cpu(s) are currently available.\")\n    with mp.Pool(processes=cpu_limit) as pool:\n        ret = pool.starmap_async(func, args)",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "change_lr",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "def change_lr(optim, new_lr):\n    for g in optim.param_groups:\n        g['lr'] = new_lr\nclass InferDataset(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __getitem__(self, index):\n        x = self.data[index]\n        return x\n    def __len__(self):",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "get_G",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "def get_G(cell_name, sel_gene, sc_adata,annotation_key):\n        def _get_mat_YW(sc_df):\n            mat_Y = torch.FloatTensor(sc_df.values)\n            mat_W = mat_Y @ mat_Y.t()\n            return mat_W\n        sec_num = 1e-20\n        sub_adata = sc_adata[sc_adata.obs[annotation_key]==cell_name,sel_gene].copy()\n        sub_df = get.count_data(sub_adata)\n        mat_W = _get_mat_YW(sub_df)\n        num = len(mat_W)",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "select_gene",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "def select_gene(expression: pd.DataFrame, sel_gene: list):\n    warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n    ret_exp = pd.DataFrame(expression.iloc[:, 0])\n    for gene in sel_gene:\n        ret_exp[gene] = expression[gene] if gene in expression.columns else 0\n    return ret_exp.iloc[:, 1:]\ndef train_cell_loop_once(cell, \n                        marker,\n                        presudo_bulk,\n                        bulk_adata,",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "train_cell_loop_once",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "description": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "peekOfCode": "def train_cell_loop_once(cell, \n                        marker,\n                        presudo_bulk,\n                        bulk_adata,\n                        batch_size,\n                        sc_adata,\n                        out_dir,\n                        device,\n                        annotation_key,\n                        project_name,",
        "detail": "CytoBulk.cytobulk.tools.model._graph_deconv",
        "documentation": {}
    },
    {
        "label": "bulk_deconv",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools._deconv",
        "description": "CytoBulk.cytobulk.tools._deconv",
        "peekOfCode": "def bulk_deconv(bulk_data,\n                sc_adata,\n                annotation_key,\n                marker_data=None,\n                rename=None,\n                dataset_name=\"\",\n                out_dir='.',\n                different_source=True,\n                cell_list=None,\n                scale_factors=100000,",
        "detail": "CytoBulk.cytobulk.tools._deconv",
        "documentation": {}
    },
    {
        "label": "st_deconv",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools._deconv",
        "description": "CytoBulk.cytobulk.tools._deconv",
        "peekOfCode": "def st_deconv(st_adata,\n            sc_adata,\n            annotation_key,\n            marker_data=None,\n            rename=None,\n            dataset_name=\"\",\n            out_dir='.',\n            different_source=True,\n            cell_list=None,\n            scale_factors=10000,",
        "detail": "CytoBulk.cytobulk.tools._deconv",
        "documentation": {}
    },
    {
        "label": "bulk_mapping",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools._mapping",
        "description": "CytoBulk.cytobulk.tools._mapping",
        "peekOfCode": "def bulk_mapping(frac_data,\n                bulk_adata,\n                sc_adata,\n                n_cell=100,\n                annotation_key=\"curated_cell_type\",\n                bulk_layer=None,\n                sc_layer=None,\n                reorder=True,\n                multiprocessing=True,\n                cpu_num=cpu_count()-2,",
        "detail": "CytoBulk.cytobulk.tools._mapping",
        "documentation": {}
    },
    {
        "label": "st_mapping",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools._mapping",
        "description": "CytoBulk.cytobulk.tools._mapping",
        "peekOfCode": "def st_mapping(st_adata,sc_adata,deconv_results,solution_method=\"cytospace\"):\n    if solution_method==\"cytospace\":\n        main_cytospace(st_adata,sc_adata,deconv_results)\n    return",
        "detail": "CytoBulk.cytobulk.tools._mapping",
        "documentation": {}
    },
    {
        "label": "Const",
        "kind": 6,
        "importPath": "CytoBulk.cytobulk.tools._segmentation",
        "description": "CytoBulk.cytobulk.tools._segmentation",
        "peekOfCode": "class Const:\n    PIX_X = 'X'\n    PIX_Y = 'Y'\ndef rgb2grey(img: np.ndarray):\n    return np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n# TODO: deal with the vesiculars\ndef predict_cell_num(img_path, \n                     spot_path,\n                     crop_r,\n                     save_png_result=None,",
        "detail": "CytoBulk.cytobulk.tools._segmentation",
        "documentation": {}
    },
    {
        "label": "rgb2grey",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools._segmentation",
        "description": "CytoBulk.cytobulk.tools._segmentation",
        "peekOfCode": "def rgb2grey(img: np.ndarray):\n    return np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n# TODO: deal with the vesiculars\ndef predict_cell_num(img_path, \n                     spot_path,\n                     crop_r,\n                     save_png_result=None,\n                     model_type='cyto2', \n                     cellprob_threshold=1):\n    '''",
        "detail": "CytoBulk.cytobulk.tools._segmentation",
        "documentation": {}
    },
    {
        "label": "predict_cell_num",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.tools._segmentation",
        "description": "CytoBulk.cytobulk.tools._segmentation",
        "peekOfCode": "def predict_cell_num(img_path, \n                     spot_path,\n                     crop_r,\n                     save_png_result=None,\n                     model_type='cyto2', \n                     cellprob_threshold=1):\n    '''\n    Params:\n    -----\n    img_path: str, WSI. size can be arbitrary.",
        "detail": "CytoBulk.cytobulk.tools._segmentation",
        "documentation": {}
    },
    {
        "label": "eval_fraction",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._evaluation",
        "description": "CytoBulk.cytobulk.utils._evaluation",
        "peekOfCode": "def eval_fraction(df1,df2,out_dir=',',save=True):\n    cells=[]\n    sig=[]\n    mse=[]\n    p_value=[]\n    cell_name = df1.columns.values.tolist()\n    for j in range(len(cell_name)):\n        data1 = df1.loc[:,cell_name[j]].values\n        data2 = df2.loc[:,cell_name[j]].values\n        mse_tmp = mean_squared_error(data1, data2)",
        "detail": "CytoBulk.cytobulk.utils._evaluation",
        "documentation": {}
    },
    {
        "label": "eval_comparsion",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._evaluation",
        "description": "CytoBulk.cytobulk.utils._evaluation",
        "peekOfCode": "def eval_comparsion(df1,df2_list,method_name,out_dir=',',save=True):\n    cells=[]\n    sig=[]\n    mse=[]\n    p_value=[]\n    cell_name = df1.columns.values.tolist()\n    methods = []\n    for i in range(len(df2_list)):\n        for j in range(len(cell_name)):\n            data1 = df2_list[i].loc[:,cell_name[j]].values",
        "detail": "CytoBulk.cytobulk.utils._evaluation",
        "documentation": {}
    },
    {
        "label": "eval_each_sample_mse",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._evaluation",
        "description": "CytoBulk.cytobulk.utils._evaluation",
        "peekOfCode": "def eval_each_sample_mse(df1,df2,method_name,out_dir=',',save=True):\n    cells=[]\n    mse=[]\n    samples=[]\n    cell_name = df1.columns.values.tolist()\n    methods = []\n    sample_name = df1.index.tolist()\n    df2 = df2.loc[sample_name,:]\n    for i in range(len(df1)):\n        for j in range(len(cell_name)):",
        "detail": "CytoBulk.cytobulk.utils._evaluation",
        "documentation": {}
    },
    {
        "label": "get_sum",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def get_sum(\n    X,\n    axis,\n    dtype=None,\n):\n    \"\"\"\n    Calculates the sum of a sparse matrix or array-like in a specified axis and\n    returns a flattened result.\n    Parameters\n    ----------",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "log1p",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def log1p(\n    X,\n):\n    \"\"\"\n    Calculates log1p inplace and in parallel.\n    Parameters\n    ----------\n    X\n        A :class:`~numpy.ndarray` with more than 1 dimension, a `scipy` sparse\n        matrix, or something which has an attribute `.X` which fits this",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "pca",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def pca(X,dimension=2):\n    \"\"\"\n    Calculates decompositioned data  with 2 dimensions.\n    Parameters\n    ----------\n    X\n        A :class:`~pd.dataframe` with more than 2 dimension.\n    dimension: int\n        The number to indicate needed dimension.\n    Returns",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "normalization_cpm",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def normalization_cpm(adata,scale_factors=None,trans_method=None,layer=None):\n    \"\"\"\n    Normalize counts per cell.\n    Parameters\n    ----------\n    scale_factors: int, optional\n        After normalization, each observation (cell) has a total count equal to the median \n        of total counts for observations (cells) before normalization.\n    trans_method: None or 'log', optional\n        If log, Computes X=log(X+1), where log denotes the natural logarithm unless a different base is given.",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "normal_center_df",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def normal_center_df(data):\n    scaler = StandardScaler()\n    scaler.fit(data.values)\n    trans_data = scaler.transform(data.values)\n    return pd.DataFrame(trans_data,index=data.index,columns=data.columns)\ndef pear(A,B):\n    tmp = np.corrcoef(A.flatten(), B.flatten())\n    return tmp[0,1] \ndef calculate_distance(matrix1,matrix2):\n    return (1 - sp.distance.cdist(matrix1, matrix2, 'cosine'))",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "pear",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def pear(A,B):\n    tmp = np.corrcoef(A.flatten(), B.flatten())\n    return tmp[0,1] \ndef calculate_distance(matrix1,matrix2):\n    return (1 - sp.distance.cdist(matrix1, matrix2, 'cosine'))",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "calculate_distance",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._math",
        "description": "CytoBulk.cytobulk.utils._math",
        "peekOfCode": "def calculate_distance(matrix1,matrix2):\n    return (1 - sp.distance.cdist(matrix1, matrix2, 'cosine'))",
        "detail": "CytoBulk.cytobulk.utils._math",
        "documentation": {}
    },
    {
        "label": "check_paths",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._read_data",
        "description": "CytoBulk.cytobulk.utils._read_data",
        "peekOfCode": "def check_paths(output_folder,output_prefix=None):\n    # Create relative path\n    output_path = os.path.join(os.getcwd(), output_folder)\n    # Make sure that the folder exists\n    Path(output_path).mkdir(parents=True, exist_ok=True)\n    if os.path.exists(os.path.join(output_path, f\"{output_prefix}assigned_locations.csv\")):\n        print(\"\\033[91mWARNING\\033[0m: Running this will overwrite previous results, choose a new\"\n              \" 'output_folder' or 'output_prefix'\")\n    return output_path\ndef read_file(file_path, file_label):",
        "detail": "CytoBulk.cytobulk.utils._read_data",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._read_data",
        "description": "CytoBulk.cytobulk.utils._read_data",
        "peekOfCode": "def read_file(file_path, file_label):\n    \"\"\"\n    Read data with given path.\n    Parameters\n    ----------\n        file_path\n            file path.\n        file_label\n            the file label to raise exception.\n    Returns",
        "detail": "CytoBulk.cytobulk.utils._read_data",
        "documentation": {}
    },
    {
        "label": "bulk_simulation",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._stimulation",
        "description": "CytoBulk.cytobulk.utils._stimulation",
        "peekOfCode": "def bulk_simulation(sc_adata,\n                    cell_list,\n                    annotation_key,\n                    project,\n                    out_dir,\n                    n_sample_each_group=100,\n                    min_cells_each_group=100,\n                    cell_gap_each_group=100,\n                    group_number=5,\n                    rename_dict=None,",
        "detail": "CytoBulk.cytobulk.utils._stimulation",
        "documentation": {}
    },
    {
        "label": "st_simulation",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._stimulation",
        "description": "CytoBulk.cytobulk.utils._stimulation",
        "peekOfCode": "def st_simulation(sc_adata,\n                cell_list,\n                annotation_key,\n                project,\n                out_dir,\n                n_sample_each_group=1000,\n                min_cells_each_group=8,\n                cell_gap_each_group=1,\n                group_number=5,\n                rename_dict=None,",
        "detail": "CytoBulk.cytobulk.utils._stimulation",
        "documentation": {}
    },
    {
        "label": "st_simulation_case",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._stimulation",
        "description": "CytoBulk.cytobulk.utils._stimulation",
        "peekOfCode": "def st_simulation_case(sc_adata,\n                    cell_list,\n                    annotation_key,\n                    project,\n                    out_dir,\n                    n_sample_each_group=100,\n                    min_cells_each_group=6,\n                    cell_gap_each_group=1,\n                    group_number=5,\n                    rename_dict=None,",
        "detail": "CytoBulk.cytobulk.utils._stimulation",
        "documentation": {}
    },
    {
        "label": "bulk_simulation_case",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._stimulation",
        "description": "CytoBulk.cytobulk.utils._stimulation",
        "peekOfCode": "def bulk_simulation_case(sc_adata,\n                        cell_list,\n                        annotation_key,\n                        project,\n                        out_dir,\n                        n_sample_each_group=100,\n                        min_cells_each_group=100,\n                        cell_gap_each_group=100,\n                        group_number=5,\n                        rename_dict=None,",
        "detail": "CytoBulk.cytobulk.utils._stimulation",
        "documentation": {}
    },
    {
        "label": "compute_cluster_averages",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def compute_cluster_averages(adata, annotation_key, common_cell,use_raw=False,project='',save=False,out_dir='./'):\n    \"\"\"\n    Compute average expression of each gene in each cluster.\n    Parameters\n    ----------\n    adata\n        AnnData object of reference single-cell dataset.\n    annotation_key\n        Name of adata.obs column containing cluster labels.\n    common_cell",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "compute_bulk_with_average_exp",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def compute_bulk_with_average_exp(pseudo_bulk, average_cell_exp,save=False,out_dir='./',project=''):\n    \"\"\"\n    Compute average expression of each gene in each cluster\n    Parameters\n    ----------\n    pseudo_bulk\n        AnnData object of reference single-cell dataset\n    annotation_key\n        Name of adata.obs column containing cluster labels\n    common_cell",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "data_dict_integration",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def data_dict_integration(common_list,data_df,data_dict,common_cell,top_num=100):\n    \"\"\"\n    Integration the dataframe and dict.\n    Parameters\n    ----------\n    data\n        Dataframe and the columns is the key.\n    dict\n        Dictionary with key and values.\n    top_number",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "marker_integration",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def marker_integration(common_list,data_df,data_dict,common_cell,top_num=100):\n    \"\"\"\n    Integration the dataframe and dict.\n    Parameters\n    ----------\n    data\n        Dataframe and the columns is the key.\n    dict\n        Dictionary with key and values.\n    top_number",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "filter_samples",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def filter_samples(pseudo_bulk, bulk_adata,data_num,num=500,cut_off=0.9,loc=None):\n    from sklearn.metrics.pairwise import cosine_similarity\n    sample_name = pseudo_bulk.obs_names\n    if loc:\n        bulk_matrix = bulk_adata.layers[loc]\n        pseudo_matrix = pseudo_bulk.layers[loc]\n    else:\n        bulk_matrix = bulk_adata.X\n        pseudo_matrix = pseudo_bulk.X\n    #similarity_matrix = np.matmul(bulk_matrix,pseudo_matrix.T)",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "compute_average_cosin",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def compute_average_cosin(pseudo_bulk_tensor,bulk_adata,loc=None):\n    from sklearn.metrics.pairwise import cosine_similarity\n    valid_list=[]\n    for i in pseudo_bulk_tensor:\n        valid_list.append(i[0].numpy())\n    pseudo_matrix = np.array(valid_list)\n    if loc:\n        bulk_matrix = bulk_adata.layers[loc]\n    else:\n        bulk_matrix = bulk_adata.X",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "filter_gene",
        "kind": 2,
        "importPath": "CytoBulk.cytobulk.utils._utils",
        "description": "CytoBulk.cytobulk.utils._utils",
        "peekOfCode": "def filter_gene(expression,reference,out_dir,cell_type,save=True):\n    data_list=[expression,reference]\n    filtered_list=[]\n    for df in data_list:\n        print(df)\n        zero_count_per_column = (df == 0).sum(axis=0)\n        columns_to_keep = zero_count_per_column[zero_count_per_column <= (len(df) / 2)].index\n        df_filtered = df[columns_to_keep]\n        filtered_list.append(df_filtered)\n    common_columns = filtered_list[0].columns.intersection(filtered_list[1].columns)",
        "detail": "CytoBulk.cytobulk.utils._utils",
        "documentation": {}
    },
    {
        "label": "test_read_adata",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_pl_preprocessing",
        "description": "CytoBulk.tests.test_pl_preprocessing",
        "peekOfCode": "def test_read_adata(adata_path):\n    return sc.read_h5ad(adata_path)\n@pytest.mark.skip\ndef test_read_df(data_path):\n    return pd.read_csv(data_path,index_col=0,sep='\\t')\n# tested\n@pytest.mark.skip\n@pytest.mark.parametrize(\"adata_path\", [(\"../data/A36_sample.h5ad\")])\ndef test_sc_qc(adata_path):\n    sc = test_read_adata(adata_path)",
        "detail": "CytoBulk.tests.test_pl_preprocessing",
        "documentation": {}
    },
    {
        "label": "test_read_df",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_pl_preprocessing",
        "description": "CytoBulk.tests.test_pl_preprocessing",
        "peekOfCode": "def test_read_df(data_path):\n    return pd.read_csv(data_path,index_col=0,sep='\\t')\n# tested\n@pytest.mark.skip\n@pytest.mark.parametrize(\"adata_path\", [(\"../data/A36_sample.h5ad\")])\ndef test_sc_qc(adata_path):\n    sc = test_read_adata(adata_path)\n    assert isinstance(ct.pp.qc_sc(sc,save=True,out_dir='../data',project='A36_sample'),ad.AnnData)\n    #return ct.pp.qc_sc(sc)   \n@pytest.mark.skip",
        "detail": "CytoBulk.tests.test_pl_preprocessing",
        "documentation": {}
    },
    {
        "label": "test_sc_qc",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_pl_preprocessing",
        "description": "CytoBulk.tests.test_pl_preprocessing",
        "peekOfCode": "def test_sc_qc(adata_path):\n    sc = test_read_adata(adata_path)\n    assert isinstance(ct.pp.qc_sc(sc,save=True,out_dir='../data',project='A36_sample'),ad.AnnData)\n    #return ct.pp.qc_sc(sc)   \n@pytest.mark.skip\n@pytest.mark.parametrize(\"adata_path,bulk_path\", [(\"../data/A36_sample.h5ad\",\"../data/reference_bulk_data/A35_sample_stimulated_bulk.txt\")])\ndef test_qc_bulk_sc(bulk_path,adata_path):\n    sc = test_read_adata(adata_path)\n    bulk = test_read_df(bulk_path)\n    ct.pp.qc_bulk_sc(bulk_data = bulk,sc_adata = sc,save=True,out_dir='../data',dataset_name='A36_sc_35_bulk')",
        "detail": "CytoBulk.tests.test_pl_preprocessing",
        "documentation": {}
    },
    {
        "label": "test_qc_bulk_sc",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_pl_preprocessing",
        "description": "CytoBulk.tests.test_pl_preprocessing",
        "peekOfCode": "def test_qc_bulk_sc(bulk_path,adata_path):\n    sc = test_read_adata(adata_path)\n    bulk = test_read_df(bulk_path)\n    ct.pp.qc_bulk_sc(bulk_data = bulk,sc_adata = sc,save=True,out_dir='../data',dataset_name='A36_sc_35_bulk')\n@pytest.mark.parametrize(\"adata_path,bulk_path,marker_path,annotation_key\", [(\"../data/filtered_A36_sample.h5ad\",\n                                                                            \"../data/reference_bulk_data/A35_sample_stimulated_bulk.txt\",\n                                                                            \"../data/cell_meta.xlsx\",\n                                                                            \"Manually_curated_celltype\")])\ndef test_preprocessing_bulk_sc(bulk_path,adata_path,marker_path,annotation_key):\n    sc = test_read_adata(adata_path)",
        "detail": "CytoBulk.tests.test_pl_preprocessing",
        "documentation": {}
    },
    {
        "label": "test_preprocessing_bulk_sc",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_pl_preprocessing",
        "description": "CytoBulk.tests.test_pl_preprocessing",
        "peekOfCode": "def test_preprocessing_bulk_sc(bulk_path,adata_path,marker_path,annotation_key):\n    sc = test_read_adata(adata_path)\n    bulk = test_read_df(bulk_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    ct.pp.preprocessing(bulk_data = bulk,sc_adata = sc,marker_data=marker,\n                        annotation_key =annotation_key,\n                        rename = names,\n                        out_dir='../data',dataset_name='filtered_A36_sc_35')",
        "detail": "CytoBulk.tests.test_pl_preprocessing",
        "documentation": {}
    },
    {
        "label": "test_read_adata",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_read_adata(adata_path):\n    return sc.read_h5ad(adata_path)\n@pytest.mark.skip\ndef test_read_df(data_path):\n    return pd.read_csv(data_path,index_col=0,sep='\\t')\n@pytest.mark.skip\ndef test_read_csv(data_path):\n    return pd.read_csv(data_path,index_col=0,sep=',')\n@pytest.mark.skip\n@pytest.mark.parametrize(\"adata_path,bulk_path,marker_path,annotation_key\", [(\"../data/filtered_A36_sample.h5ad\",",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_read_df",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_read_df(data_path):\n    return pd.read_csv(data_path,index_col=0,sep='\\t')\n@pytest.mark.skip\ndef test_read_csv(data_path):\n    return pd.read_csv(data_path,index_col=0,sep=',')\n@pytest.mark.skip\n@pytest.mark.parametrize(\"adata_path,bulk_path,marker_path,annotation_key\", [(\"../data/filtered_A36_sample.h5ad\",\n                                                                            \"../data/reference_bulk_data/A35_sample_stimulated_bulk.txt\",\n                                                                            \"../data/cell_meta.xlsx\",\n                                                                            \"curated_cell_type\")])",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_read_csv",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_read_csv(data_path):\n    return pd.read_csv(data_path,index_col=0,sep=',')\n@pytest.mark.skip\n@pytest.mark.parametrize(\"adata_path,bulk_path,marker_path,annotation_key\", [(\"../data/filtered_A36_sample.h5ad\",\n                                                                            \"../data/reference_bulk_data/A35_sample_stimulated_bulk.txt\",\n                                                                            \"../data/cell_meta.xlsx\",\n                                                                            \"curated_cell_type\")])\ndef test_bulk_deconv(bulk_path,adata_path,marker_path,annotation_key):\n    sc = test_read_adata(adata_path)\n    bulk = test_read_df(bulk_path)",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_bulk_deconv",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_bulk_deconv(bulk_path,adata_path,marker_path,annotation_key):\n    sc = test_read_adata(adata_path)\n    bulk = test_read_df(bulk_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    ct.tl.bulk_deconv(bulk_data = bulk,sc_adata = sc,marker_data=marker,\n                        annotation_key =annotation_key,\n                        rename = names,\n                        out_dir='D:/project/CytoBulk/case/st_human_sc',dataset_name='filtered_A36_sc_35')",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_bulk_mapping",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_bulk_mapping(frac_data,sc_adata,bulk_adata,n_cell,annotation_key):\n    frac_data = test_read_csv(frac_data)\n    sc_adata = test_read_adata(sc_adata)\n    bulk_adata = test_read_adata(bulk_adata)\n    ct.tl.bulk_mapping(frac_data = frac_data,\n                        sc_adata = sc_adata,\n                        bulk_adata = bulk_adata,\n                        n_cell = n_cell,\n                        annotation_key=annotation_key,\n                        dataset_name=\"filtered_A36_sc_35\",",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_st_deconv",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_st_deconv(bulk_path,adata_path,marker_path,annotation_key,out_dir,dataset_name):\n    sc = test_read_adata(adata_path)\n    st = test_read_adata(bulk_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    ct.tl.st_deconv(st_adata = st,sc_adata = sc,marker_data=marker,\n                        annotation_key =annotation_key,\n                        rename = names,\n                        out_dir=out_dir,",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_st_deconv_hnsc",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_st_deconv_hnsc(bulk_path,adata_path,marker_path,annotation_key,out_dir,dataset_name):\n    sc_adata = test_read_adata(adata_path)\n    sc_adata.__dict__['_raw'].__dict__['_var'] = sc_adata.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n    st = pd.read_csv(bulk_path,index_col=0)\n    st_adata = sc.AnnData(st)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    ct.tl.st_deconv(st_adata = st_adata,sc_adata = sc_adata,marker_data=marker,\n                        annotation_key =annotation_key,",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_st_deconv",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_st_deconv(bulk_path,adata_path,marker_path,annotation_key,out_dir,dataset_name):\n    sc = test_read_adata(adata_path)\n    st = test_read_adata(bulk_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    ct.tl.st_deconv(st_adata = st,sc_adata = sc,marker_data=marker,\n                        annotation_key =annotation_key,\n                        rename = names,\n                        out_dir=out_dir,",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_simulation_st",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_simulation_st(sc_adata,dataset_name, out_dir, annotation_key,marker_path):\n    sc = test_read_adata(sc_adata)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    sc.__dict__['_raw'].__dict__['_var'] = sc.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n    common_cell = names.keys()\n    pseudo_st = ct.ul.st_simulation_case(\n                sc, \n                common_cell, ",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_st_mapping",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_st_mapping(sc_adata,st_adata,marker_path,annotation_key,out_dir,dataset_name):\n    sc = test_read_adata(sc_adata)\n    st = test_read_adata(st_adata)\n    sc.__dict__['_raw'].__dict__['_var'] = sc.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    ct.tl.st_deconv(st_adata = st,sc_adata = sc,marker_data=marker,\n                        annotation_key =annotation_key,\n                        rename = names,",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_st_mapping",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_tl_tools",
        "description": "CytoBulk.tests.test_tl_tools",
        "peekOfCode": "def test_st_mapping(image_path,st_path):\n    st = sc.read_visium(st_path)\n    '''\n    '''\n    ct.tl.img_segmentation(image_path = image_path,st_data = st)\nif __name__ == '__main__':\n    pytest.main([\"-s\", \"test_tl_tools.py\"])",
        "detail": "CytoBulk.tests.test_tl_tools",
        "documentation": {}
    },
    {
        "label": "test_read_adata",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_ul_stimulation",
        "description": "CytoBulk.tests.test_ul_stimulation",
        "peekOfCode": "def test_read_adata(adata_path):\n    return sc.read_h5ad(adata_path)\n@pytest.mark.parametrize(\"adata_path, project, out_dir,annotation_key,marker_path\", [(\"../data/A35_sample.h5ad\",\"A35_sample\",\"../data\",\"Manually_curated_celltype\",\n                                                                                    \"../data/cell_meta.xlsx\")])\n@pytest.mark.skip\ndef test_stimulation_bulk(adata_path,project, out_dir, annotation_key,marker_path):\n    sc = test_read_adata(adata_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()",
        "detail": "CytoBulk.tests.test_ul_stimulation",
        "documentation": {}
    },
    {
        "label": "test_stimulation_bulk",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_ul_stimulation",
        "description": "CytoBulk.tests.test_ul_stimulation",
        "peekOfCode": "def test_stimulation_bulk(adata_path,project, out_dir, annotation_key,marker_path):\n    sc = test_read_adata(adata_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    common_cell = names.keys()\n    pseudo_bulk, pseudo_prop = ct.ul.bulk_simulation(sc, \n                                common_cell, \n                                annotation_key = annotation_key,\n                                project=project, ",
        "detail": "CytoBulk.tests.test_ul_stimulation",
        "documentation": {}
    },
    {
        "label": "test_stimulation_case",
        "kind": 2,
        "importPath": "CytoBulk.tests.test_ul_stimulation",
        "description": "CytoBulk.tests.test_ul_stimulation",
        "peekOfCode": "def test_stimulation_case(adata_path,project, out_dir, annotation_key,marker_path):\n    sc = test_read_adata(adata_path)\n    marker = pd.read_excel(marker_path, sheet_name = \"marker\")\n    names = pd.read_excel(marker_path, sheet_name = \"rename\")\n    names = names.set_index(['Original_name'])['Curated_name'].to_dict()\n    common_cell = names.keys()\n    pseudo_bulk, pseudo_prop = ct.ul.bulk_simulation_case(\n                                sc, \n                                common_cell, \n                                annotation_key = annotation_key,",
        "detail": "CytoBulk.tests.test_ul_stimulation",
        "documentation": {}
    },
    {
        "label": "balance_dataset",
        "kind": 6,
        "importPath": "final.datasets.balance_dataset",
        "description": "final.datasets.balance_dataset",
        "peekOfCode": "class balance_dataset(data.Dataset):\n    def __init__(self,similarities, num_samples,embeddings,distances,datas):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.similarities = similarities\n        self.embeddings = embeddings",
        "detail": "final.datasets.balance_dataset",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "kind": 6,
        "importPath": "final.datasets.hc_dataset",
        "description": "final.datasets.hc_dataset",
        "peekOfCode": "class HCDataset(data.Dataset):\n    \"\"\"Hierarchical clustering dataset.\"\"\"\n    def __init__(self, features, labels, similarities, num_samples):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.features = features",
        "detail": "final.datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "final.datasets.loading",
        "description": "final.datasets.loading",
        "peekOfCode": "def load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.\n    @param dataset: dataset name\n    @type dataset: str\n    @param normalize: whether to normalize features or not\n    @type normalize: boolean\n    @return: feature vectors, labels, and pairwise similarities computed with cosine similarity\n    @rtype: Tuple[np.array, np.array, np.array]\n    \"\"\"\n    # if dataset in UCI_DATASETS:",
        "detail": "final.datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_uci_data",
        "kind": 2,
        "importPath": "final.datasets.loading",
        "description": "final.datasets.loading",
        "peekOfCode": "def load_uci_data(dataset,start_idx,end_idx,label_idx):\n    \"\"\"Loads data from UCI repository.\n    @param dataset: UCI dataset name\n    @return: feature vectors, labels\n    @rtype: Tuple[np.array, np.array]\n    \"\"\"\n    x = []\n    y = []\n    # data_path = os.path.join(os.environ[\"DATAPATH\"], dataset, \"{}.data\".format(dataset))\n    data_path = dataset",
        "detail": "final.datasets.loading",
        "documentation": {}
    },
    {
        "label": "UCI_DATASETS",
        "kind": 5,
        "importPath": "final.datasets.loading",
        "description": "final.datasets.loading",
        "peekOfCode": "UCI_DATASETS = [\n    \"glass\",\n    \"zoo\",\n    \"iris\",\n    \"sc\",\n    \"4_7\",\n    \"4_8\",\n]\ndef load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.",
        "detail": "final.datasets.loading",
        "documentation": {}
    },
    {
        "label": "Preprocessing",
        "kind": 6,
        "importPath": "final.datasets.preprecossing",
        "description": "final.datasets.preprecossing",
        "peekOfCode": "class Preprocessing:\n    def __init__(self):\n        pass\n    def preprocessing_rawdata(\n        self,\n        adata,\n        Min_Genes=200,\n        Min_Cells=3,\n        Min_Mean=0.0125,\n        Max_Mean=3,",
        "detail": "final.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 2,
        "importPath": "final.datasets.preprecossing",
        "description": "final.datasets.preprecossing",
        "peekOfCode": "def preprocessing(\n    adata: AnnData,\n    Min_Genes: int = 200,\n    Min_Cells: int = 3,\n    Min_Mean: float = 0.0125,\n    Max_Mean: float = 3,\n    Min_Disp: float = 0.5,\n    N_pcs: int = 50,\n    n_Top_genes: int = 2000,\n    K: int = 10,",
        "detail": "final.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing_cluster",
        "kind": 2,
        "importPath": "final.datasets.preprecossing",
        "description": "final.datasets.preprecossing",
        "peekOfCode": "def preprocessing_cluster(adata,\n                        N_pcs=50,\n                        K=15,\n                        copy=False,\n                        resolution=0.5,\n                        min_genes=200,\n                        min_cells=3\n                    ):\n        if(N_pcs > len(adata.var)):\n            N_pcs = len(adata.var)",
        "detail": "final.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid_for_genes",
        "kind": 2,
        "importPath": "final.datasets.preprecossing",
        "description": "final.datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid_for_genes(\n        adata,\n        gene_list,\n        save_path=\"./\",\n        groupby ='leiden',\n    ):\n    filtered_data = adata[:, gene_list]\n    # filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    # adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))",
        "detail": "final.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "sort_data",
        "kind": 2,
        "importPath": "final.datasets.preprecossing",
        "description": "final.datasets.preprecossing",
        "peekOfCode": "def sort_data(\n    adata1,\n    adata2,\n    N_1=2000,\n    N_2=2000\n):\n    if N_1 is not None:\n        sc.pp.highly_variable_genes(adata1, n_top_genes=N_1)\n        adata1 = adata1[:, adata1.var['highly_variable']]\n    if N_2 is not None:",
        "detail": "final.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "kind": 2,
        "importPath": "final.datasets.triples",
        "description": "final.datasets.triples",
        "peekOfCode": "def samples_triples(n_nodes, num_samples):\n    num_samples = int(num_samples)\n    all_nodes = np.arange(n_nodes)\n    mesh = np.array(np.meshgrid(all_nodes, all_nodes))\n    pairs = mesh.T.reshape(-1, 2)\n    pairs = pairs[pairs[:, 0] < pairs[:, 1]]\n    n_pairs = pairs.shape[0]\n    if num_samples < n_pairs:\n        print(\"Generating all pairs subset\")\n        subset = np.random.choice(np.arange(n_pairs), num_samples, replace=False)",
        "detail": "final.datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "kind": 2,
        "importPath": "final.datasets.triples",
        "description": "final.datasets.triples",
        "peekOfCode": "def generate_all_triples(n_nodes):\n    triples = []\n    for n1 in tqdm(np.arange(n_nodes)):\n        for n2 in np.arange(n1 + 1, n_nodes):\n            for n3 in np.arange(n2 + 1, n_nodes):\n                triples += [(n1, n2, n3)]\n    return np.array(triples)",
        "detail": "final.datasets.triples",
        "documentation": {}
    },
    {
        "label": "balancehc",
        "kind": 6,
        "importPath": "final.model.balancehc",
        "description": "final.model.balancehc",
        "peekOfCode": "class balancehc(nn.Module):\n    def __init__(self,nodes,embeddings,hyperparamter=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3,):\n        super(balancehc, self).__init__()\n        self.nodes = nodes\n        self.leaves_embeddings = embeddings\n        self.n_nodes = len(embeddings)\n        self.embeddings = nn.Embedding(self.n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)\n        self.embeddings.weight.data = torch.tensor(embeddings);",
        "detail": "final.model.balancehc",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "kind": 6,
        "importPath": "final.model.hyphc",
        "description": "final.model.hyphc",
        "peekOfCode": "class HypHC(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(HypHC, self).__init__()\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)",
        "detail": "final.model.hyphc",
        "documentation": {}
    },
    {
        "label": "RAdam",
        "kind": 6,
        "importPath": "final.optim.radam",
        "description": "final.optim.radam",
        "peekOfCode": "class RAdam(torch.optim.Adam):\n    \"\"\"Riemannian Adam with the same API as :class:`torch.optim.Adam`\n    Parameters\n    ----------\n    params : iterable\n        iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr : float (optional)\n        learning rate (default: 1e-3)\n    betas : Tuple[float, float] (optional)",
        "detail": "final.optim.radam",
        "documentation": {}
    },
    {
        "label": "copy_or_set_",
        "kind": 2,
        "importPath": "final.optim.radam",
        "description": "final.optim.radam",
        "peekOfCode": "def copy_or_set_(dest, source):\n    \"\"\"\n    A workaround to respect strides of :code:`dest` when copying :code:`source`\n    (https://github.com/geoopt/geoopt/issues/70)\n    Parameters\n    ----------\n    dest : torch.Tensor\n        Destination tensor where to store new data\n    source : torch.Tensor\n        Source data to put in the new tensor",
        "detail": "final.optim.radam",
        "documentation": {}
    },
    {
        "label": "isometric_transform",
        "kind": 2,
        "importPath": "final.utils.lca",
        "description": "final.utils.lca",
        "peekOfCode": "def isometric_transform(a, x):\n    \"\"\"Reflection (circle inversion of x through orthogonal circle centered at a).\"\"\"\n    r2 = torch.sum(a ** 2, dim=-1, keepdim=True) - 1.\n    u = x - a\n    return r2 / torch.sum(u ** 2, dim=-1, keepdim=True) * u + a\ndef reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"",
        "detail": "final.utils.lca",
        "documentation": {}
    },
    {
        "label": "reflection_center",
        "kind": 2,
        "importPath": "final.utils.lca",
        "description": "final.utils.lca",
        "peekOfCode": "def reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)",
        "detail": "final.utils.lca",
        "documentation": {}
    },
    {
        "label": "euc_reflection",
        "kind": 2,
        "importPath": "final.utils.lca",
        "description": "final.utils.lca",
        "peekOfCode": "def euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)\n    norm_a_sq = torch.sum(a ** 2, dim=-1, keepdim=True).clamp_min(MIN_NORM)\n    proj = xTa * a / norm_a_sq\n    return 2 * proj - x",
        "detail": "final.utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "kind": 2,
        "importPath": "final.utils.lca",
        "description": "final.utils.lca",
        "peekOfCode": "def hyp_lca(a, b, return_coord=True):\n    \"\"\"\n    Computes projection of the origin on the geodesic between a and b, at scale c\n    More optimized than hyp_lca1\n    \"\"\"\n    r = reflection_center(a)\n    b_inv = isometric_transform(r, b)\n    o_inv = a\n    o_inv_ref = euc_reflection(o_inv, b_inv)\n    o_ref = isometric_transform(r, o_inv_ref)",
        "detail": "final.utils.lca",
        "documentation": {}
    },
    {
        "label": "sl_np_mst",
        "kind": 2,
        "importPath": "final.utils.linkage",
        "description": "final.utils.linkage",
        "peekOfCode": "def sl_np_mst(similarities):\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst(similarities, n)\n    uf = unionfind.UnionFind(n)\n    uf.merge(ij)\n    return uf.tree\ndef sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]",
        "detail": "final.utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "kind": 2,
        "importPath": "final.utils.linkage",
        "description": "final.utils.linkage",
        "peekOfCode": "def sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    return sl_np_mst(sim_mat.numpy())\n### Single linkage using naive union find\n# @profile\ndef nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1",
        "detail": "final.utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "kind": 2,
        "importPath": "final.utils.linkage",
        "description": "final.utils.linkage",
        "peekOfCode": "def nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1\n    similarities will be partitioned into buckets of geometrically increasing size\n    \"\"\"\n    n = xs.shape[0]\n    # Construct distance matrix (negative similarity; since numpy only has increasing sorting)\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    dist_mat = -S(xs0, xs1)  # (n, n)",
        "detail": "final.utils.linkage",
        "documentation": {}
    },
    {
        "label": "Artanh",
        "kind": 6,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "class Artanh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(-1 + 1e-5, 1 - 1e-5)\n        ctx.save_for_backward(x)\n        dtype = x.dtype\n        x = x.double()\n        return (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5).to(dtype)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "Arcosh",
        "kind": 6,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "class Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "Arsinh",
        "kind": 6,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "class Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors\n        return grad_output / (1 + input ** 2) ** 0.5",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "kind": 2,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "def arctanh(x):\n    return Artanh.apply(x)\ndef tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "kind": 2,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "def tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "kind": 2,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "def arcosh(x):\n    return Arcosh.apply(x)\ndef cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "cosh",
        "kind": 2,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "def cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "arsinh",
        "kind": 2,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "def arsinh(x):\n    return Arsinh.apply(x)\ndef sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "sinh",
        "kind": 2,
        "importPath": "final.utils.math",
        "description": "final.utils.math",
        "peekOfCode": "def sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "final.utils.math",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "kind": 2,
        "importPath": "final.utils.metrics",
        "description": "final.utils.metrics",
        "peekOfCode": "def dasgupta_cost(tree, similarities):\n    \"\"\" Non-recursive version of DC for binary trees.\n    Optimized for speed by reordering similarity matrix for locality\n    \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    n_leaves = len(similarities)\n    leaves = descendants_traversal(tree)\n    n_desc, left_desc = descendants_count(tree)\n    cost = [0] * n  # local cost for every node",
        "detail": "final.utils.metrics",
        "documentation": {}
    },
    {
        "label": "mst",
        "kind": 2,
        "importPath": "final.utils.mst",
        "description": "final.utils.mst",
        "peekOfCode": "def mst(dists, n):\n    ij = np.empty((n - 1, 2), dtype=np.int)\n    Z = ij\n    l = np.empty(n-1)\n    l_ = l\n    # Which nodes were already merged.\n    merged = np.zeros(n, dtype=np.int)\n    # Best distance of node i to current tree\n    D = np.empty(n)\n    D[:] = - np.inf",
        "detail": "final.utils.mst",
        "documentation": {}
    },
    {
        "label": "reorder",
        "kind": 2,
        "importPath": "final.utils.mst",
        "description": "final.utils.mst",
        "peekOfCode": "def reorder( A,  idx, n):\n    \"\"\"\n    A : (n, n)\n    idx: (n)\n    \"\"\"\n    B = np.empty((n, n))\n    B_ = B\n    for i in range(n):\n        k = idx[i]\n        for j in range(n):",
        "detail": "final.utils.mst",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "lambda_",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)\ndef gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "gyration",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)\n    uv = (u * v).sum(dim=-1, keepdim=True)\n    uw = (u * w).sum(dim=-1, keepdim=True)\n    vw = (v * w).sum(dim=-1, keepdim=True)\n    a = - uw * v2 + vw + 2 * uv * vw\n    b = - vw * u2 - uw\n    d = 1 + 2 * uv + u2 * v2",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def ptransp(x, y, u):\n    \"\"\"Parallel transport.\"\"\"\n    lx = lambda_(x)\n    ly = lambda_(y)\n    return gyration(y, -x, u) * lx / ly\ndef expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1\ndef project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)\n    cond = norm > maxnorm\n    projected = x / norm * maxnorm\n    return torch.where(cond, projected, x)\ndef mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"\n    x2 = torch.sum(x * x, dim=-1, keepdim=True)\n    y2 = torch.sum(y * y, dim=-1, keepdim=True)\n    xy = torch.sum(x * y, dim=-1, keepdim=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    denom = 1 + 2 * xy + x2 * y2\n    return num / denom.clamp_min(MIN_NORM)\ndef mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"\n    normx = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    return tanh(t * arctanh(normx)) * x / normx\ndef get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "get_midpoint_o",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)\n    return 2 * arctanh(x_norm)\ndef hyp_dist(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "kind": 2,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "def hyp_dist(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "kind": 5,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "MIN_NORM = 1e-15\nBALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "BALL_EPS",
        "kind": 5,
        "importPath": "final.utils.poincare",
        "description": "final.utils.poincare",
        "peekOfCode": "BALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)",
        "detail": "final.utils.poincare",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "kind": 2,
        "importPath": "final.utils.tree",
        "description": "final.utils.tree",
        "peekOfCode": "def descendants_traversal(tree):\n    \"\"\"Get all descendants non-recursively, in traversal order.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    traversal = []\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    is_leaf = [len(children[node]) == 0 for node in range(n)]\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "final.utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "kind": 2,
        "importPath": "final.utils.tree",
        "description": "final.utils.tree",
        "peekOfCode": "def descendants_count(tree):\n    \"\"\"For every node, count its number of descendant leaves, and the number of leaves before it.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    left = [0] * n\n    desc = [0] * n\n    leaf_idx = 0\n    children = [list(tree.neighbors(node))[::-1] for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:",
        "detail": "final.utils.tree",
        "documentation": {}
    },
    {
        "label": {
            "name": "",
            "kind": 6,
            "peekOfCode": "class  UnionFind:\n    def __init__(self, n):\n        self.n = n\n        # self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self._next_id = n\n        self._tree = [-1 for i in range(2*n-1)]\n        self._id = [i for i in range(n)]\n    def _find(self, i):"
        },
        "kind": 6,
        "importPath": "final.utils.unionfind",
        "description": "final.utils.unionfind",
        "peekOfCode": "class  UnionFind:\n    def __init__(self, n):\n        self.n = n\n        # self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self._next_id = n\n        self._tree = [-1 for i in range(2*n-1)]\n        self._id = [i for i in range(n)]\n    def _find(self, i):",
        "detail": "final.utils.unionfind",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "class node:\n    \"\"\"\n    Class of the node of the tree\n    \"\"\"\n    def __init__(self,value=None,son=[],name=''):\n        self.value = value;\n        self.son = son;\n        self.name =name;\n        self.f = None;\n        self.depth=0;",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "newnode",
        "kind": 6,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "class newnode:\n    \"\"\"\n    Class of the aligned nodes by linear programming\n    \"\"\"\n    def __init__(self,node1,node2):\n        self.node1 = node1\n        self.node2 = node2\n        self.f = None\n        self.edge = [];\n        self.indegree = 0;",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "tree_alignment",
        "kind": 6,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "class tree_alignment:\n    \"\"\"\n    Class is used to perform tree alignment between two trees\n    \"\"\"\n    def __init__(self,root1,root2,cost1):\n        self.cost1 = cost1;\n        self.dp = dict();\n        self.forestdp = dict();\n        self.anslist = [];\n        self.ansnodes = [];",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "show_graph",
        "kind": 6,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "class show_graph:\n    def __init__(self,ans,root1,root2):\n        self.ans = ans;\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "show_tree",
        "kind": 6,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "class show_tree:\n    def __init__(self,root1):\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];\n        self.cnt = 0;",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "show_the_tree",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def show_the_tree(folder_path1):\n    nodes1,n1 = build_hyper_tree_from_folder(folder_path1)\n    show_tree(nodes1[0]).show_fig()\ndef build_hyper_tree_from_folder(folder_path):\n    \"\"\"\n    Build the tree from the folder\n    \"\"\"\n    pos_1 = pd.read_csv(folder_path + 'datas.csv')\n    pos = pos_1.set_index(pos_1.columns[0]).values\n    edge = np.load(folder_path + \"datalink.npy\");",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "build_hyper_tree_from_folder",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def build_hyper_tree_from_folder(folder_path):\n    \"\"\"\n    Build the tree from the folder\n    \"\"\"\n    pos_1 = pd.read_csv(folder_path + 'datas.csv')\n    pos = pos_1.set_index(pos_1.columns[0]).values\n    edge = np.load(folder_path + \"datalink.npy\");\n    father_name = np.load(folder_path + \"dataname.npy\")\n    father_name = father_name.astype(np.int)\n    xys = np.load(folder_path+'dataxy.npy');",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "search_tree",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def search_tree(now,c,merge_list):\n    \"\"\"\n    Merge the tree nodes according of the c\n    \"\"\"\n    if(len(now.son) != 2):\n        return now;\n    lson = search_tree(now.son[0],c,merge_list);\n    now.son[0] = lson;\n    rson = search_tree(now.son[1],c,merge_list);\n    now.son[1] = rson",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "find_path_root",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def find_path_root(now,dfs,path,dfs_node,f):\n    \"\"\"\n    Find the path to the root\n    \"\"\"\n    now.path=path.copy();\n    now.f=f\n    now.dfs=dfs;\n    path.append(now);\n    dfs_node.append(now);\n    for i in now.son:",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "find_indegree",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def find_indegree(lists,indegree):\n    \"\"\"\n    Find the indegrees\n    \"\"\"\n    ans=[]\n    for i in lists:\n        if(i.indegree == indegree):\n            ans.append(i);\n    return ans;\ndef run_alignment_linear(nodes1,nodes2):",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment_linear",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def run_alignment_linear(nodes1,nodes2):\n    \"\"\"\n    Alignment two trees by linear programming\n    \"\"\"\n    values1 = np.array([i.value for i in nodes1])\n    values2 = np.array([i.value for i in nodes2])\n    similarities =np.zeros((len(values1),len(values2)))\n    for i in range(len(values1)):\n        for j in range(len(values2)):\n            similarities[i][j]=np.corrcoef(values1[i],values2[j])[0][1]",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment",
        "kind": 2,
        "importPath": "final.alignment",
        "description": "final.alignment",
        "peekOfCode": "def run_alignment(nodes1,nodes2,folder_path1,folder_path2,meta_list1,meta_list2):\n    \"\"\"\n    Alignment two trees by dynmaic programming\n    \"\"\"\n    T=tree_alignment(nodes1[0],nodes2[0],1);\n    minn = T.run_alignment();\n    T.show_ans();\n    ans = T.get_ans()\n    G=show_graph(ans,nodes1[0],nodes2[0]);\n    # G.show_fig()",
        "detail": "final.alignment",
        "documentation": {}
    },
    {
        "label": "merge_by_radius",
        "kind": 2,
        "importPath": "final.core",
        "description": "final.core",
        "peekOfCode": "def merge_by_radius(cell_path,folder_path,radius,method='average',meta_col='celltype'):\n    \"\"\"\n    Merge the cells of the datasets according to the radius \n    Parameters\n    ----------\n    cell_path : string\n        Path to the dataset's cell data h5ad file \n    folder_path1 : string\n        Path to the folder to save the result files of the dataset      \n    radius : float",
        "detail": "final.core",
        "documentation": {}
    },
    {
        "label": "alignment_process",
        "kind": 2,
        "importPath": "final.core",
        "description": "final.core",
        "peekOfCode": "def alignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col='celltype',contin=False,resolution=0.5,method='average',alignment=1,n_pca=50):\n    \"\"\"\n    Performs alignment of two datasets. \n    Parameters\n    ----------\n    cell_path1 : string\n        Path to the first dataset's cell data h5ad file \n    cell_path2 : string\n        Path to the second dataset's cell data h5ad file \n    folder_path1 : string",
        "detail": "final.core",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"\n    Computes the hyperbolic LCA in numpy.\n    \"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"\n    Check if node is a leaf in tree.\n    \"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"\n    Get embeddings of internal nodes from leaves' embeddings using LCA construction.\n    \"\"\"\n    def _complete_tree(embeddings, node):",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"\n    Get embeddings of internal nodes from leaves' embeddings using LCA construction.\n    \"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def train(model,dataloader,optimizer,similarities,epoches):\n    \"\"\"\n    Train the embedding model\n    \"\"\"\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n        total_loss = 0.0",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "train2",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def train2(model,dataloader,optimizer,epoches):\n    \"\"\"\n    Train the rotation model\n    \"\"\"\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n        total_loss = 0.0",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "sl_np_mst_ij",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def sl_np_mst_ij(xs, S):\n    \"\"\"\n    Return the ij to merge the unionfind\n    \"\"\"\n    xs = project(xs).detach()\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    similarities = sim_mat.numpy()\n    n = similarities.shape[0]",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"\n    Random color assignment for label classes.\n    \"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "search_merge_tree",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def search_merge_tree(now,ids,save_path,values,fathers,xys):\n    \"\"\"\n    Search the tree and save the information\n    \"\"\"\n    fathers.append(ids);\n    values.append(now.name);\n    xys.append(now.value);\n    now_id = len(values)-1;\n    for son in now.son:\n        search_merge_tree(son,now_id,save_path,values,fathers,xys)",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "deep_search_tree",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def deep_search_tree(now,depth,path,f):\n    \"\"\"\n    Search the tree and calculate the information\n    \"\"\"\n    now.f=f\n    now.depth=depth;\n    path.append(now);\n    now.path=path.copy();\n    if(f!=now):\n        now.distance_to_root = f.distance_to_root + hyp_dist(f.value,now.value)",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "get_Hyper_tree",
        "kind": 2,
        "importPath": "final.hyper",
        "description": "final.hyper",
        "peekOfCode": "def get_Hyper_tree(data_path,start,end,label,epoches,model_path=None,model_path2=None,save_path='./'):\n    \"\"\"\n    Embedding the dataset into hyperbolic tree structure\n    Parameters\n    ----------\n    data_path : string\n        Path of the cluster center file\n    start : int\n        Index of the starting in the data file\n    end : int",
        "detail": "final.hyper",
        "documentation": {}
    },
    {
        "label": "str2bool",
        "kind": 2,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "def str2bool(v):\n    if isinstance(v, bool):\n        return v\n    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError('Boolean value expected.')\nwarnings.filterwarnings(\"ignore\")",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('--cell_path1','-cp1', type=str)\nparser.add_argument('--folder_path1','-f1', type=str)\nparser.add_argument('--radius1','-r1', type=float,default=15)\nparser.add_argument('--capacity1','-c1', type=float,default=0.1)\nparser.add_argument('--epoches1','-e1', type=int,default=10)\nparser.add_argument('--cell_path2','-cp2', type=str)\nparser.add_argument('--folder_path2','-f2', type=str)\nparser.add_argument('--radius2','-r2', type=float,default=15)\nparser.add_argument('--capacity2','-c2', type=float,default=0.1)",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "args = parser.parse_args()\nif(args.cell_path1 ==None):\n    print(\"Please input the h5 file path for data 1\")\n    exit()\nif(args.cell_path2 ==None):\n    print(\"Please input the h5 file paht for data 2\")\n    exit()\nif(os.path.exists(args.cell_path1)==False):\n    print(\"Input correct path for data 1\")\nif(os.path.exists(args.cell_path2)==False):",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "cell_path1",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "cell_path1 = args.cell_path1\ncell_path2= args.cell_path2\nfolder_path1 = args.folder_path1\nfolder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "folder_path1",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "folder_path1 = args.folder_path1\nfolder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "folder_path2",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "folder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "radius1",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "radius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "radius2",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "radius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "c1",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "c1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "c2",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "c2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "epoches1",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "epoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "epoches2",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "epoches2 = args.epoches2\ncontin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "contin",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "contin = str2bool(args.contin)\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "method",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "method = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "alignment",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "alignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "resolution",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "resolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "n_pca",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "n_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "meta_col",
        "kind": 5,
        "importPath": "final.run_sc",
        "description": "final.run_sc",
        "peekOfCode": "meta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/120/1/sample1_small.h5' -f1 \"./datas/120/1/\" -r1 52.48461374600768 -c1 0.1 -e1 10 -cp2 './datas/120/2/sample1_small.h5' -f2 \"./datas/120/2/\" -r2 52.43896907992145 -c2 0.1 -e2 10 --contin True --alignment 1 --resolution 1 --n_pca 100",
        "detail": "final.run_sc",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "integer.node",
        "description": "integer.node",
        "peekOfCode": "class node:\n    def __init__(self,name,son):\n        self.name=name;\n        self.son=son;\n        self.f=None;\n        self.path=None;\n        self.num_son=0;\n        self.dfs=None;\n    def __repr__(self):\n            return self.name",
        "detail": "integer.node",
        "documentation": {}
    },
    {
        "label": "newnode",
        "kind": 6,
        "importPath": "integer.node",
        "description": "integer.node",
        "peekOfCode": "class newnode:\n    def __init__(self,node1,node2):\n        self.node1 = node1\n        self.node2 = node2\n        self.f = None\n        self.edge = [];\n        self.indegree = 0;\n    def __str__(self):\n        return \"{}_{}\".format(self.node1,self.node2)\n    def __repr__(self):",
        "detail": "integer.node",
        "documentation": {}
    },
    {
        "label": "balance_dataset",
        "kind": 6,
        "importPath": "package.datasets.balance_dataset",
        "description": "package.datasets.balance_dataset",
        "peekOfCode": "class balance_dataset(data.Dataset):\n    def __init__(self,similarities, num_samples,embeddings,distances,datas):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.similarities = similarities\n        self.embeddings = embeddings",
        "detail": "package.datasets.balance_dataset",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "kind": 6,
        "importPath": "package.datasets.hc_dataset",
        "description": "package.datasets.hc_dataset",
        "peekOfCode": "class HCDataset(data.Dataset):\n    \"\"\"Hierarchical clustering dataset.\"\"\"\n    def __init__(self, features, labels, similarities, num_samples):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.features = features",
        "detail": "package.datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "IMDataset",
        "kind": 6,
        "importPath": "package.datasets.improve_dataset",
        "description": "package.datasets.improve_dataset",
        "peekOfCode": "class IMDataset(data.Dataset):\n    def __init__(self,similarities, num_samples,leaves_embeddings,datas):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.similarities = similarities\n        self.leaves_embeddings = leaves_embeddings",
        "detail": "package.datasets.improve_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "package.datasets.loading",
        "description": "package.datasets.loading",
        "peekOfCode": "def load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.\n    @param dataset: dataset name\n    @type dataset: str\n    @param normalize: whether to normalize features or not\n    @type normalize: boolean\n    @return: feature vectors, labels, and pairwise similarities computed with cosine similarity\n    @rtype: Tuple[np.array, np.array, np.array]\n    \"\"\"\n    # if dataset in UCI_DATASETS:",
        "detail": "package.datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_uci_data",
        "kind": 2,
        "importPath": "package.datasets.loading",
        "description": "package.datasets.loading",
        "peekOfCode": "def load_uci_data(dataset,start_idx,end_idx,label_idx):\n    \"\"\"Loads data from UCI repository.\n    @param dataset: UCI dataset name\n    @return: feature vectors, labels\n    @rtype: Tuple[np.array, np.array]\n    \"\"\"\n    x = []\n    y = []\n    # data_path = os.path.join(os.environ[\"DATAPATH\"], dataset, \"{}.data\".format(dataset))\n    data_path = dataset",
        "detail": "package.datasets.loading",
        "documentation": {}
    },
    {
        "label": "UCI_DATASETS",
        "kind": 5,
        "importPath": "package.datasets.loading",
        "description": "package.datasets.loading",
        "peekOfCode": "UCI_DATASETS = [\n    \"glass\",\n    \"zoo\",\n    \"iris\",\n    \"sc\",\n    \"4_7\",\n    \"4_8\",\n]\ndef load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.",
        "detail": "package.datasets.loading",
        "documentation": {}
    },
    {
        "label": "Preprocessing",
        "kind": 6,
        "importPath": "package.datasets.preprecossing",
        "description": "package.datasets.preprecossing",
        "peekOfCode": "class Preprocessing:\n    def __init__(self):\n        pass\n    def preprocessing_rawdata(\n        self,\n        adata,\n        Min_Genes=200,\n        Min_Cells=3,\n        Min_Mean=0.0125,\n        Max_Mean=3,",
        "detail": "package.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 2,
        "importPath": "package.datasets.preprecossing",
        "description": "package.datasets.preprecossing",
        "peekOfCode": "def preprocessing(\n    adata: AnnData,\n    Min_Genes: int = 200,\n    Min_Cells: int = 3,\n    Min_Mean: float = 0.0125,\n    Max_Mean: float = 3,\n    Min_Disp: float = 0.5,\n    N_pcs: int = 50,\n    n_Top_genes: int = 2000,\n    K: int = 10,",
        "detail": "package.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing_cluster",
        "kind": 2,
        "importPath": "package.datasets.preprecossing",
        "description": "package.datasets.preprecossing",
        "peekOfCode": "def preprocessing_cluster(adata,\n                        N_pcs=50,\n                        K=10,\n                        copy=False,\n                        resolution=0.5,\n                    ):\n        adata.raw = adata\n        # adata._inplace_subset_var(adata.var['highly_variable'])\n        sc.tl.pca(\n            adata,",
        "detail": "package.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid_for_genes",
        "kind": 2,
        "importPath": "package.datasets.preprecossing",
        "description": "package.datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid_for_genes(\n        adata,\n        gene_list,\n        save_path=\"./\",\n        groupby ='leiden',\n    ):\n    filtered_data = adata.raw.to_adata()[:, gene_list]\n    # filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    # adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))",
        "detail": "package.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "sort_data",
        "kind": 2,
        "importPath": "package.datasets.preprecossing",
        "description": "package.datasets.preprecossing",
        "peekOfCode": "def sort_data(\n    adata1,\n    adata2,\n    N_1=2000,\n    N_2=2000\n):\n    if N_1 is not None:\n        adata1 = adata1.raw.to_adata()\n        sc.pp.highly_variable_genes(adata1, n_top_genes=N_1,flavor='seurat_v3')\n        adata1 = adata1[:, adata1.var['highly_variable']]",
        "detail": "package.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "kind": 2,
        "importPath": "package.datasets.triples",
        "description": "package.datasets.triples",
        "peekOfCode": "def samples_triples(n_nodes, num_samples):\n    num_samples = int(num_samples)\n    all_nodes = np.arange(n_nodes)\n    mesh = np.array(np.meshgrid(all_nodes, all_nodes))\n    pairs = mesh.T.reshape(-1, 2)\n    pairs = pairs[pairs[:, 0] < pairs[:, 1]]\n    n_pairs = pairs.shape[0]\n    if num_samples < n_pairs:\n        print(\"Generating all pairs subset\")\n        subset = np.random.choice(np.arange(n_pairs), num_samples, replace=False)",
        "detail": "package.datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "kind": 2,
        "importPath": "package.datasets.triples",
        "description": "package.datasets.triples",
        "peekOfCode": "def generate_all_triples(n_nodes):\n    triples = []\n    for n1 in tqdm(np.arange(n_nodes)):\n        for n2 in np.arange(n1 + 1, n_nodes):\n            for n3 in np.arange(n2 + 1, n_nodes):\n                triples += [(n1, n2, n3)]\n    return np.array(triples)",
        "detail": "package.datasets.triples",
        "documentation": {}
    },
    {
        "label": "balancehc",
        "kind": 6,
        "importPath": "package.model.balancehc",
        "description": "package.model.balancehc",
        "peekOfCode": "class balancehc(nn.Module):\n    def __init__(self,nodes,embeddings,hyperparamter=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3,):\n        super(balancehc, self).__init__()\n        self.nodes = nodes\n        self.leaves_embeddings = embeddings\n        self.n_nodes = len(embeddings)\n        self.embeddings = nn.Embedding(self.n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)\n        self.embeddings.weight.data = torch.tensor(embeddings);",
        "detail": "package.model.balancehc",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "kind": 6,
        "importPath": "package.model.hyphc",
        "description": "package.model.hyphc",
        "peekOfCode": "class HypHC(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(HypHC, self).__init__()\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)",
        "detail": "package.model.hyphc",
        "documentation": {}
    },
    {
        "label": "improvehc",
        "kind": 6,
        "importPath": "package.model.improvehc",
        "description": "package.model.improvehc",
        "peekOfCode": "class improvehc(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self,leaves_embeddings,dumpy_node, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(improvehc, self).__init__()\n        self.leaves_embeddings = leaves_embeddings\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature",
        "detail": "package.model.improvehc",
        "documentation": {}
    },
    {
        "label": "RAdam",
        "kind": 6,
        "importPath": "package.optim.radam",
        "description": "package.optim.radam",
        "peekOfCode": "class RAdam(torch.optim.Adam):\n    \"\"\"Riemannian Adam with the same API as :class:`torch.optim.Adam`\n    Parameters\n    ----------\n    params : iterable\n        iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr : float (optional)\n        learning rate (default: 1e-3)\n    betas : Tuple[float, float] (optional)",
        "detail": "package.optim.radam",
        "documentation": {}
    },
    {
        "label": "copy_or_set_",
        "kind": 2,
        "importPath": "package.optim.radam",
        "description": "package.optim.radam",
        "peekOfCode": "def copy_or_set_(dest, source):\n    \"\"\"\n    A workaround to respect strides of :code:`dest` when copying :code:`source`\n    (https://github.com/geoopt/geoopt/issues/70)\n    Parameters\n    ----------\n    dest : torch.Tensor\n        Destination tensor where to store new data\n    source : torch.Tensor\n        Source data to put in the new tensor",
        "detail": "package.optim.radam",
        "documentation": {}
    },
    {
        "label": "isometric_transform",
        "kind": 2,
        "importPath": "package.utils.lca",
        "description": "package.utils.lca",
        "peekOfCode": "def isometric_transform(a, x):\n    \"\"\"Reflection (circle inversion of x through orthogonal circle centered at a).\"\"\"\n    r2 = torch.sum(a ** 2, dim=-1, keepdim=True) - 1.\n    u = x - a\n    return r2 / torch.sum(u ** 2, dim=-1, keepdim=True) * u + a\ndef reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"",
        "detail": "package.utils.lca",
        "documentation": {}
    },
    {
        "label": "reflection_center",
        "kind": 2,
        "importPath": "package.utils.lca",
        "description": "package.utils.lca",
        "peekOfCode": "def reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)",
        "detail": "package.utils.lca",
        "documentation": {}
    },
    {
        "label": "euc_reflection",
        "kind": 2,
        "importPath": "package.utils.lca",
        "description": "package.utils.lca",
        "peekOfCode": "def euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)\n    norm_a_sq = torch.sum(a ** 2, dim=-1, keepdim=True).clamp_min(MIN_NORM)\n    proj = xTa * a / norm_a_sq\n    return 2 * proj - x",
        "detail": "package.utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "kind": 2,
        "importPath": "package.utils.lca",
        "description": "package.utils.lca",
        "peekOfCode": "def hyp_lca(a, b, return_coord=True):\n    \"\"\"\n    Computes projection of the origin on the geodesic between a and b, at scale c\n    More optimized than hyp_lca1\n    \"\"\"\n    r = reflection_center(a)\n    b_inv = isometric_transform(r, b)\n    o_inv = a\n    o_inv_ref = euc_reflection(o_inv, b_inv)\n    o_ref = isometric_transform(r, o_inv_ref)",
        "detail": "package.utils.lca",
        "documentation": {}
    },
    {
        "label": "sl_np_mst",
        "kind": 2,
        "importPath": "package.utils.linkage",
        "description": "package.utils.linkage",
        "peekOfCode": "def sl_np_mst(similarities):\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst(similarities, n)\n    uf = unionfind.UnionFind(n)\n    uf.merge(ij)\n    return uf.tree\ndef sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]",
        "detail": "package.utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "kind": 2,
        "importPath": "package.utils.linkage",
        "description": "package.utils.linkage",
        "peekOfCode": "def sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    return sl_np_mst(sim_mat.numpy())\n### Single linkage using naive union find\n# @profile\ndef nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1",
        "detail": "package.utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "kind": 2,
        "importPath": "package.utils.linkage",
        "description": "package.utils.linkage",
        "peekOfCode": "def nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1\n    similarities will be partitioned into buckets of geometrically increasing size\n    \"\"\"\n    n = xs.shape[0]\n    # Construct distance matrix (negative similarity; since numpy only has increasing sorting)\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    dist_mat = -S(xs0, xs1)  # (n, n)",
        "detail": "package.utils.linkage",
        "documentation": {}
    },
    {
        "label": "Artanh",
        "kind": 6,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "class Artanh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(-1 + 1e-5, 1 - 1e-5)\n        ctx.save_for_backward(x)\n        dtype = x.dtype\n        x = x.double()\n        return (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5).to(dtype)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "Arcosh",
        "kind": 6,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "class Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "Arsinh",
        "kind": 6,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "class Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors\n        return grad_output / (1 + input ** 2) ** 0.5",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "kind": 2,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "def arctanh(x):\n    return Artanh.apply(x)\ndef tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "kind": 2,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "def tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "kind": 2,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "def arcosh(x):\n    return Arcosh.apply(x)\ndef cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "cosh",
        "kind": 2,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "def cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "arsinh",
        "kind": 2,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "def arsinh(x):\n    return Arsinh.apply(x)\ndef sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "sinh",
        "kind": 2,
        "importPath": "package.utils.math",
        "description": "package.utils.math",
        "peekOfCode": "def sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "package.utils.math",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "kind": 2,
        "importPath": "package.utils.metrics",
        "description": "package.utils.metrics",
        "peekOfCode": "def dasgupta_cost(tree, similarities):\n    \"\"\" Non-recursive version of DC for binary trees.\n    Optimized for speed by reordering similarity matrix for locality\n    \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    n_leaves = len(similarities)\n    leaves = descendants_traversal(tree)\n    n_desc, left_desc = descendants_count(tree)\n    cost = [0] * n  # local cost for every node",
        "detail": "package.utils.metrics",
        "documentation": {}
    },
    {
        "label": "mst",
        "kind": 2,
        "importPath": "package.utils.mst",
        "description": "package.utils.mst",
        "peekOfCode": "def mst(dists, n):\n    ij = np.empty((n - 1, 2), dtype=np.int)\n    Z = ij\n    l = np.empty(n-1)\n    l_ = l\n    # Which nodes were already merged.\n    merged = np.zeros(n, dtype=np.int)\n    # Best distance of node i to current tree\n    D = np.empty(n)\n    D[:] = - np.inf",
        "detail": "package.utils.mst",
        "documentation": {}
    },
    {
        "label": "reorder",
        "kind": 2,
        "importPath": "package.utils.mst",
        "description": "package.utils.mst",
        "peekOfCode": "def reorder( A,  idx, n):\n    \"\"\"\n    A : (n, n)\n    idx: (n)\n    \"\"\"\n    B = np.empty((n, n))\n    B_ = B\n    for i in range(n):\n        k = idx[i]\n        for j in range(n):",
        "detail": "package.utils.mst",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "lambda_",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)\ndef gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "gyration",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)\n    uv = (u * v).sum(dim=-1, keepdim=True)\n    uw = (u * w).sum(dim=-1, keepdim=True)\n    vw = (v * w).sum(dim=-1, keepdim=True)\n    a = - uw * v2 + vw + 2 * uv * vw\n    b = - vw * u2 - uw\n    d = 1 + 2 * uv + u2 * v2",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def ptransp(x, y, u):\n    \"\"\"Parallel transport.\"\"\"\n    lx = lambda_(x)\n    ly = lambda_(y)\n    return gyration(y, -x, u) * lx / ly\ndef expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1\ndef project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)\n    cond = norm > maxnorm\n    projected = x / norm * maxnorm\n    return torch.where(cond, projected, x)\ndef mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"\n    x2 = torch.sum(x * x, dim=-1, keepdim=True)\n    y2 = torch.sum(y * y, dim=-1, keepdim=True)\n    xy = torch.sum(x * y, dim=-1, keepdim=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    denom = 1 + 2 * xy + x2 * y2\n    return num / denom.clamp_min(MIN_NORM)\ndef mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"\n    normx = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    return tanh(t * arctanh(normx)) * x / normx\ndef get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "get_midpoint_o",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)\n    return 2 * arctanh(x_norm)\ndef hyp_dist(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist",
        "kind": 2,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "def hyp_dist(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "kind": 5,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "MIN_NORM = 1e-15\nBALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "BALL_EPS",
        "kind": 5,
        "importPath": "package.utils.poincare",
        "description": "package.utils.poincare",
        "peekOfCode": "BALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)",
        "detail": "package.utils.poincare",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "kind": 2,
        "importPath": "package.utils.tree",
        "description": "package.utils.tree",
        "peekOfCode": "def descendants_traversal(tree):\n    \"\"\"Get all descendants non-recursively, in traversal order.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    traversal = []\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    is_leaf = [len(children[node]) == 0 for node in range(n)]\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "package.utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "kind": 2,
        "importPath": "package.utils.tree",
        "description": "package.utils.tree",
        "peekOfCode": "def descendants_count(tree):\n    \"\"\"For every node, count its number of descendant leaves, and the number of leaves before it.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    left = [0] * n\n    desc = [0] * n\n    leaf_idx = 0\n    children = [list(tree.neighbors(node))[::-1] for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:",
        "detail": "package.utils.tree",
        "documentation": {}
    },
    {
        "label": {
            "name": "",
            "kind": 6,
            "peekOfCode": "class  UnionFind:\n    def __init__(self, n):\n        self.n = n\n        # self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self._next_id = n\n        self._tree = [-1 for i in range(2*n-1)]\n        self._id = [i for i in range(n)]\n    def _find(self, i):"
        },
        "kind": 6,
        "importPath": "package.utils.unionfind",
        "description": "package.utils.unionfind",
        "peekOfCode": "class  UnionFind:\n    def __init__(self, n):\n        self.n = n\n        # self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self._next_id = n\n        self._tree = [-1 for i in range(2*n-1)]\n        self._id = [i for i in range(n)]\n    def _find(self, i):",
        "detail": "package.utils.unionfind",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "class node:\n    \"\"\"\n    Class of the node of the tree\n    \"\"\"\n    def __init__(self,value=None,son=[],name=''):\n        self.value = value;\n        self.son = son;\n        self.name =name;\n        self.f = None;\n        self.depth=0;",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "newnode",
        "kind": 6,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "class newnode:\n    \"\"\"\n    Class of the aligned nodes by linear programming\n    \"\"\"\n    def __init__(self,node1,node2):\n        self.node1 = node1\n        self.node2 = node2\n        self.f = None\n        self.edge = [];\n        self.indegree = 0;",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "tree_alignment",
        "kind": 6,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "class tree_alignment:\n    \"\"\"\n    Class is used to perform tree alignment between two trees\n    \"\"\"\n    def __init__(self,root1,root2,cost1):\n        self.cost1 = cost1;\n        self.dp = dict();\n        self.forestdp = dict();\n        self.anslist = [];\n        self.ansnodes = [];",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "show_graph",
        "kind": 6,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "class show_graph:\n    def __init__(self,ans,root1,root2):\n        self.ans = ans;\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "show_tree",
        "kind": 6,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "class show_tree:\n    def __init__(self,root1):\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];\n        self.cnt = 0;",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "show_the_tree",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def show_the_tree(folder_path1):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    n1 = len(pos_1)\n    root1 = -1;\n    for i,j in edge_1:\n        root1 = max(root1,i);\n    length1 = root1 + 1;    \n    nodes1 = [node(name=str(i),son=[]) for i in range(length1)]",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "build_hyper_tree_from_folder",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def build_hyper_tree_from_folder(folder_path):\n    \"\"\"\n    Build the tree from the folder\n    \"\"\"\n    pos_1 = pd.read_csv(folder_path + 'datas.csv')\n    pos = pos_1.set_index(pos_1.columns[0]).values\n    edge = np.load(folder_path + \"datalink.npy\");\n    father_name = np.load(folder_path + \"dataname.npy\")\n    father_name = father_name.astype(np.int)\n    xys = np.load(folder_path+'dataxy.npy');",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "search_tree",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def search_tree(now,c,merge_list):\n    \"\"\"\n    Merge the tree nodes according of the c\n    \"\"\"\n    if(len(now.son) != 2):\n        return now;\n    lson = search_tree(now.son[0],c,merge_list);\n    now.son[0] = lson;\n    rson = search_tree(now.son[1],c,merge_list);\n    now.son[1] = rson",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "find_path_root",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def find_path_root(now,dfs,path,dfs_node,f):\n    \"\"\"\n    Find the path to the root\n    \"\"\"\n    now.path=path.copy();\n    now.f=f\n    now.dfs=dfs;\n    path.append(now);\n    dfs_node.append(now);\n    for i in now.son:",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "find_indegree",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def find_indegree(lists,indegree):\n    \"\"\"\n    Find the indegrees\n    \"\"\"\n    ans=[]\n    for i in lists:\n        if(i.indegree == indegree):\n            ans.append(i);\n    return ans;\ndef run_alignment_linear(nodes1,nodes2):",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment_linear",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def run_alignment_linear(nodes1,nodes2):\n    \"\"\"\n    Alignment two trees by linear programming\n    \"\"\"\n    values1 = np.array([i.value for i in nodes1])\n    values2 = np.array([i.value for i in nodes2])\n    similarities =np.zeros((len(values1),len(values2)))\n    for i in range(len(values1)):\n        for j in range(len(values2)):\n            similarities[i][j]=np.corrcoef(values1[i],values2[j])[0][1]",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment",
        "kind": 2,
        "importPath": "package.alignment",
        "description": "package.alignment",
        "peekOfCode": "def run_alignment(nodes1,nodes2,folder_path1,folder_path2,meta_list1,meta_list2):\n    \"\"\"\n    Alignment two trees by dynmaic programming\n    \"\"\"\n    T=tree_alignment(nodes1[0],nodes2[0],1);\n    minn = T.run_alignment();\n    T.show_ans();\n    ans = T.get_ans()\n    G=show_graph(ans,nodes1[0],nodes2[0]);\n    # G.show_fig()",
        "detail": "package.alignment",
        "documentation": {}
    },
    {
        "label": "merge_by_radius",
        "kind": 2,
        "importPath": "package.core",
        "description": "package.core",
        "peekOfCode": "def merge_by_radius(cell_path,folder_path,radius,method='average',meta_col='celltype'):\n    \"\"\"\n    Merge the cells of the datasets according to the radius \n    Parameters\n    ----------\n    cell_path : string\n        Path to the dataset's cell data h5ad file \n    folder_path1 : string\n        Path to the folder to save the result files of the dataset      \n    radius : float",
        "detail": "package.core",
        "documentation": {}
    },
    {
        "label": "alignment_process",
        "kind": 2,
        "importPath": "package.core",
        "description": "package.core",
        "peekOfCode": "def alignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col='celltype',contin=True,resolution=0.5,method='average',alignment=1,n_pca=50):\n    \"\"\"\n    Performs alignment of two datasets. \n    Parameters\n    ----------\n    cell_path1 : string\n        Path to the first dataset's cell data h5ad file \n    cell_path2 : string\n        Path to the second dataset's cell data h5ad file \n    folder_path1 : string",
        "detail": "package.core",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"\n    Computes the hyperbolic LCA in numpy.\n    \"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"\n    Check if node is a leaf in tree.\n    \"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"\n    Get embeddings of internal nodes from leaves' embeddings using LCA construction.\n    \"\"\"\n    def _complete_tree(embeddings, node):",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"\n    Get embeddings of internal nodes from leaves' embeddings using LCA construction.\n    \"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def train(model,dataloader,optimizer,similarities,epoches):\n    \"\"\"\n    Train the embedding model\n    \"\"\"\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n        total_loss = 0.0",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "train2",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def train2(model,dataloader,optimizer,epoches):\n    \"\"\"\n    Train the rotation model\n    \"\"\"\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n        total_loss = 0.0",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "sl_np_mst_ij",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def sl_np_mst_ij(xs, S):\n    \"\"\"\n    Return the ij to merge the unionfind\n    \"\"\"\n    xs = project(xs).detach()\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    similarities = sim_mat.numpy()\n    n = similarities.shape[0]",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"\n    Random color assignment for label classes.\n    \"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "search_merge_tree",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def search_merge_tree(now,ids,save_path,values,fathers,xys):\n    \"\"\"\n    Search the tree and save the information\n    \"\"\"\n    fathers.append(ids);\n    values.append(now.name);\n    xys.append(now.value);\n    now_id = len(values)-1;\n    for son in now.son:\n        search_merge_tree(son,now_id,save_path,values,fathers,xys)",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "deep_search_tree",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def deep_search_tree(now,depth,path,f):\n    \"\"\"\n    Search the tree and calculate the information\n    \"\"\"\n    now.f=f\n    now.depth=depth;\n    path.append(now);\n    now.path=path.copy();\n    if(f!=now):\n        now.distance_to_root = f.distance_to_root + hyp_dist(f.value,now.value)",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "get_Hyper_tree",
        "kind": 2,
        "importPath": "package.hyper",
        "description": "package.hyper",
        "peekOfCode": "def get_Hyper_tree(data_path,start,end,label,epoches,model_path=None,model_path2=None,save_path='./'):\n    \"\"\"\n    Embedding the dataset into hyperbolic tree structure\n    Parameters\n    ----------\n    data_path : string\n        Path of the cluster center file\n    start : int\n        Index of the starting in the data file\n    end : int",
        "detail": "package.hyper",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('--cell_path1','-cp1', type=str)\nparser.add_argument('--folder_path1','-f1', type=str)\nparser.add_argument('--radius1','-r1', type=float,default=15)\nparser.add_argument('--capacity1','-c1', type=float,default=0.1)\nparser.add_argument('--epoches1','-e1', type=int,default=10)\nparser.add_argument('--cell_path2','-cp2', type=str)\nparser.add_argument('--folder_path2','-f2', type=str)\nparser.add_argument('--radius2','-r2', type=float,default=15)\nparser.add_argument('--capacity2','-c2', type=float,default=0.1)",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "args = parser.parse_args()\nif(args.cell_path1 ==None):\n    print(\"Please input the h5 file path for data 1\")\n    exit()\nif(args.cell_path2 ==None):\n    print(\"Please input the h5 file paht for data 2\")\n    exit()\nif(os.path.exists(args.cell_path1)==False):\n    print(\"Input correct path for data 1\")\nif(os.path.exists(args.cell_path2)==False):",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "cell_path1",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "cell_path1 = args.cell_path1\ncell_path2= args.cell_path2\nfolder_path1 = args.folder_path1\nfolder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "folder_path1",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "folder_path1 = args.folder_path1\nfolder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "folder_path2",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "folder_path2 = args.folder_path2\nradius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "radius1",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "radius1 = args.radius1\nradius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "radius2",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "radius2 = args.radius2\nc1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "c1",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "c1 = args.capacity1\nc2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "c2",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "c2 = args.capacity2\nepoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "epoches1",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "epoches1 = args.epoches1\nepoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "epoches2",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "epoches2 = args.epoches2\ncontin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "contin",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "contin = args.contin\nmethod = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "method",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "method = args.method\nalignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "alignment",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "alignment = args.alignment\nresolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "resolution",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "resolution = args.resolution\nn_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "n_pca",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "n_pca = args.n_pca\nmeta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "meta_col",
        "kind": 5,
        "importPath": "package.run_sc",
        "description": "package.run_sc",
        "peekOfCode": "meta_col = args.meta_col\nalignment_process(cell_path1,cell_path2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2,meta_col=meta_col,contin=contin,resolution=resolution,method=method,alignment=alignment,n_pca=n_pca)\n# python run_sc.py -cp1 './datas/d1/sample.h5' -f1 \"./datas/d1/\" -r1 50 -c1 0.001 -e1 10 -cp2 './datas/d2/sample.h5' -f2 \"./datas/d2/\" -r2 50 -c2 0.001 -e2 10\n# python run_sc.py -cp1 './datas/test/A35.h5' -f1 \"./datas/118/1/\" -r1 147.63807097087118 -c1 0.001 -e1 5 -cp2 './datas/test/A36.h5' -f2 \"./datas/118/2/\" -r2 149.58609561052123 -c2 0.001 -e2 5 --contin True",
        "detail": "package.run_sc",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "kind": 6,
        "importPath": "scsc.datasets.hc_dataset",
        "description": "scsc.datasets.hc_dataset",
        "peekOfCode": "class HCDataset(data.Dataset):\n    \"\"\"Hierarchical clustering dataset.\"\"\"\n    def __init__(self, features, labels, similarities, num_samples):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.features = features",
        "detail": "scsc.datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "scsc.datasets.loading",
        "description": "scsc.datasets.loading",
        "peekOfCode": "def load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.\n    @param dataset: dataset name\n    @type dataset: str\n    @param normalize: whether to normalize features or not\n    @type normalize: boolean\n    @return: feature vectors, labels, and pairwise similarities computed with cosine similarity\n    @rtype: Tuple[np.array, np.array, np.array]\n    \"\"\"\n    # if dataset in UCI_DATASETS:",
        "detail": "scsc.datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_uci_data",
        "kind": 2,
        "importPath": "scsc.datasets.loading",
        "description": "scsc.datasets.loading",
        "peekOfCode": "def load_uci_data(dataset,start_idx,end_idx,label_idx):\n    \"\"\"Loads data from UCI repository.\n    @param dataset: UCI dataset name\n    @return: feature vectors, labels\n    @rtype: Tuple[np.array, np.array]\n    \"\"\"\n    x = []\n    y = []\n    ids = {\n        \"zoo\": (1, 17, -1),",
        "detail": "scsc.datasets.loading",
        "documentation": {}
    },
    {
        "label": "UCI_DATASETS",
        "kind": 5,
        "importPath": "scsc.datasets.loading",
        "description": "scsc.datasets.loading",
        "peekOfCode": "UCI_DATASETS = [\n    \"glass\",\n    \"zoo\",\n    \"iris\",\n    \"sc\",\n    \"4_7\",\n    \"4_8\",\n]\ndef load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.",
        "detail": "scsc.datasets.loading",
        "documentation": {}
    },
    {
        "label": "Preprocessing",
        "kind": 6,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "class Preprocessing:\n    def __init__(self):\n        pass\n    def preprocessing_rawdata(\n        self,\n        adata,\n        Min_Genes=200,\n        Min_Cells=3,\n        Min_Mean=0.0125,\n        Max_Mean=3,",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 2,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "def preprocessing(\n    adata: AnnData,\n    Min_Genes: int = 200,\n    Min_Cells: int = 3,\n    Min_Mean: float = 0.0125,\n    Max_Mean: float = 3,\n    Min_Disp: float = 0.5,\n    N_pcs: int = 50,\n    n_Top_genes: int = 2000,\n    K: int = 10,",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing_cluster",
        "kind": 2,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "def preprocessing_cluster(adata,\n                        N_pcs=50,\n                        K=10,\n                        copy=False,\n                        resolution=0.5,\n                    ):\n        adata.raw = adata\n        # adata._inplace_subset_var(adata.var['highly_variable'])\n        sc.tl.pca(\n            adata,",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid",
        "kind": 2,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid(\n    adata,\n    dimension=\"pca\",\n    groupby=\"leiden\"\n):\n    if dimension == \"pca\":\n        X_dimension = \"X_pca\"\n    elif dimension == \"diffmap\":\n        X_dimension = \"X_diffmap\"\n    elif dimension == \"raw\":",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "set_initial_condition",
        "kind": 2,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "def set_initial_condition(\n        adata,\n        groupby=\"leiden\",\n        method=\"euclid\",\n        dimension=\"pca\",\n        copy=False\n    ):\n    if not isinstance(adata.X, np.ndarray):\n        adata_tmp = adata.copy()\n        adata_tmp.X = adata.X.toarray()",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid_for_genes",
        "kind": 2,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid_for_genes(\n        adata,\n        gene_list,\n        save_path=\"./\",\n    ):\n    groupby = adata.uns[\"capital\"][\"tree\"][\"annotation\"]\n    filtered_data = adata.raw.to_adata()[:, gene_list]\n    # filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    # adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "sort_data",
        "kind": 2,
        "importPath": "scsc.datasets.preprecossing",
        "description": "scsc.datasets.preprecossing",
        "peekOfCode": "def sort_data(\n    adata1,\n    adata2,\n    N_1=2000,\n    N_2=2000\n):\n    if N_1 is not None:\n        adata1 = adata1.raw.to_adata()\n        sc.pp.highly_variable_genes(adata1, n_top_genes=N_1)\n        adata1 = adata1[:, adata1.var['highly_variable']]",
        "detail": "scsc.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "kind": 2,
        "importPath": "scsc.datasets.triples",
        "description": "scsc.datasets.triples",
        "peekOfCode": "def samples_triples(n_nodes, num_samples):\n    num_samples = int(num_samples)\n    all_nodes = np.arange(n_nodes)\n    mesh = np.array(np.meshgrid(all_nodes, all_nodes))\n    pairs = mesh.T.reshape(-1, 2)\n    pairs = pairs[pairs[:, 0] < pairs[:, 1]]\n    n_pairs = pairs.shape[0]\n    if num_samples < n_pairs:\n        print(\"Generating all pairs subset\")\n        subset = np.random.choice(np.arange(n_pairs), num_samples, replace=False)",
        "detail": "scsc.datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "kind": 2,
        "importPath": "scsc.datasets.triples",
        "description": "scsc.datasets.triples",
        "peekOfCode": "def generate_all_triples(n_nodes):\n    triples = []\n    for n1 in tqdm(np.arange(n_nodes)):\n        for n2 in np.arange(n1 + 1, n_nodes):\n            for n3 in np.arange(n2 + 1, n_nodes):\n                triples += [(n1, n2, n3)]\n    return np.array(triples)",
        "detail": "scsc.datasets.triples",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "kind": 6,
        "importPath": "scsc.model.hyphc",
        "description": "scsc.model.hyphc",
        "peekOfCode": "class HypHC(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(HypHC, self).__init__()\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)",
        "detail": "scsc.model.hyphc",
        "documentation": {}
    },
    {
        "label": "RAdam",
        "kind": 6,
        "importPath": "scsc.optim.radam",
        "description": "scsc.optim.radam",
        "peekOfCode": "class RAdam(torch.optim.Adam):\n    \"\"\"Riemannian Adam with the same API as :class:`torch.optim.Adam`\n    Parameters\n    ----------\n    params : iterable\n        iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr : float (optional)\n        learning rate (default: 1e-3)\n    betas : Tuple[float, float] (optional)",
        "detail": "scsc.optim.radam",
        "documentation": {}
    },
    {
        "label": "copy_or_set_",
        "kind": 2,
        "importPath": "scsc.optim.radam",
        "description": "scsc.optim.radam",
        "peekOfCode": "def copy_or_set_(dest, source):\n    \"\"\"\n    A workaround to respect strides of :code:`dest` when copying :code:`source`\n    (https://github.com/geoopt/geoopt/issues/70)\n    Parameters\n    ----------\n    dest : torch.Tensor\n        Destination tensor where to store new data\n    source : torch.Tensor\n        Source data to put in the new tensor",
        "detail": "scsc.optim.radam",
        "documentation": {}
    },
    {
        "label": "isometric_transform",
        "kind": 2,
        "importPath": "scsc.utils.lca",
        "description": "scsc.utils.lca",
        "peekOfCode": "def isometric_transform(a, x):\n    \"\"\"Reflection (circle inversion of x through orthogonal circle centered at a).\"\"\"\n    r2 = torch.sum(a ** 2, dim=-1, keepdim=True) - 1.\n    u = x - a\n    return r2 / torch.sum(u ** 2, dim=-1, keepdim=True) * u + a\ndef reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"",
        "detail": "scsc.utils.lca",
        "documentation": {}
    },
    {
        "label": "reflection_center",
        "kind": 2,
        "importPath": "scsc.utils.lca",
        "description": "scsc.utils.lca",
        "peekOfCode": "def reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)",
        "detail": "scsc.utils.lca",
        "documentation": {}
    },
    {
        "label": "euc_reflection",
        "kind": 2,
        "importPath": "scsc.utils.lca",
        "description": "scsc.utils.lca",
        "peekOfCode": "def euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)\n    norm_a_sq = torch.sum(a ** 2, dim=-1, keepdim=True).clamp_min(MIN_NORM)\n    proj = xTa * a / norm_a_sq\n    return 2 * proj - x",
        "detail": "scsc.utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "kind": 2,
        "importPath": "scsc.utils.lca",
        "description": "scsc.utils.lca",
        "peekOfCode": "def hyp_lca(a, b, return_coord=True):\n    \"\"\"\n    Computes projection of the origin on the geodesic between a and b, at scale c\n    More optimized than hyp_lca1\n    \"\"\"\n    r = reflection_center(a)\n    b_inv = isometric_transform(r, b)\n    o_inv = a\n    o_inv_ref = euc_reflection(o_inv, b_inv)\n    o_ref = isometric_transform(r, o_inv_ref)",
        "detail": "scsc.utils.lca",
        "documentation": {}
    },
    {
        "label": "sl_np_mst",
        "kind": 2,
        "importPath": "scsc.utils.linkage",
        "description": "scsc.utils.linkage",
        "peekOfCode": "def sl_np_mst(similarities):\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst.mst(similarities, n)\n    uf = unionfind.UnionFind(n)\n    uf.merge(ij)\n    return uf.tree\ndef sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]",
        "detail": "scsc.utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "kind": 2,
        "importPath": "scsc.utils.linkage",
        "description": "scsc.utils.linkage",
        "peekOfCode": "def sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    return sl_np_mst(sim_mat.numpy())\n### Single linkage using naive union find\n# @profile\ndef nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1",
        "detail": "scsc.utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "kind": 2,
        "importPath": "scsc.utils.linkage",
        "description": "scsc.utils.linkage",
        "peekOfCode": "def nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1\n    similarities will be partitioned into buckets of geometrically increasing size\n    \"\"\"\n    n = xs.shape[0]\n    # Construct distance matrix (negative similarity; since numpy only has increasing sorting)\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    dist_mat = -S(xs0, xs1)  # (n, n)",
        "detail": "scsc.utils.linkage",
        "documentation": {}
    },
    {
        "label": "Artanh",
        "kind": 6,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "class Artanh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(-1 + 1e-5, 1 - 1e-5)\n        ctx.save_for_backward(x)\n        dtype = x.dtype\n        x = x.double()\n        return (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5).to(dtype)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "Arcosh",
        "kind": 6,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "class Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "Arsinh",
        "kind": 6,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "class Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors\n        return grad_output / (1 + input ** 2) ** 0.5",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "kind": 2,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "def arctanh(x):\n    return Artanh.apply(x)\ndef tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "kind": 2,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "def tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "kind": 2,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "def arcosh(x):\n    return Arcosh.apply(x)\ndef cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "cosh",
        "kind": 2,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "def cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "arsinh",
        "kind": 2,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "def arsinh(x):\n    return Arsinh.apply(x)\ndef sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "sinh",
        "kind": 2,
        "importPath": "scsc.utils.math",
        "description": "scsc.utils.math",
        "peekOfCode": "def sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "scsc.utils.math",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost_iterative",
        "kind": 2,
        "importPath": "scsc.utils.metrics",
        "description": "scsc.utils.metrics",
        "peekOfCode": "def dasgupta_cost_iterative(tree, similarities):\n    \"\"\" Non-recursive version of DC. Also works on non-binary trees \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    cost = [0] * n\n    desc = [None] * n  # intermediate computation: children of node\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "scsc.utils.metrics",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "kind": 2,
        "importPath": "scsc.utils.metrics",
        "description": "scsc.utils.metrics",
        "peekOfCode": "def dasgupta_cost(tree, similarities):\n    \"\"\" Non-recursive version of DC for binary trees.\n    Optimized for speed by reordering similarity matrix for locality\n    \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    n_leaves = len(similarities)\n    leaves = descendants_traversal(tree)\n    n_desc, left_desc = descendants_count(tree)\n    cost = [0] * n  # local cost for every node",
        "detail": "scsc.utils.metrics",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "lambda_",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)\ndef gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "gyration",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)\n    uv = (u * v).sum(dim=-1, keepdim=True)\n    uw = (u * w).sum(dim=-1, keepdim=True)\n    vw = (v * w).sum(dim=-1, keepdim=True)\n    a = - uw * v2 + vw + 2 * uv * vw\n    b = - vw * u2 - uw\n    d = 1 + 2 * uv + u2 * v2",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def ptransp(x, y, u):\n    \"\"\"Parallel transport.\"\"\"\n    lx = lambda_(x)\n    ly = lambda_(y)\n    return gyration(y, -x, u) * lx / ly\ndef expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1\ndef project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)\n    cond = norm > maxnorm\n    projected = x / norm * maxnorm\n    return torch.where(cond, projected, x)\ndef mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"\n    x2 = torch.sum(x * x, dim=-1, keepdim=True)\n    y2 = torch.sum(y * y, dim=-1, keepdim=True)\n    xy = torch.sum(x * y, dim=-1, keepdim=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    denom = 1 + 2 * xy + x2 * y2\n    return num / denom.clamp_min(MIN_NORM)\ndef mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"\n    normx = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    return tanh(t * arctanh(normx)) * x / normx\ndef get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "get_midpoint_o",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)\n    return 2 * arctanh(x_norm)\ndef hyp_dist_djj(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_djj",
        "kind": 2,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "def hyp_dist_djj(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "kind": 5,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "MIN_NORM = 1e-15\nBALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "BALL_EPS",
        "kind": 5,
        "importPath": "scsc.utils.poincare",
        "description": "scsc.utils.poincare",
        "peekOfCode": "BALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)",
        "detail": "scsc.utils.poincare",
        "documentation": {}
    },
    {
        "label": "str2bool",
        "kind": 2,
        "importPath": "scsc.utils.training",
        "description": "scsc.utils.training",
        "peekOfCode": "def str2bool(v):\n    \"\"\"Converts string to boolean.\"\"\"\n    if isinstance(v, bool):\n        return v\n    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError('Boolean value expected.')",
        "detail": "scsc.utils.training",
        "documentation": {}
    },
    {
        "label": "add_flags_from_config",
        "kind": 2,
        "importPath": "scsc.utils.training",
        "description": "scsc.utils.training",
        "peekOfCode": "def add_flags_from_config(parser, config_dict):\n    \"\"\"Adds a flag (and default value) to an ArgumentParser for each parameter in a config.\"\"\"\n    def OrNone(default):\n        def func(x):\n            # Convert \"none\" to proper None object\n            if x.lower() == \"none\":\n                return None\n            # If default is None (and x is not None), return x without conversion as str\n            elif default is None:\n                return str(x)",
        "detail": "scsc.utils.training",
        "documentation": {}
    },
    {
        "label": "hash_dict",
        "kind": 2,
        "importPath": "scsc.utils.training",
        "description": "scsc.utils.training",
        "peekOfCode": "def hash_dict(values):\n    \"\"\"Hash of dict key, value pairs.\"\"\"\n    m = hashlib.sha256()\n    keys = sorted(list(values.keys()))\n    for k in keys:\n        if k != \"seed\":\n            m.update(str(values[k]).encode('utf-8'))\n    return m.hexdigest()\ndef get_savedir(args):\n    \"\"\"Hash of args used for training.\"\"\"",
        "detail": "scsc.utils.training",
        "documentation": {}
    },
    {
        "label": "get_savedir",
        "kind": 2,
        "importPath": "scsc.utils.training",
        "description": "scsc.utils.training",
        "peekOfCode": "def get_savedir(args):\n    \"\"\"Hash of args used for training.\"\"\"\n    dir_hash = hash_dict(args.__dict__)\n    save_dir = os.path.join(os.environ[\"SAVEPATH\"], args.dataset, dir_hash)\n    return save_dir",
        "detail": "scsc.utils.training",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "kind": 2,
        "importPath": "scsc.utils.tree",
        "description": "scsc.utils.tree",
        "peekOfCode": "def descendants_traversal(tree):\n    \"\"\"Get all descendants non-recursively, in traversal order.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    traversal = []\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    is_leaf = [len(children[node]) == 0 for node in range(n)]\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "scsc.utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "kind": 2,
        "importPath": "scsc.utils.tree",
        "description": "scsc.utils.tree",
        "peekOfCode": "def descendants_count(tree):\n    \"\"\"For every node, count its number of descendant leaves, and the number of leaves before it.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    left = [0] * n\n    desc = [0] * n\n    leaf_idx = 0\n    children = [list(tree.neighbors(node))[::-1] for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:",
        "detail": "scsc.utils.tree",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition in numpy.\"\"\"\n    xy = np.sum(x * y, 1, keepdims=True)\n    x2 = np.sum(x * x, 1, keepdims=True)\n    y2 = np.sum(y * y, 1, keepdims=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    den = 1 + 2 * xy + x2 * y2\n    return num / den\ndef mobius_mul(x, t):\n    \"\"\"Mobius multiplication in numpy.\"\"\"",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius multiplication in numpy.\"\"\"\n    normx = np.sqrt(np.sum(x * x, 1, keepdims=True)) \n    return np.tanh(t * np.arctanh(normx)) * x / normx \ndef geodesic_fn(x, y, nb_points=100):\n    \"\"\"Get coordinates of points on the geodesic between x and y.\"\"\"\n    t = np.linspace(0, 1, nb_points)\n    x_rep = np.repeat(x.reshape((1, -1)), len(t), 0)\n    y_rep = np.repeat(y.reshape((1, -1)), len(t), 0)\n    t1 = mobius_add(-x_rep, y_rep)",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "geodesic_fn",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def geodesic_fn(x, y, nb_points=100):\n    \"\"\"Get coordinates of points on the geodesic between x and y.\"\"\"\n    t = np.linspace(0, 1, nb_points)\n    x_rep = np.repeat(x.reshape((1, -1)), len(t), 0)\n    y_rep = np.repeat(y.reshape((1, -1)), len(t), 0)\n    t1 = mobius_add(-x_rep, y_rep)\n    t2 = mobius_mul(t1, t.reshape((-1, 1)))\n    return mobius_add(x_rep, t2)\ndef plot_geodesic(x, y, ax):\n    \"\"\"Plots geodesic between x and y.\"\"\"",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_geodesic",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def plot_geodesic(x, y, ax):\n    \"\"\"Plots geodesic between x and y.\"\"\"\n    points = geodesic_fn(x, y)\n    ax.plot(points[:, 0]*20, points[:, 1]*20, color='black', linewidth=1.5, alpha=1)\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)\n            if left_leaf and right_leaf:\n                pass",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"Computes the hyperbolic LCA in numpy.\"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    print(embeddings,\"djj\")\n    for n1, n2 in tree.edges():",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"random color assignment for label classes.\"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()\n        colors[k] = (r, g, b)\n    return [colors[k] for k in y]",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves_djj_1",
        "kind": 2,
        "importPath": "scsc.utils.visualization",
        "description": "scsc.utils.visualization",
        "peekOfCode": "def plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "scsc.utils.visualization",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "scsc.alignment",
        "description": "scsc.alignment",
        "peekOfCode": "class node:\n    def __init__(self,value=None,son=[],name=''):\n        self.value = value;\n        self.son = son;\n        self.name =name;\n        self.f = None;\n        self.depth=0;\n        self.subson= [];\n    def __repr__(self):\n        return self.name",
        "detail": "scsc.alignment",
        "documentation": {}
    },
    {
        "label": "tree_alignment",
        "kind": 6,
        "importPath": "scsc.alignment",
        "description": "scsc.alignment",
        "peekOfCode": "class tree_alignment:\n    def __init__(self,root1,root2,cost1):\n        self.cost1 = cost1;\n        self.dp = dict();\n        self.forestdp = dict();\n        self.anslist = [];\n        self.ansnodes = [];\n        self.root1 = root1;\n        self.root2 = root2;\n        self.minn = math.inf;",
        "detail": "scsc.alignment",
        "documentation": {}
    },
    {
        "label": "show_graph",
        "kind": 6,
        "importPath": "scsc.alignment",
        "description": "scsc.alignment",
        "peekOfCode": "class show_graph:\n    def __init__(self,ans,root1,root2):\n        self.ans = ans;\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];",
        "detail": "scsc.alignment",
        "documentation": {}
    },
    {
        "label": "show_tree",
        "kind": 6,
        "importPath": "scsc.alignment",
        "description": "scsc.alignment",
        "peekOfCode": "class show_tree:\n    def __init__(self,root1):\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];\n        self.cnt = 0;",
        "detail": "scsc.alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment",
        "kind": 2,
        "importPath": "scsc.alignment",
        "description": "scsc.alignment",
        "peekOfCode": "def run_alignment(folder_path1,folder_path2):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    pos_2 = pd.read_csv(folder_path2+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    edge_2 = np.load(folder_path2+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    mer2 = np.load(folder_path2+\"datamerge.npy\");\n    n1 = len(pos_1)\n    n2 = len(pos_2)\n    root1 = -1;",
        "detail": "scsc.alignment",
        "documentation": {}
    },
    {
        "label": "show_the_tree",
        "kind": 2,
        "importPath": "scsc.alignment",
        "description": "scsc.alignment",
        "peekOfCode": "def show_the_tree(folder_path1):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    n1 = len(pos_1)\n    root1 = -1;\n    for i,j in edge_1:\n        root1 = max(root1,i);\n    length1 = root1 + 1;    \n    nodes1 = [node(name=str(i),son=[]) for i in range(length1)]",
        "detail": "scsc.alignment",
        "documentation": {}
    },
    {
        "label": "alignment_process",
        "kind": 2,
        "importPath": "scsc.core",
        "description": "scsc.core",
        "peekOfCode": "def alignment_process(cell_path1,cell_path2,celltype_path1,celltype_path2,celltype_column1,celltype_column2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2):\n    loss = merge_cells_by_radius(cell_path1,celltype_path1,celltype_column1,folder_path1,radius1)\n    print(\"cell merge loss for dataset1: {}\".format(loss))\n    loss = merge_cells_by_radius(cell_path2,celltype_path2,celltype_column2,folder_path2,radius2)\n    print(\"cell merge loss for dataset2: {}\".format(loss))\n    adata1 = pd.read_csv(folder_path1+\"merge_cell_data.csv\")\n    cell_meta = pd.read_csv(folder_path1+\"merge_cell_meta.csv\")\n    cell_meta = cell_meta.set_index(cell_meta.columns[0])\n    adata1 = adata1.set_index(adata1.columns[0])\n    adata1 = anndata.AnnData(adata1)",
        "detail": "scsc.core",
        "documentation": {}
    },
    {
        "label": {
            "name": "",
            "kind": 6,
            "peekOfCode": "class  UnionFind:\n    def __init__(self, n , pos , c):\n        self.n = n\n        self.pos = pos\n        self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self.vis = [0 for i in range(2*n-1)]\n        self.vis2 = [0 for i in range(2*n-1)]\n        self.mer = [-1 for i in range(2*n-1)]"
        },
        "kind": 6,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "class  UnionFind:\n    def __init__(self, n , pos , c):\n        self.n = n\n        self.pos = pos\n        self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self.vis = [0 for i in range(2*n-1)]\n        self.vis2 = [0 for i in range(2*n-1)]\n        self.mer = [-1 for i in range(2*n-1)]",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"Computes the hyperbolic LCA in numpy.\"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)\n            if left_leaf and right_leaf:\n                pass",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def train(model,dataloader,optimizer,similarities,epoches):\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n    total_loss = 0.0\n    with tqdm(total=len(dataloader), unit='ex') as bar:\n        for step, (triple_ids, triple_similarities) in enumerate(dataloader):\n            # triple_ids = triple_ids.cuda()",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "dist",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def dist(x,y):\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));\ndef plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves_djj_1",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "sl_np_mst_ij",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def sl_np_mst_ij(xs, S):\n    xs = project(xs).detach().cpu()\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    similarities = sim_mat.numpy()\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst.mst(similarities, n)\n    return ij",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"random color assignment for label classes.\"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()\n        colors[k] = (r, g, b)\n    return [colors[k] for k in y]",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "search_tree",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def search_tree(now,c,merge_list):\n    if(len(now.son) != 2):\n        return now;\n    lson = search_tree(now.son[0],c,merge_list);\n    now.son[0] = lson;\n    rson = search_tree(now.son[1],c,merge_list);\n    now.son[1] = rson\n    if(np.linalg.norm(lson.value-rson.value)<=c):\n        if(len(lson.son)>1 and len(rson.son)>1):\n            pass",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "search_merge_tree",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def search_merge_tree(now,ids,save_path,values,fathers):\n    fathers.append(ids);\n    values.append(now.name);\n    now_id = len(values)-1;\n    for son in now.son:\n        search_merge_tree(son,now_id,save_path,values,fathers)\ndef cccfg(\n        adata,\n        save_path=\"./\",\n    ):",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "cccfg",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def cccfg(\n        adata,\n        save_path=\"./\",\n    ):\n    groupby = adata.uns[\"capital\"][\"tree\"][\"annotation\"]\n    filtered_data = adata.raw.to_adata()[:]\n    filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))\n    clustername = filtered_data.obs[groupby].unique().tolist()",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "get_Hyper_tree",
        "kind": 2,
        "importPath": "scsc.hyper",
        "description": "scsc.hyper",
        "peekOfCode": "def get_Hyper_tree(adata1,data_path,start,end,lable,epoches,model_path=None,save_path='./',c=-1):\n    np.random.seed(1234)\n    torch.manual_seed(1234)\n    # x, y_true, similarities = load_data('../../../cityu/HypHC/data/4_8/4_8.data',start,end,lable)\n    x, y_true, similarities = load_data(data_path,start,end,lable)\n    print(\"{} length:{}\".format(data_path,len(y_true)));\n    dataset = HCDataset(x, y_true, similarities, num_samples=50000)\n    dataloader = data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n    if(model_path ==None):\n        model = HypHC(dataset.n_nodes, 2, 5e-2, 5e-2 ,0.999)",
        "detail": "scsc.hyper",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "scsc.read_data",
        "description": "scsc.read_data",
        "peekOfCode": "def read_file(file_path, file_label):\n    '''\n    Read data with given path.\n    args:\n        file_path: file path.\n        file_label: the file label to raise exception.\n    return:\n        the read file.\n    '''\n    try:",
        "detail": "scsc.read_data",
        "documentation": {}
    },
    {
        "label": "read_training_data",
        "kind": 2,
        "importPath": "scsc.read_data",
        "description": "scsc.read_data",
        "peekOfCode": "def read_training_data(sc_path,meta_path,marker,sc_nor,out_dir):\n    \"\"\"read sc data and meta information to train model.\n    args:\n        sc_path:    sc-rna data path.\n        meta_path:  meta data with cell type information path.\n        marker:     the marker gene list if provided or none.\n        sc_nor:     Boolean, true for using preprocessing on sc data.\n        out_path:   the dir to store the result files.\n    \"\"\"\n    warnings.filterwarnings(action='ignore', category=FutureWarning) ",
        "detail": "scsc.read_data",
        "documentation": {}
    },
    {
        "label": "merge_cells_by_radius",
        "kind": 2,
        "importPath": "scsc.read_data",
        "description": "scsc.read_data",
        "peekOfCode": "def merge_cells_by_radius(cell_path,celltype_path,celltype_column,folder_path,radius):\n    datas = pd.read_csv(cell_path)\n    datas = datas.set_index(datas.columns[0])\n    celltype = pd.read_csv(celltype_path,sep=\"\\t\")\n    adata = datas.copy()\n    adata.loc[list(celltype['Cell']), 'Celltype'] = list(celltype[celltype_column])\n    adata\n    ans_value = []\n    ans_label = []\n    true_label = [];",
        "detail": "scsc.read_data",
        "documentation": {}
    },
    {
        "label": "build_hyper_tree",
        "kind": 2,
        "importPath": "scsc.read_data",
        "description": "scsc.read_data",
        "peekOfCode": "def build_hyper_tree(folder_path):\n    pos_1 = pd.read_csv(folder_path + 'datas.csv')\n    pos = pos_1.set_index(pos_1.columns[0]).values\n    edge = np.load(folder_path + \"datalink.npy\");\n    father_name = np.load(folder_path + \"dataxy.npy\")\n    father_name = father_name.astype(np.int)\n    n = len(edge)\n    n_points = len(pos);\n    nodes = [node(name=str(i),son=[]) for i in range(n)];\n    for i in range(n):",
        "detail": "scsc.read_data",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "scsc.test",
        "description": "scsc.test",
        "peekOfCode": "def run(data1_path,data2_path,folder1_path,folder2_path):\n    # adata1 = sc.read(\"../../../capital/docs/tutorials/BRCA_EMTAB8107_expression_processed.h5ad\")\n    # adata2 = sc.read(\"../../../capital/docs/tutorials/BRCA_GSE114727_inDrop_expression_processed.h5ad\") \n    adata1 = sc.read(data1_path)\n    adata2 = sc.read(data2_path)\n    # preprocessing()\n    # sc.pl.umap(adata1, color=\"leiden\")\n    set_initial_condition(adata1)\n    set_initial_condition(adata2)\n    adata2.uns.pop(\"log1p\")",
        "detail": "scsc.test",
        "documentation": {}
    },
    {
        "label": "HCDataset",
        "kind": 6,
        "importPath": "stst.datasets.hc_dataset",
        "description": "stst.datasets.hc_dataset",
        "peekOfCode": "class HCDataset(data.Dataset):\n    \"\"\"Hierarchical clustering dataset.\"\"\"\n    def __init__(self, features, labels, similarities, num_samples):\n        \"\"\"Creates Hierarchical Clustering dataset with triples.\n        @param labels: ground truth labels\n        @type labels: np.array of shape (n_datapoints,)\n        @param similarities: pairwise similarities between datapoints\n        @type similarities: np.array of shape (n_datapoints, n_datapoints)\n        \"\"\"\n        self.features = features",
        "detail": "stst.datasets.hc_dataset",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "stst.datasets.loading",
        "description": "stst.datasets.loading",
        "peekOfCode": "def load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.\n    @param dataset: dataset name\n    @type dataset: str\n    @param normalize: whether to normalize features or not\n    @type normalize: boolean\n    @return: feature vectors, labels, and pairwise similarities computed with cosine similarity\n    @rtype: Tuple[np.array, np.array, np.array]\n    \"\"\"\n    # if dataset in UCI_DATASETS:",
        "detail": "stst.datasets.loading",
        "documentation": {}
    },
    {
        "label": "load_uci_data",
        "kind": 2,
        "importPath": "stst.datasets.loading",
        "description": "stst.datasets.loading",
        "peekOfCode": "def load_uci_data(dataset,start_idx,end_idx,label_idx):\n    \"\"\"Loads data from UCI repository.\n    @param dataset: UCI dataset name\n    @return: feature vectors, labels\n    @rtype: Tuple[np.array, np.array]\n    \"\"\"\n    x = []\n    y = []\n    ids = {\n        \"zoo\": (1, 17, -1),",
        "detail": "stst.datasets.loading",
        "documentation": {}
    },
    {
        "label": "UCI_DATASETS",
        "kind": 5,
        "importPath": "stst.datasets.loading",
        "description": "stst.datasets.loading",
        "peekOfCode": "UCI_DATASETS = [\n    \"glass\",\n    \"zoo\",\n    \"iris\",\n    \"sc\",\n    \"4_7\",\n    \"4_8\",\n]\ndef load_data(dataset, start_idx,end_idx,label_idx,normalize=True):\n    \"\"\"Load dataset.",
        "detail": "stst.datasets.loading",
        "documentation": {}
    },
    {
        "label": "Preprocessing",
        "kind": 6,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "class Preprocessing:\n    def __init__(self):\n        pass\n    def preprocessing_rawdata(\n        self,\n        adata,\n        Min_Genes=200,\n        Min_Cells=3,\n        Min_Mean=0.0125,\n        Max_Mean=3,",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def preprocessing(\n    adata: AnnData,\n    Min_Genes: int = 200,\n    Min_Cells: int = 3,\n    Min_Mean: float = 0.0125,\n    Max_Mean: float = 3,\n    Min_Disp: float = 0.5,\n    N_pcs: int = 50,\n    n_Top_genes: int = 2000,\n    K: int = 10,",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing_cluster",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def preprocessing_cluster(adata,\n                        N_pcs=50,\n                        K=10,\n                        copy=False,\n                        resolution=0.5,\n                    ):\n        adata.raw = adata\n        # adata._inplace_subset_var(adata.var['highly_variable'])\n        sc.tl.pca(\n            adata,",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "preprocessing_st_cluster",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def preprocessing_st_cluster(adata,\n                        N_pcs=20,\n                        K=10,\n                        copy=False,\n                        resolution=0.5,\n                    ):\n        adata.raw = adata\n        # adata._inplace_subset_var(adata.var['highly_variable'])\n        # sc.tl.pca(\n        #     adata,",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid(\n    adata,\n    dimension=\"pca\",\n    groupby=\"leiden\"\n):\n    if dimension == \"pca\":\n        X_dimension = \"X_pca\"\n    elif dimension == \"diffmap\":\n        X_dimension = \"X_diffmap\"\n    elif dimension == \"raw\":",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "set_initial_condition",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def set_initial_condition(\n        adata,\n        groupby=\"leiden\",\n        method=\"euclid\",\n        dimension=\"pca\",\n        copy=False\n    ):\n    if not isinstance(adata.X, np.ndarray):\n        adata_tmp = adata.copy()\n        adata_tmp.X = adata.X.toarray()",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "calculate_cluster_centroid_for_genes",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def calculate_cluster_centroid_for_genes(\n        adata,\n        gene_list,\n        save_path=\"./\",\n    ):\n    groupby = adata.uns[\"capital\"][\"tree\"][\"annotation\"]\n    filtered_data = adata.raw.to_adata()[:, gene_list]\n    # filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    # adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "sort_data",
        "kind": 2,
        "importPath": "stst.datasets.preprecossing",
        "description": "stst.datasets.preprecossing",
        "peekOfCode": "def sort_data(\n    adata1,\n    adata2,\n    N_1=2000,\n    N_2=2000\n):\n    if N_1 is not None:\n        adata1 = adata1.raw.to_adata()\n        sc.pp.highly_variable_genes(adata1, n_top_genes=N_1)\n        adata1 = adata1[:, adata1.var['highly_variable']]",
        "detail": "stst.datasets.preprecossing",
        "documentation": {}
    },
    {
        "label": "samples_triples",
        "kind": 2,
        "importPath": "stst.datasets.triples",
        "description": "stst.datasets.triples",
        "peekOfCode": "def samples_triples(n_nodes, num_samples):\n    num_samples = int(num_samples)\n    all_nodes = np.arange(n_nodes)\n    mesh = np.array(np.meshgrid(all_nodes, all_nodes))\n    pairs = mesh.T.reshape(-1, 2)\n    pairs = pairs[pairs[:, 0] < pairs[:, 1]]\n    n_pairs = pairs.shape[0]\n    if num_samples < n_pairs:\n        print(\"Generating all pairs subset\")\n        subset = np.random.choice(np.arange(n_pairs), num_samples, replace=False)",
        "detail": "stst.datasets.triples",
        "documentation": {}
    },
    {
        "label": "generate_all_triples",
        "kind": 2,
        "importPath": "stst.datasets.triples",
        "description": "stst.datasets.triples",
        "peekOfCode": "def generate_all_triples(n_nodes):\n    triples = []\n    for n1 in tqdm(np.arange(n_nodes)):\n        for n2 in np.arange(n1 + 1, n_nodes):\n            for n3 in np.arange(n2 + 1, n_nodes):\n                triples += [(n1, n2, n3)]\n    return np.array(triples)",
        "detail": "stst.datasets.triples",
        "documentation": {}
    },
    {
        "label": "HypHC",
        "kind": 6,
        "importPath": "stst.model.hyphc",
        "description": "stst.model.hyphc",
        "peekOfCode": "class HypHC(nn.Module):\n    \"\"\"\n    Hyperbolic embedding model for hierarchical clustering.\n    \"\"\"\n    def __init__(self, n_nodes=1, rank=2, temperature=0.05, init_size=1e-3, max_scale=1. - 1e-3):\n        super(HypHC, self).__init__()\n        self.n_nodes = n_nodes\n        self.embeddings = nn.Embedding(n_nodes, rank)\n        self.temperature = temperature\n        self.scale = nn.Parameter(torch.Tensor([init_size]), requires_grad=True)",
        "detail": "stst.model.hyphc",
        "documentation": {}
    },
    {
        "label": "RAdam",
        "kind": 6,
        "importPath": "stst.optim.radam",
        "description": "stst.optim.radam",
        "peekOfCode": "class RAdam(torch.optim.Adam):\n    \"\"\"Riemannian Adam with the same API as :class:`torch.optim.Adam`\n    Parameters\n    ----------\n    params : iterable\n        iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr : float (optional)\n        learning rate (default: 1e-3)\n    betas : Tuple[float, float] (optional)",
        "detail": "stst.optim.radam",
        "documentation": {}
    },
    {
        "label": "copy_or_set_",
        "kind": 2,
        "importPath": "stst.optim.radam",
        "description": "stst.optim.radam",
        "peekOfCode": "def copy_or_set_(dest, source):\n    \"\"\"\n    A workaround to respect strides of :code:`dest` when copying :code:`source`\n    (https://github.com/geoopt/geoopt/issues/70)\n    Parameters\n    ----------\n    dest : torch.Tensor\n        Destination tensor where to store new data\n    source : torch.Tensor\n        Source data to put in the new tensor",
        "detail": "stst.optim.radam",
        "documentation": {}
    },
    {
        "label": "isometric_transform",
        "kind": 2,
        "importPath": "stst.utils.lca",
        "description": "stst.utils.lca",
        "peekOfCode": "def isometric_transform(a, x):\n    \"\"\"Reflection (circle inversion of x through orthogonal circle centered at a).\"\"\"\n    r2 = torch.sum(a ** 2, dim=-1, keepdim=True) - 1.\n    u = x - a\n    return r2 / torch.sum(u ** 2, dim=-1, keepdim=True) * u + a\ndef reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"",
        "detail": "stst.utils.lca",
        "documentation": {}
    },
    {
        "label": "reflection_center",
        "kind": 2,
        "importPath": "stst.utils.lca",
        "description": "stst.utils.lca",
        "peekOfCode": "def reflection_center(mu):\n    \"\"\"Center of inversion circle.\"\"\"\n    return mu / torch.sum(mu ** 2, dim=-1, keepdim=True)\ndef euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)",
        "detail": "stst.utils.lca",
        "documentation": {}
    },
    {
        "label": "euc_reflection",
        "kind": 2,
        "importPath": "stst.utils.lca",
        "description": "stst.utils.lca",
        "peekOfCode": "def euc_reflection(x, a):\n    \"\"\"\n    Euclidean reflection (also hyperbolic) of x\n    Along the geodesic that goes through a and the origin\n    (straight line)\n    \"\"\"\n    xTa = torch.sum(x * a, dim=-1, keepdim=True)\n    norm_a_sq = torch.sum(a ** 2, dim=-1, keepdim=True).clamp_min(MIN_NORM)\n    proj = xTa * a / norm_a_sq\n    return 2 * proj - x",
        "detail": "stst.utils.lca",
        "documentation": {}
    },
    {
        "label": "hyp_lca",
        "kind": 2,
        "importPath": "stst.utils.lca",
        "description": "stst.utils.lca",
        "peekOfCode": "def hyp_lca(a, b, return_coord=True):\n    \"\"\"\n    Computes projection of the origin on the geodesic between a and b, at scale c\n    More optimized than hyp_lca1\n    \"\"\"\n    r = reflection_center(a)\n    b_inv = isometric_transform(r, b)\n    o_inv = a\n    o_inv_ref = euc_reflection(o_inv, b_inv)\n    o_ref = isometric_transform(r, o_inv_ref)",
        "detail": "stst.utils.lca",
        "documentation": {}
    },
    {
        "label": "sl_np_mst",
        "kind": 2,
        "importPath": "stst.utils.linkage",
        "description": "stst.utils.linkage",
        "peekOfCode": "def sl_np_mst(similarities):\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst.mst(similarities, n)\n    uf = unionfind.UnionFind(n)\n    uf.merge(ij)\n    return uf.tree\ndef sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]",
        "detail": "stst.utils.linkage",
        "documentation": {}
    },
    {
        "label": "sl_from_embeddings",
        "kind": 2,
        "importPath": "stst.utils.linkage",
        "description": "stst.utils.linkage",
        "peekOfCode": "def sl_from_embeddings(xs, S):\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    return sl_np_mst(sim_mat.numpy())\n### Single linkage using naive union find\n# @profile\ndef nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1",
        "detail": "stst.utils.linkage",
        "documentation": {}
    },
    {
        "label": "nn_merge_uf_fast_np",
        "kind": 2,
        "importPath": "stst.utils.linkage",
        "description": "stst.utils.linkage",
        "peekOfCode": "def nn_merge_uf_fast_np(xs, S, partition_ratio=None, verbose=False):\n    \"\"\" Uses Cython union find and numpy sorting\n    partition_ratio: either None, or real number > 1\n    similarities will be partitioned into buckets of geometrically increasing size\n    \"\"\"\n    n = xs.shape[0]\n    # Construct distance matrix (negative similarity; since numpy only has increasing sorting)\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    dist_mat = -S(xs0, xs1)  # (n, n)",
        "detail": "stst.utils.linkage",
        "documentation": {}
    },
    {
        "label": "Artanh",
        "kind": 6,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "class Artanh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(-1 + 1e-5, 1 - 1e-5)\n        ctx.save_for_backward(x)\n        dtype = x.dtype\n        x = x.double()\n        return (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5).to(dtype)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "Arcosh",
        "kind": 6,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "class Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "Arsinh",
        "kind": 6,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "class Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors\n        return grad_output / (1 + input ** 2) ** 0.5",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "arctanh",
        "kind": 2,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "def arctanh(x):\n    return Artanh.apply(x)\ndef tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "tanh",
        "kind": 2,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "def tanh(x):\n    return x.clamp(-15, 15).tanh()\n# ################# cosh ########################\nclass Arcosh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        x = x.clamp(min=1 + 1e-7)\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(z.pow(2) - 1)).clamp_min_(1e-15).log_().to(x.dtype)",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "arcosh",
        "kind": 2,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "def arcosh(x):\n    return Arcosh.apply(x)\ndef cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "cosh",
        "kind": 2,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "def cosh(x, clamp=15):\n    return x.clamp(-clamp, clamp).cosh()\n# ################# sinh ########################\nclass Arsinh(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        z = x.double()\n        return (z + torch.sqrt_(1 + z.pow(2))).clamp_min_(1e-15).log_().to(x.dtype)\n    @staticmethod",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "arsinh",
        "kind": 2,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "def arsinh(x):\n    return Arsinh.apply(x)\ndef sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "sinh",
        "kind": 2,
        "importPath": "stst.utils.math",
        "description": "stst.utils.math",
        "peekOfCode": "def sinh(x, clamp=15):\n    return x.clamp(-clamp, clamp).sinh()",
        "detail": "stst.utils.math",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost_iterative",
        "kind": 2,
        "importPath": "stst.utils.metrics",
        "description": "stst.utils.metrics",
        "peekOfCode": "def dasgupta_cost_iterative(tree, similarities):\n    \"\"\" Non-recursive version of DC. Also works on non-binary trees \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    cost = [0] * n\n    desc = [None] * n  # intermediate computation: children of node\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "stst.utils.metrics",
        "documentation": {}
    },
    {
        "label": "dasgupta_cost",
        "kind": 2,
        "importPath": "stst.utils.metrics",
        "description": "stst.utils.metrics",
        "peekOfCode": "def dasgupta_cost(tree, similarities):\n    \"\"\" Non-recursive version of DC for binary trees.\n    Optimized for speed by reordering similarity matrix for locality\n    \"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    n_leaves = len(similarities)\n    leaves = descendants_traversal(tree)\n    n_desc, left_desc = descendants_count(tree)\n    cost = [0] * n  # local cost for every node",
        "detail": "stst.utils.metrics",
        "documentation": {}
    },
    {
        "label": "egrad2rgrad",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "lambda_",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)\ndef inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "inner",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def inner(x, u, v=None):\n    \"\"\"Computes inner product for two tangent vectors.\"\"\"\n    if v is None:\n        v = u\n    lx = lambda_(x)\n    return lx ** 2 * (u * v).sum(dim=-1, keepdim=True)\ndef gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "gyration",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def gyration(u, v, w):\n    \"\"\"Gyration.\"\"\"\n    u2 = u.pow(2).sum(dim=-1, keepdim=True)\n    v2 = v.pow(2).sum(dim=-1, keepdim=True)\n    uv = (u * v).sum(dim=-1, keepdim=True)\n    uw = (u * w).sum(dim=-1, keepdim=True)\n    vw = (v * w).sum(dim=-1, keepdim=True)\n    a = - uw * v2 + vw + 2 * uv * vw\n    b = - vw * u2 - uw\n    d = 1 + 2 * uv + u2 * v2",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "ptransp",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def ptransp(x, y, u):\n    \"\"\"Parallel transport.\"\"\"\n    lx = lambda_(x)\n    ly = lambda_(y)\n    return gyration(y, -x, u) * lx / ly\ndef expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "expmap",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def expmap(u, p):\n    u_norm = u.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    second_term = tanh(lambda_(p) * u_norm / 2) * u / u_norm\n    gamma_1 = mobius_add(p, second_term)\n    return gamma_1\ndef project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def project(x):\n    \"\"\"Projects points on the manifold.\"\"\"\n    norm = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    eps = BALL_EPS[x.dtype]\n    maxnorm = (1 - eps)\n    cond = norm > maxnorm\n    projected = x / norm * maxnorm\n    return torch.where(cond, projected, x)\ndef mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition.\"\"\"\n    x2 = torch.sum(x * x, dim=-1, keepdim=True)\n    y2 = torch.sum(y * y, dim=-1, keepdim=True)\n    xy = torch.sum(x * y, dim=-1, keepdim=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    denom = 1 + 2 * xy + x2 * y2\n    return num / denom.clamp_min(MIN_NORM)\ndef mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius scalar multiplication.\"\"\"\n    normx = x.norm(dim=-1, p=2, keepdim=True).clamp_min(MIN_NORM)\n    return tanh(t * arctanh(normx)) * x / normx\ndef get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "get_midpoint_o",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def get_midpoint_o(x):\n    \"\"\"\n    Computes hyperbolic midpoint between x and the origin.\n    \"\"\"\n    return mobius_mul(x, 0.5)\ndef hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_o",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def hyp_dist_o(x):\n    \"\"\"\n    Computes hyperbolic distance between x and the origin.\n    \"\"\"\n    x_norm = x.norm(dim=-1, p=2, keepdim=True)\n    return 2 * arctanh(x_norm)\ndef hyp_dist_djj(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "hyp_dist_djj",
        "kind": 2,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "def hyp_dist_djj(x,y):\n    \"\"\"\n    hyperbolic distance\n    \"\"\"\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "MIN_NORM",
        "kind": 5,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "MIN_NORM = 1e-15\nBALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "BALL_EPS",
        "kind": 5,
        "importPath": "stst.utils.poincare",
        "description": "stst.utils.poincare",
        "peekOfCode": "BALL_EPS = {torch.float32: 4e-3, torch.float64: 1e-5}\ndef egrad2rgrad(p, dp):\n    \"\"\"Converts Euclidean gradient to Hyperbolic gradient.\"\"\"\n    lambda_p = lambda_(p)\n    dp /= lambda_p.pow(2)\n    return dp\ndef lambda_(x):\n    \"\"\"Computes the conformal factor.\"\"\"\n    x_sqnorm = torch.sum(x.data.pow(2), dim=-1, keepdim=True)\n    return 2 / (1. - x_sqnorm).clamp_min(MIN_NORM)",
        "detail": "stst.utils.poincare",
        "documentation": {}
    },
    {
        "label": "str2bool",
        "kind": 2,
        "importPath": "stst.utils.training",
        "description": "stst.utils.training",
        "peekOfCode": "def str2bool(v):\n    \"\"\"Converts string to boolean.\"\"\"\n    if isinstance(v, bool):\n        return v\n    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError('Boolean value expected.')",
        "detail": "stst.utils.training",
        "documentation": {}
    },
    {
        "label": "add_flags_from_config",
        "kind": 2,
        "importPath": "stst.utils.training",
        "description": "stst.utils.training",
        "peekOfCode": "def add_flags_from_config(parser, config_dict):\n    \"\"\"Adds a flag (and default value) to an ArgumentParser for each parameter in a config.\"\"\"\n    def OrNone(default):\n        def func(x):\n            # Convert \"none\" to proper None object\n            if x.lower() == \"none\":\n                return None\n            # If default is None (and x is not None), return x without conversion as str\n            elif default is None:\n                return str(x)",
        "detail": "stst.utils.training",
        "documentation": {}
    },
    {
        "label": "hash_dict",
        "kind": 2,
        "importPath": "stst.utils.training",
        "description": "stst.utils.training",
        "peekOfCode": "def hash_dict(values):\n    \"\"\"Hash of dict key, value pairs.\"\"\"\n    m = hashlib.sha256()\n    keys = sorted(list(values.keys()))\n    for k in keys:\n        if k != \"seed\":\n            m.update(str(values[k]).encode('utf-8'))\n    return m.hexdigest()\ndef get_savedir(args):\n    \"\"\"Hash of args used for training.\"\"\"",
        "detail": "stst.utils.training",
        "documentation": {}
    },
    {
        "label": "get_savedir",
        "kind": 2,
        "importPath": "stst.utils.training",
        "description": "stst.utils.training",
        "peekOfCode": "def get_savedir(args):\n    \"\"\"Hash of args used for training.\"\"\"\n    dir_hash = hash_dict(args.__dict__)\n    save_dir = os.path.join(os.environ[\"SAVEPATH\"], args.dataset, dir_hash)\n    return save_dir",
        "detail": "stst.utils.training",
        "documentation": {}
    },
    {
        "label": "descendants_traversal",
        "kind": 2,
        "importPath": "stst.utils.tree",
        "description": "stst.utils.tree",
        "peekOfCode": "def descendants_traversal(tree):\n    \"\"\"Get all descendants non-recursively, in traversal order.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    traversal = []\n    children = [list(tree.neighbors(node)) for node in range(n)]  # children remaining to process\n    is_leaf = [len(children[node]) == 0 for node in range(n)]\n    stack = [root]\n    while len(stack) > 0:\n        node = stack[-1]",
        "detail": "stst.utils.tree",
        "documentation": {}
    },
    {
        "label": "descendants_count",
        "kind": 2,
        "importPath": "stst.utils.tree",
        "description": "stst.utils.tree",
        "peekOfCode": "def descendants_count(tree):\n    \"\"\"For every node, count its number of descendant leaves, and the number of leaves before it.\"\"\"\n    n = len(list(tree.nodes()))\n    root = n - 1\n    left = [0] * n\n    desc = [0] * n\n    leaf_idx = 0\n    children = [list(tree.neighbors(node))[::-1] for node in range(n)]  # children remaining to process\n    stack = [root]\n    while len(stack) > 0:",
        "detail": "stst.utils.tree",
        "documentation": {}
    },
    {
        "label": "mobius_add",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def mobius_add(x, y):\n    \"\"\"Mobius addition in numpy.\"\"\"\n    xy = np.sum(x * y, 1, keepdims=True)\n    x2 = np.sum(x * x, 1, keepdims=True)\n    y2 = np.sum(y * y, 1, keepdims=True)\n    num = (1 + 2 * xy + y2) * x + (1 - x2) * y\n    den = 1 + 2 * xy + x2 * y2\n    return num / den\ndef mobius_mul(x, t):\n    \"\"\"Mobius multiplication in numpy.\"\"\"",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "mobius_mul",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def mobius_mul(x, t):\n    \"\"\"Mobius multiplication in numpy.\"\"\"\n    normx = np.sqrt(np.sum(x * x, 1, keepdims=True)) \n    return np.tanh(t * np.arctanh(normx)) * x / normx \ndef geodesic_fn(x, y, nb_points=100):\n    \"\"\"Get coordinates of points on the geodesic between x and y.\"\"\"\n    t = np.linspace(0, 1, nb_points)\n    x_rep = np.repeat(x.reshape((1, -1)), len(t), 0)\n    y_rep = np.repeat(y.reshape((1, -1)), len(t), 0)\n    t1 = mobius_add(-x_rep, y_rep)",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "geodesic_fn",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def geodesic_fn(x, y, nb_points=100):\n    \"\"\"Get coordinates of points on the geodesic between x and y.\"\"\"\n    t = np.linspace(0, 1, nb_points)\n    x_rep = np.repeat(x.reshape((1, -1)), len(t), 0)\n    y_rep = np.repeat(y.reshape((1, -1)), len(t), 0)\n    t1 = mobius_add(-x_rep, y_rep)\n    t2 = mobius_mul(t1, t.reshape((-1, 1)))\n    return mobius_add(x_rep, t2)\ndef plot_geodesic(x, y, ax):\n    \"\"\"Plots geodesic between x and y.\"\"\"",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_geodesic",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def plot_geodesic(x, y, ax):\n    \"\"\"Plots geodesic between x and y.\"\"\"\n    points = geodesic_fn(x, y)\n    ax.plot(points[:, 0]*20, points[:, 1]*20, color='black', linewidth=1.5, alpha=1)\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)\n            if left_leaf and right_leaf:\n                pass",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"Computes the hyperbolic LCA in numpy.\"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def plot_tree_from_leaves(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    print(embeddings,\"djj\")\n    for n1, n2 in tree.edges():",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"random color assignment for label classes.\"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()\n        colors[k] = (r, g, b)\n    return [colors[k] for k in y]",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves_djj_1",
        "kind": 2,
        "importPath": "stst.utils.visualization",
        "description": "stst.utils.visualization",
        "peekOfCode": "def plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "stst.utils.visualization",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "stst.alignment",
        "description": "stst.alignment",
        "peekOfCode": "class node:\n    def __init__(self,value=None,son=[],name=''):\n        self.value = value;\n        self.son = son;\n        self.name =name;\n        self.f = None;\n        self.depth=0;\n        self.subson= [];\n    def __repr__(self):\n        return self.name",
        "detail": "stst.alignment",
        "documentation": {}
    },
    {
        "label": "tree_alignment",
        "kind": 6,
        "importPath": "stst.alignment",
        "description": "stst.alignment",
        "peekOfCode": "class tree_alignment:\n    def __init__(self,root1,root2,cost1):\n        self.cost1 = cost1;\n        self.dp = dict();\n        self.forestdp = dict();\n        self.anslist = [];\n        self.ansnodes = [];\n        self.root1 = root1;\n        self.root2 = root2;\n        self.minn = math.inf;",
        "detail": "stst.alignment",
        "documentation": {}
    },
    {
        "label": "show_graph",
        "kind": 6,
        "importPath": "stst.alignment",
        "description": "stst.alignment",
        "peekOfCode": "class show_graph:\n    def __init__(self,ans,root1,root2):\n        self.ans = ans;\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];",
        "detail": "stst.alignment",
        "documentation": {}
    },
    {
        "label": "show_tree",
        "kind": 6,
        "importPath": "stst.alignment",
        "description": "stst.alignment",
        "peekOfCode": "class show_tree:\n    def __init__(self,root1):\n        self.pos_x=[];\n        self.pos_y=[];\n        self.edges=[];\n        self.label_hash = dict(); \n        self.labels = [];\n        self.hover_text =[];\n        self.values=[];\n        self.cnt = 0;",
        "detail": "stst.alignment",
        "documentation": {}
    },
    {
        "label": "run_alignment",
        "kind": 2,
        "importPath": "stst.alignment",
        "description": "stst.alignment",
        "peekOfCode": "def run_alignment(folder_path1,folder_path2):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    pos_2 = pd.read_csv(folder_path2+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    edge_2 = np.load(folder_path2+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    mer2 = np.load(folder_path2+\"datamerge.npy\");\n    n1 = len(pos_1)\n    n2 = len(pos_2)\n    root1 = -1;",
        "detail": "stst.alignment",
        "documentation": {}
    },
    {
        "label": "show_the_tree",
        "kind": 2,
        "importPath": "stst.alignment",
        "description": "stst.alignment",
        "peekOfCode": "def show_the_tree(folder_path1):\n    pos_1 = pd.read_csv(folder_path1+\"datas.csv\",index_col=\"Unnamed: 0\").sort_index().values\n    edge_1 = np.load(folder_path1+\"datalink.npy\");\n    mer1 = np.load(folder_path1+\"datamerge.npy\");\n    n1 = len(pos_1)\n    root1 = -1;\n    for i,j in edge_1:\n        root1 = max(root1,i);\n    length1 = root1 + 1;    \n    nodes1 = [node(name=str(i),son=[]) for i in range(length1)]",
        "detail": "stst.alignment",
        "documentation": {}
    },
    {
        "label": "alignment_process",
        "kind": 2,
        "importPath": "stst.core",
        "description": "stst.core",
        "peekOfCode": "def alignment_process(cell_path1,cell_path2,celltype_path1,celltype_path2,celltype_column1,celltype_column2,folder_path1,folder_path2,radius1,radius2,c1,c2,epoches1,epoches2):\n    loss = merge_cells_by_radius(cell_path1,celltype_path1,celltype_column1,folder_path1,radius1)\n    print(\"cell merge loss for dataset1: {}\".format(loss))\n    loss = merge_cells_by_radius(cell_path2,celltype_path2,celltype_column2,folder_path2,radius2)\n    print(\"cell merge loss for dataset2: {}\".format(loss))\n    adata1 = pd.read_csv(folder_path1+\"merge_cell_data.csv\")\n    cell_meta = pd.read_csv(folder_path1+\"merge_cell_meta.csv\")\n    cell_meta = cell_meta.set_index(cell_meta.columns[0])\n    adata1 = adata1.set_index(adata1.columns[0])\n    adata1 = anndata.AnnData(adata1)",
        "detail": "stst.core",
        "documentation": {}
    },
    {
        "label": {
            "name": "",
            "kind": 6,
            "peekOfCode": "class  UnionFind:\n    def __init__(self, n , pos , c):\n        self.n = n\n        self.pos = pos\n        self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self.vis = [0 for i in range(2*n-1)]\n        self.vis2 = [0 for i in range(2*n-1)]\n        self.mer = [-1 for i in range(2*n-1)]"
        },
        "kind": 6,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "class  UnionFind:\n    def __init__(self, n , pos , c):\n        self.n = n\n        self.pos = pos\n        self.c = c\n        self.parent = [i for i in range(n)]\n        self.rank = [0 for i in range(n)]\n        self.vis = [0 for i in range(2*n-1)]\n        self.vis2 = [0 for i in range(2*n-1)]\n        self.mer = [-1 for i in range(2*n-1)]",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "hyp_lca_numpy",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def hyp_lca_numpy(x, y):\n    \"\"\"Computes the hyperbolic LCA in numpy.\"\"\"\n    x = torch.from_numpy(x).view((1, 2))\n    y = torch.from_numpy(y).view((1, 2))\n    lca = hyp_lca(x, y, return_coord=True)\n    return lca.view((2,)).numpy()\ndef is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "is_leaf",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def is_leaf(tree, node):\n    \"\"\"check if node is a leaf in tree.\"\"\"\n    return len(list(tree.neighbors(node))) == 0\ndef complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "complete_tree",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def complete_tree(tree, leaves_embeddings):\n    \"\"\"Get embeddings of internal nodes from leaves' embeddings using LCA construction.\"\"\"\n    def _complete_tree(embeddings, node):\n        children = list(tree.neighbors(node))\n        if len(children) == 2:\n            left_c, right_c = children\n            left_leaf = is_leaf(tree, left_c)\n            right_leaf = is_leaf(tree, right_c)\n            if left_leaf and right_leaf:\n                pass",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def train(model,dataloader,optimizer,similarities,epoches):\n    best_cost = np.inf\n    best_model = None\n    counter = 0\n    for epoch in range(epoches):\n        model.train()\n        total_loss = 0.0\n        with tqdm(total=len(dataloader), unit='ex') as bar:\n            for step, (triple_ids, triple_similarities) in enumerate(dataloader):\n                # triple_ids = triple_ids.cuda()",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "dist",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def dist(x,y):\n    return arcosh(1+ 2*( (x-y).norm(dim=-1, p=2, keepdim=True))/((1- y.norm(dim=-1, p=2, keepdim=True))*(1- x.norm(dim=-1, p=2, keepdim=True))));\ndef plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "plot_tree_from_leaves_djj_1",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def plot_tree_from_leaves_djj_1(ax, tree, leaves_embeddings, labels, color_seed=1234):\n    \"\"\"Plots a tree on leaves embeddings using the LCA construction.\"\"\"\n    circle = plt.Circle((0, 0), 20.0, color='r', alpha=0.1)\n    ax.add_artist(circle)\n    n = leaves_embeddings.shape[0]\n    embeddings = complete_tree(tree, leaves_embeddings)\n    colors = get_colors(labels, color_seed)\n    ax.scatter(embeddings[:n, 0]*20, embeddings[:n, 1]*20, c=colors, s=50, alpha=0.6)\n    for n1, n2 in tree.edges():\n        x1 = embeddings[n1]",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "sl_np_mst_ij",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def sl_np_mst_ij(xs, S):\n    xs = project(xs).detach().cpu()\n    xs0 = xs[None, :, :]\n    xs1 = xs[:, None, :]\n    sim_mat = S(xs0, xs1)  # (n, n)\n    similarities = sim_mat.numpy()\n    n = similarities.shape[0]\n    similarities=similarities.astype('double')\n    ij, _ = mst.mst(similarities, n)\n    return ij",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "get_colors",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def get_colors(y, color_seed=1234):\n    \"\"\"random color assignment for label classes.\"\"\"\n    np.random.seed(color_seed)\n    colors = {}\n    for k in np.unique(y):\n        r = np.random.random()\n        b = np.random.random()\n        g = np.random.random()\n        colors[k] = (r, g, b)\n    return [colors[k] for k in y]",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "search_tree",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def search_tree(now,c,merge_list):\n    if(len(now.son) != 2):\n        return now;\n    lson = search_tree(now.son[0],c,merge_list);\n    now.son[0] = lson;\n    rson = search_tree(now.son[1],c,merge_list);\n    now.son[1] = rson\n    if(np.linalg.norm(lson.value-rson.value)<=c):\n        if(len(lson.son)>1 and len(rson.son)>1):\n            pass",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "search_merge_tree",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def search_merge_tree(now,ids,save_path,values,fathers):\n    fathers.append(ids);\n    values.append(now.name);\n    now_id = len(values)-1;\n    for son in now.son:\n        search_merge_tree(son,now_id,save_path,values,fathers)\ndef cccfg(\n        adata,\n        save_path=\"./\",\n    ):",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "cccfg",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def cccfg(\n        adata,\n        save_path=\"./\",\n    ):\n    groupby = adata.uns[\"capital\"][\"tree\"][\"annotation\"]\n    filtered_data = adata.raw.to_adata()[:]\n    filtered_data.to_df().to_csv(save_path+\"data_cell.csv\");\n    adata.obs.to_csv(save_path+\"data_type.csv\")\n    cluster_centroid_data = np.empty((0, filtered_data.n_vars))\n    clustername = filtered_data.obs[groupby].unique().tolist()",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "get_Hyper_tree",
        "kind": 2,
        "importPath": "stst.hyper",
        "description": "stst.hyper",
        "peekOfCode": "def get_Hyper_tree(data_path,start,end,lable,epoches,model_path=None,save_path='./',c=-1):\n    np.random.seed(1234)\n    torch.manual_seed(1234)\n    # x, y_true, similarities = load_data('../../../cityu/HypHC/data/4_8/4_8.data',start,end,lable)\n    x, y_true, similarities = load_data(data_path,start,end,lable)\n    print(\"{} length:{}\".format(data_path,len(y_true)));\n    dataset = HCDataset(x, y_true, similarities, num_samples=50000)\n    dataloader = data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n    if(model_path ==None):\n        model = HypHC(dataset.n_nodes, 2, 5e-2, 5e-2 ,0.999)",
        "detail": "stst.hyper",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "stst.read_data",
        "description": "stst.read_data",
        "peekOfCode": "def read_file(file_path, file_label):\n    '''\n    Read data with given path.\n    args:\n        file_path: file path.\n        file_label: the file label to raise exception.\n    return:\n        the read file.\n    '''\n    try:",
        "detail": "stst.read_data",
        "documentation": {}
    },
    {
        "label": "read_training_data",
        "kind": 2,
        "importPath": "stst.read_data",
        "description": "stst.read_data",
        "peekOfCode": "def read_training_data(sc_path,meta_path,marker,sc_nor,out_dir):\n    \"\"\"read sc data and meta information to train model.\n    args:\n        sc_path:    sc-rna data path.\n        meta_path:  meta data with cell type information path.\n        marker:     the marker gene list if provided or none.\n        sc_nor:     Boolean, true for using preprocessing on sc data.\n        out_path:   the dir to store the result files.\n    \"\"\"\n    warnings.filterwarnings(action='ignore', category=FutureWarning) ",
        "detail": "stst.read_data",
        "documentation": {}
    },
    {
        "label": "merge_cells_by_radius",
        "kind": 2,
        "importPath": "stst.read_data",
        "description": "stst.read_data",
        "peekOfCode": "def merge_cells_by_radius(cell_path,celltype_path,celltype_column,folder_path,radius):\n    datas = pd.read_csv(cell_path)\n    datas = datas.set_index(datas.columns[0])\n    celltype = pd.read_csv(celltype_path,sep=\"\\t\")\n    adata = datas.copy()\n    adata.loc[list(celltype['Cell']), 'Celltype'] = list(celltype[celltype_column])\n    adata\n    ans_value = []\n    ans_label = []\n    true_label = [];",
        "detail": "stst.read_data",
        "documentation": {}
    },
    {
        "label": "build_hyper_tree",
        "kind": 2,
        "importPath": "stst.read_data",
        "description": "stst.read_data",
        "peekOfCode": "def build_hyper_tree(folder_path):\n    pos_1 = pd.read_csv(folder_path + 'datas.csv')\n    pos = pos_1.set_index(pos_1.columns[0]).values\n    edge = np.load(folder_path + \"datalink.npy\");\n    father_name = np.load(folder_path + \"dataxy.npy\")\n    father_name = father_name.astype(np.int)\n    n = len(edge)\n    n_points = len(pos);\n    nodes = [node(name=str(i),son=[]) for i in range(n)];\n    for i in range(n):",
        "detail": "stst.read_data",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "stst.test",
        "description": "stst.test",
        "peekOfCode": "def run(data1_path,data2_path,folder1_path,folder2_path):\n    # adata1 = sc.read(\"../../../capital/docs/tutorials/BRCA_EMTAB8107_expression_processed.h5ad\")\n    # adata2 = sc.read(\"../../../capital/docs/tutorials/BRCA_GSE114727_inDrop_expression_processed.h5ad\") \n    adata1 = sc.read(data1_path)\n    adata2 = sc.read(data2_path)\n    # preprocessing()\n    # sc.pl.umap(adata1, color=\"leiden\")\n    set_initial_condition(adata1)\n    set_initial_condition(adata2)\n    adata2.uns.pop(\"log1p\")",
        "detail": "stst.test",
        "documentation": {}
    }
]